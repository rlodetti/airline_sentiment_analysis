{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aee659b3-a44b-4d8d-9c1f-8de2162c1bb3",
   "metadata": {},
   "source": [
    "1. Load Data (stratified sample)\n",
    "2. train-val-test split\n",
    "4. clean/tokenize, not stop, not lemma\n",
    "5. convert to tf.dataset\n",
    "6. run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc367dae-a0da-481d-a487-c5f27ac00637",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading sample Data\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945900ad-0e74-4360-8dc7-0f51cd020da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, Sequential\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "\n",
    "def prepare_tf_dataset(X, y, batch_size, is_training=False):\n",
    "    \"\"\"\n",
    "    Prepares a TensorFlow dataset for efficient training or evaluation.\n",
    "    \"\"\"\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    if is_training:\n",
    "        dataset = dataset.shuffle(10000)  # Shuffle only if dataset is for training\n",
    "    return dataset.batch(batch_size).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "def load_data(path, include_validation=False, sample_size=0):\n",
    "    \"\"\"Load review data from a CSV file, with optional sampling and validation split.\"\"\"\n",
    "    df = pd.read_csv(path)[['Review_Title', 'Review', 'Recommended']]\n",
    "    if sample_size > 0:\n",
    "        df = df.sample(sample_size)\n",
    "    \n",
    "    X = df['Review_Title'] + ' ' + df['Review']\n",
    "    y = df['Recommended'].map({'yes': 1, 'no': 0})\n",
    "    \n",
    "    if include_validation:\n",
    "        return split_data_with_validation(X, y)\n",
    "    else:\n",
    "        return train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "def split_data_with_validation(X, y):\n",
    "    \"\"\"Split data into training, validation, and test sets.\"\"\"\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Map POS tag to first character lemmatize() accepts.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(review, stop_words=None, lemmatize=True):\n",
    "    \"\"\"Clean and preprocess a single review text.\"\"\"\n",
    "    tokenizer = RegexpTokenizer(r\"([a-zA-Z]+(?:â€™[a-z]+)?)\")\n",
    "    lemmatizer = WordNetLemmatizer() if lemmatize else None\n",
    "    \n",
    "    tokens = tokenizer.tokenize(review.lower())\n",
    "    if lemmatize:\n",
    "        pos_tags = pos_tag(tokens)\n",
    "        tokens = [lemmatizer.lemmatize(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    if stop_words:\n",
    "        tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "def preprocess_texts(reviews, stop_words=None, lemmatize=False):\n",
    "    \"\"\"Apply text cleaning and preprocessing to a list of texts.\"\"\"\n",
    "    return [clean_text(review, stop_words=stop_words, lemmatize=lemmatize) for review in reviews]\n",
    "\n",
    "def load_and_prepare_data(path, include_validation=True, sample_size=5000, \n",
    "                          stop_words=None, lemmatize=False, \n",
    "                          max_tokens=10000, percentile_len=0.9, batch_size=64):\n",
    "    \"\"\"\n",
    "    Load, clean, and prepare data for training and validation.\n",
    "    \"\"\"\n",
    "    # Load the data with validation split and optional sampling\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = load_data(\n",
    "        path, include_validation=include_validation, sample_size=sample_size)\n",
    "    \n",
    "    # Clean the text data\n",
    "    X_train = preprocess_texts(X_train, stop_words=stop_words, lemmatize=lemmatize)\n",
    "    X_val = preprocess_texts(X_val, stop_words=stop_words, lemmatize=lemmatize)\n",
    "    \n",
    "    # Calculating percentile sequence length and vocabulary size for training set\n",
    "    lengths = pd.Series([len(review.split()) for review in X_train])\n",
    "    sequence_length = int(lengths.quantile(percentile_len))\n",
    "    vocab_size = min(max_tokens, len(set(word for review in X_train for word in review.split())))\n",
    "    \n",
    "    # Initialize and adapt the TextVectorization layer\n",
    "    text_vectorization = tf.keras.layers.TextVectorization(\n",
    "        standardize=None,\n",
    "        max_tokens=vocab_size,\n",
    "        output_mode='int',\n",
    "        output_sequence_length=sequence_length)\n",
    "    \n",
    "    text_vectorization.adapt(X_train)\n",
    "    X_train = text_vectorization(X_train)\n",
    "    X_val = text_vectorization(X_val)\n",
    "    \n",
    "    # Prepare the datasets\n",
    "    train_ds = prepare_tf_dataset(X_train, y_train, batch_size, is_training=True)\n",
    "    val_ds = prepare_tf_dataset(X_val, y_val, batch_size)\n",
    "\n",
    "    return train_ds, val_ds, vocab_size, sequence_length, batch_size\n",
    "\n",
    "def add_rnn_layer(model, units, rnn_type='gru', bidirectional=False, return_sequences=False):\n",
    "    LayerClass = layers.GRU if rnn_type == 'gru' else layers.LSTM\n",
    "    layer = LayerClass(units, return_sequences=return_sequences)\n",
    "    if bidirectional:\n",
    "        layer = layers.Bidirectional(layer)\n",
    "    model.add(layer)\n",
    "\n",
    "def build_rnn_model(rnn_layers, dense_layers, recurrent_type, bi_directional, dropout_rate, units, sequence_length, vocab_size):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=units, input_length=sequence_length))\n",
    "\n",
    "    for i in range(rnn_layers):\n",
    "        add_rnn_layer(model, units, rnn_type=recurrent_type, bidirectional=bi_directional, \n",
    "                      return_sequences=(i < rnn_layers - 1))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(2, units // 2)\n",
    "\n",
    "    for _ in range(dense_layers):\n",
    "        model.add(layers.Dense(units, activation=\"relu\"))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(2, units // 2)\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC(name=\"auc\")])\n",
    "    return model\n",
    "\n",
    "def extract_performance_metrics(history, callbacks, duration):\n",
    "    early_stopping = next(\n",
    "        (cb for cb in callbacks if isinstance(cb, tf.keras.callbacks.EarlyStopping)), \n",
    "        None\n",
    "    )\n",
    "    if early_stopping and early_stopping.stopped_epoch > 0:\n",
    "        adjusted_epoch = early_stopping.stopped_epoch - early_stopping.patience\n",
    "        max_epoch_index = len(history.history['loss']) - 1\n",
    "        best_epoch = max(0, min(adjusted_epoch, max_epoch_index))\n",
    "    else:\n",
    "        best_epoch = len(history.history['loss']) - 1\n",
    "\n",
    "    metrics = {\n",
    "        'loss': history.history['loss'][best_epoch],\n",
    "        'val_loss': history.history['val_loss'][best_epoch],\n",
    "        'val_accuracy': history.history.get('val_accuracy', [None])[best_epoch],\n",
    "        'val_auc': history.history.get('val_auc', [None])[best_epoch],\n",
    "        'duration': duration\n",
    "    }\n",
    "    return metrics\n",
    "\n",
    "def train_and_evaluate(model_function, train_ds, val_ds, epochs):\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            min_delta=0.001,\n",
    "            patience=5, \n",
    "            restore_best_weights=True,\n",
    "            verbose=0\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    model = model_function()    \n",
    "    start_time = time.time()\n",
    "    history = model.fit(\n",
    "        train_ds, \n",
    "        epochs=epochs, \n",
    "        validation_data=val_ds,\n",
    "        callbacks=callbacks,\n",
    "        verbose=0\n",
    "    )\n",
    "    duration = time.time() - start_time\n",
    "    return extract_performance_metrics(history, callbacks, duration)\n",
    "\n",
    "def calculate_average_metrics(runs, model_function, train_ds, val_ds, epochs):\n",
    "    metrics_aggregate = {'loss': 0, 'val_loss': 0, 'val_accuracy': 0, 'val_auc': 0, 'duration': 0}\n",
    "\n",
    "    for _ in range(runs):\n",
    "        metrics = train_and_evaluate(model_function, train_ds, val_ds, epochs)\n",
    "        for key in metrics_aggregate:\n",
    "            metrics_aggregate[key] += metrics[key]\n",
    "\n",
    "    return {key: val / runs for key, val in metrics_aggregate.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f8e1ed4-be78-4642-a3e4-c29e2e4c4866",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load and Prepare the Data\n",
    "train_ds, val_ds, vocab_size, sequence_length, batch_size = load_and_prepare_data(\n",
    "    path='data/Airline_review.csv', \n",
    "    include_validation=True, \n",
    "    sample_size=5000, \n",
    "    stop_words=None, \n",
    "    lemmatize=False, \n",
    "    max_tokens=10000, \n",
    "    percentile_len=0.9, \n",
    "    batch_size=64\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ea1080e-f1eb-4fa3-a2a7-a9e76c734034",
   "metadata": {},
   "source": [
    "loss, val_loss, val_accuracy, val_auc, duration, rnn_layers, dense_layers, recurrent_type, bi_directional, dropout_rate, units, sequence_length, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "717f51dc-d20d-4bdd-b1df-d5079d6162b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "def generate_configurations(param_dict):\n",
    "    # Extract parameter names and their possible values\n",
    "    param_names = list(param_dict.keys())\n",
    "    param_values = list(param_dict.values())\n",
    "\n",
    "    # Compute the Cartesian product of parameter values\n",
    "    all_combinations = product(*param_values)\n",
    "\n",
    "    # Construct a list of dictionaries for each combination\n",
    "    configurations = [dict(zip(param_names, combination)) for combination in all_combinations]\n",
    "   \n",
    "    return configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7dc956e3-a382-4808-a44c-8ee62e2afd17",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "13/13 [==============================] - 4s 153ms/step - loss: 0.6753 - accuracy: 0.6388 - auc: 0.4666 - val_loss: 0.6498 - val_accuracy: 0.6500 - val_auc: 0.6470\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.6397 - accuracy: 0.6488 - auc: 0.5771 - val_loss: 0.6289 - val_accuracy: 0.6500 - val_auc: 0.7758\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.5823 - accuracy: 0.6488 - auc: 0.8588 - val_loss: 0.5289 - val_accuracy: 0.6800 - val_auc: 0.8960\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.3722 - accuracy: 0.8425 - auc: 0.9442 - val_loss: 0.3812 - val_accuracy: 0.8100 - val_auc: 0.9222\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 89ms/step - loss: 0.2215 - accuracy: 0.9350 - auc: 0.9699 - val_loss: 0.4468 - val_accuracy: 0.7400 - val_auc: 0.9244\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 97ms/step - loss: 0.1683 - accuracy: 0.9563 - auc: 0.9898 - val_loss: 0.4552 - val_accuracy: 0.8300 - val_auc: 0.8967\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.1046 - accuracy: 0.9700 - auc: 0.9935 - val_loss: 0.4139 - val_accuracy: 0.8600 - val_auc: 0.9044\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.0488 - accuracy: 0.9900 - auc: 0.9973 - val_loss: 0.5015 - val_accuracy: 0.8600 - val_auc: 0.8835\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.0170 - accuracy: 0.9987 - auc: 0.9998 - val_loss: 0.6302 - val_accuracy: 0.8500 - val_auc: 0.8732\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 133ms/step - loss: 0.6746 - accuracy: 0.6300 - auc: 0.4815 - val_loss: 0.6515 - val_accuracy: 0.6500 - val_auc: 0.6114\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 88ms/step - loss: 0.6427 - accuracy: 0.6488 - auc: 0.5603 - val_loss: 0.6360 - val_accuracy: 0.6500 - val_auc: 0.7279\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 86ms/step - loss: 0.6031 - accuracy: 0.6488 - auc: 0.7967 - val_loss: 0.5684 - val_accuracy: 0.6500 - val_auc: 0.8996\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.4342 - accuracy: 0.7600 - auc: 0.9302 - val_loss: 0.4315 - val_accuracy: 0.8600 - val_auc: 0.9213\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.2622 - accuracy: 0.9312 - auc: 0.9762 - val_loss: 0.3870 - val_accuracy: 0.8300 - val_auc: 0.9356\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.1097 - accuracy: 0.9675 - auc: 0.9907 - val_loss: 0.7195 - val_accuracy: 0.7700 - val_auc: 0.9088\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.0575 - accuracy: 0.9850 - auc: 0.9953 - val_loss: 0.4775 - val_accuracy: 0.8700 - val_auc: 0.9088\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.0250 - accuracy: 0.9937 - auc: 0.9990 - val_loss: 0.4836 - val_accuracy: 0.8500 - val_auc: 0.9042\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.0173 - accuracy: 0.9975 - auc: 0.9999 - val_loss: 0.6126 - val_accuracy: 0.8500 - val_auc: 0.8796\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.0071 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.8534 - val_accuracy: 0.8400 - val_auc: 0.8705\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 131ms/step - loss: 0.6782 - accuracy: 0.6463 - auc: 0.4772 - val_loss: 0.6557 - val_accuracy: 0.6500 - val_auc: 0.6037\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 97ms/step - loss: 0.6433 - accuracy: 0.6488 - auc: 0.5528 - val_loss: 0.6289 - val_accuracy: 0.6500 - val_auc: 0.7477\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.5752 - accuracy: 0.6538 - auc: 0.8415 - val_loss: 0.5140 - val_accuracy: 0.6800 - val_auc: 0.9143\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 90ms/step - loss: 0.3835 - accuracy: 0.8450 - auc: 0.9262 - val_loss: 0.4065 - val_accuracy: 0.8700 - val_auc: 0.9360\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 87ms/step - loss: 0.2415 - accuracy: 0.9225 - auc: 0.9747 - val_loss: 0.4084 - val_accuracy: 0.8000 - val_auc: 0.9440\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.1252 - accuracy: 0.9638 - auc: 0.9908 - val_loss: 0.4285 - val_accuracy: 0.8200 - val_auc: 0.9451\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 94ms/step - loss: 0.0609 - accuracy: 0.9837 - auc: 0.9962 - val_loss: 0.4365 - val_accuracy: 0.8700 - val_auc: 0.9325\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 94ms/step - loss: 0.0329 - accuracy: 0.9900 - auc: 0.9982 - val_loss: 0.7324 - val_accuracy: 0.8400 - val_auc: 0.8743\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 97ms/step - loss: 0.0122 - accuracy: 0.9975 - auc: 1.0000 - val_loss: 0.6556 - val_accuracy: 0.8700 - val_auc: 0.8820\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 158ms/step - loss: 0.6893 - accuracy: 0.5888 - auc: 0.4824 - val_loss: 0.6756 - val_accuracy: 0.6500 - val_auc: 0.5501\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 103ms/step - loss: 0.6644 - accuracy: 0.6488 - auc: 0.5083 - val_loss: 0.6426 - val_accuracy: 0.6500 - val_auc: 0.6987\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.6310 - accuracy: 0.6463 - auc: 0.6235 - val_loss: 0.6056 - val_accuracy: 0.6500 - val_auc: 0.8793\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 106ms/step - loss: 0.5257 - accuracy: 0.6637 - auc: 0.8522 - val_loss: 0.4473 - val_accuracy: 0.7100 - val_auc: 0.9310\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.4089 - accuracy: 0.8562 - auc: 0.9240 - val_loss: 0.3875 - val_accuracy: 0.8600 - val_auc: 0.9407\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 104ms/step - loss: 0.2308 - accuracy: 0.9450 - auc: 0.9837 - val_loss: 0.3816 - val_accuracy: 0.8200 - val_auc: 0.9387\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.1118 - accuracy: 0.9675 - auc: 0.9890 - val_loss: 0.6811 - val_accuracy: 0.8200 - val_auc: 0.9123\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0741 - accuracy: 0.9812 - auc: 0.9927 - val_loss: 0.4998 - val_accuracy: 0.8800 - val_auc: 0.9051\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.0320 - accuracy: 0.9950 - auc: 0.9981 - val_loss: 0.8692 - val_accuracy: 0.8300 - val_auc: 0.8870\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 117ms/step - loss: 0.0193 - accuracy: 0.9962 - auc: 0.9998 - val_loss: 0.8521 - val_accuracy: 0.8300 - val_auc: 0.8741\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 132ms/step - loss: 0.6804 - accuracy: 0.6338 - auc: 0.4856 - val_loss: 0.6601 - val_accuracy: 0.6500 - val_auc: 0.4987\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 96ms/step - loss: 0.6527 - accuracy: 0.6488 - auc: 0.5107 - val_loss: 0.6418 - val_accuracy: 0.6500 - val_auc: 0.6560\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 96ms/step - loss: 0.6225 - accuracy: 0.6488 - auc: 0.6627 - val_loss: 0.5915 - val_accuracy: 0.6500 - val_auc: 0.8431\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.4891 - accuracy: 0.6900 - auc: 0.8915 - val_loss: 0.4714 - val_accuracy: 0.8000 - val_auc: 0.9160\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.3640 - accuracy: 0.8950 - auc: 0.9682 - val_loss: 0.4784 - val_accuracy: 0.7800 - val_auc: 0.9363\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 94ms/step - loss: 0.2080 - accuracy: 0.9538 - auc: 0.9842 - val_loss: 0.4250 - val_accuracy: 0.8600 - val_auc: 0.9437\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 95ms/step - loss: 0.0969 - accuracy: 0.9762 - auc: 0.9888 - val_loss: 0.6187 - val_accuracy: 0.8100 - val_auc: 0.8947\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 94ms/step - loss: 0.0473 - accuracy: 0.9887 - auc: 0.9971 - val_loss: 0.8122 - val_accuracy: 0.8100 - val_auc: 0.8763\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 91ms/step - loss: 0.0204 - accuracy: 0.9950 - auc: 0.9991 - val_loss: 1.1180 - val_accuracy: 0.8200 - val_auc: 0.8334\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 96ms/step - loss: 0.0057 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.9239 - val_accuracy: 0.8200 - val_auc: 0.8633\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 92ms/step - loss: 0.0046 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 1.3825 - val_accuracy: 0.8400 - val_auc: 0.8130\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 151ms/step - loss: 0.6812 - accuracy: 0.6263 - auc: 0.4739 - val_loss: 0.6574 - val_accuracy: 0.6500 - val_auc: 0.5316\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 105ms/step - loss: 0.6483 - accuracy: 0.6488 - auc: 0.5420 - val_loss: 0.6423 - val_accuracy: 0.6500 - val_auc: 0.6842\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6126 - accuracy: 0.6513 - auc: 0.6957 - val_loss: 0.5873 - val_accuracy: 0.6500 - val_auc: 0.8723\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.4444 - accuracy: 0.7700 - auc: 0.9129 - val_loss: 0.3780 - val_accuracy: 0.8500 - val_auc: 0.9112\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.2267 - accuracy: 0.9350 - auc: 0.9667 - val_loss: 0.4104 - val_accuracy: 0.8400 - val_auc: 0.9345\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 101ms/step - loss: 0.1058 - accuracy: 0.9737 - auc: 0.9879 - val_loss: 0.5017 - val_accuracy: 0.8500 - val_auc: 0.8903\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0466 - accuracy: 0.9887 - auc: 0.9977 - val_loss: 0.8115 - val_accuracy: 0.8400 - val_auc: 0.8490\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.0260 - accuracy: 0.9937 - auc: 0.9986 - val_loss: 1.2441 - val_accuracy: 0.8200 - val_auc: 0.8277\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.0094 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.7271 - val_accuracy: 0.8500 - val_auc: 0.8651\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 240ms/step - loss: 0.6769 - accuracy: 0.6250 - auc: 0.4758 - val_loss: 0.6513 - val_accuracy: 0.6500 - val_auc: 0.6492\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 0.6488 - accuracy: 0.6475 - auc: 0.5303 - val_loss: 0.6292 - val_accuracy: 0.6500 - val_auc: 0.7567\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 0.5827 - accuracy: 0.6637 - auc: 0.7874 - val_loss: 0.5003 - val_accuracy: 0.7800 - val_auc: 0.9042\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 0.3381 - accuracy: 0.8863 - auc: 0.9340 - val_loss: 0.4120 - val_accuracy: 0.7900 - val_auc: 0.9229\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 164ms/step - loss: 0.1746 - accuracy: 0.9438 - auc: 0.9797 - val_loss: 0.4593 - val_accuracy: 0.8100 - val_auc: 0.9110\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 166ms/step - loss: 0.1032 - accuracy: 0.9675 - auc: 0.9926 - val_loss: 0.4338 - val_accuracy: 0.8500 - val_auc: 0.9092\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.0435 - accuracy: 0.9925 - auc: 0.9976 - val_loss: 0.6318 - val_accuracy: 0.8300 - val_auc: 0.8782\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.0154 - accuracy: 0.9950 - auc: 0.9999 - val_loss: 0.6528 - val_accuracy: 0.8400 - val_auc: 0.8851\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.0121 - accuracy: 0.9975 - auc: 0.9999 - val_loss: 0.7380 - val_accuracy: 0.8300 - val_auc: 0.8697\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 247ms/step - loss: 0.6772 - accuracy: 0.6400 - auc: 0.4623 - val_loss: 0.6527 - val_accuracy: 0.6500 - val_auc: 0.5633\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.6495 - accuracy: 0.6488 - auc: 0.5166 - val_loss: 0.6353 - val_accuracy: 0.6500 - val_auc: 0.7387\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.6016 - accuracy: 0.6488 - auc: 0.7678 - val_loss: 0.5521 - val_accuracy: 0.6500 - val_auc: 0.9077\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 0.3812 - accuracy: 0.8313 - auc: 0.9347 - val_loss: 0.3586 - val_accuracy: 0.8400 - val_auc: 0.9207\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.1874 - accuracy: 0.9337 - auc: 0.9783 - val_loss: 0.3258 - val_accuracy: 0.8600 - val_auc: 0.9321\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.0915 - accuracy: 0.9737 - auc: 0.9941 - val_loss: 0.7037 - val_accuracy: 0.8000 - val_auc: 0.9068\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.0731 - accuracy: 0.9775 - auc: 0.9949 - val_loss: 0.4469 - val_accuracy: 0.8400 - val_auc: 0.9196\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.0215 - accuracy: 0.9962 - auc: 0.9995 - val_loss: 0.6012 - val_accuracy: 0.8400 - val_auc: 0.8895\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 0.0090 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.5855 - val_accuracy: 0.8500 - val_auc: 0.8886\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.0051 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6937 - val_accuracy: 0.8500 - val_auc: 0.8815\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 243ms/step - loss: 0.6719 - accuracy: 0.6475 - auc: 0.4748 - val_loss: 0.6503 - val_accuracy: 0.6500 - val_auc: 0.6000\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.6410 - accuracy: 0.6488 - auc: 0.5804 - val_loss: 0.6220 - val_accuracy: 0.6500 - val_auc: 0.8165\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.5443 - accuracy: 0.6875 - auc: 0.8744 - val_loss: 0.4728 - val_accuracy: 0.7500 - val_auc: 0.9037\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.3177 - accuracy: 0.8900 - auc: 0.9468 - val_loss: 0.3786 - val_accuracy: 0.8200 - val_auc: 0.9187\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.1624 - accuracy: 0.9550 - auc: 0.9845 - val_loss: 0.6875 - val_accuracy: 0.8100 - val_auc: 0.8952\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.0944 - accuracy: 0.9750 - auc: 0.9928 - val_loss: 0.7072 - val_accuracy: 0.8000 - val_auc: 0.8756\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.0576 - accuracy: 0.9900 - auc: 0.9950 - val_loss: 0.7314 - val_accuracy: 0.8100 - val_auc: 0.8848\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 171ms/step - loss: 0.0217 - accuracy: 0.9975 - auc: 0.9991 - val_loss: 0.8266 - val_accuracy: 0.8300 - val_auc: 0.8466\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 176ms/step - loss: 0.0154 - accuracy: 0.9987 - auc: 0.9981 - val_loss: 0.7556 - val_accuracy: 0.8500 - val_auc: 0.8756\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 254ms/step - loss: 0.6804 - accuracy: 0.6225 - auc: 0.4545 - val_loss: 0.6547 - val_accuracy: 0.6500 - val_auc: 0.5877\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 172ms/step - loss: 0.6595 - accuracy: 0.6438 - auc: 0.4853 - val_loss: 0.6401 - val_accuracy: 0.6500 - val_auc: 0.7600\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.6285 - accuracy: 0.6500 - auc: 0.6331 - val_loss: 0.5922 - val_accuracy: 0.6500 - val_auc: 0.9218\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 170ms/step - loss: 0.5070 - accuracy: 0.6538 - auc: 0.8805 - val_loss: 0.4234 - val_accuracy: 0.6700 - val_auc: 0.9385\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.3446 - accuracy: 0.8400 - auc: 0.9566 - val_loss: 0.4496 - val_accuracy: 0.8400 - val_auc: 0.9424\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.2519 - accuracy: 0.9350 - auc: 0.9787 - val_loss: 0.8856 - val_accuracy: 0.7800 - val_auc: 0.8879\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 169ms/step - loss: 0.1356 - accuracy: 0.9625 - auc: 0.9912 - val_loss: 0.4495 - val_accuracy: 0.8700 - val_auc: 0.9070\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.0963 - accuracy: 0.9737 - auc: 0.9948 - val_loss: 0.8768 - val_accuracy: 0.8400 - val_auc: 0.8503\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 167ms/step - loss: 0.0674 - accuracy: 0.9812 - auc: 0.9967 - val_loss: 1.4704 - val_accuracy: 0.7900 - val_auc: 0.7732\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 234ms/step - loss: 0.6751 - accuracy: 0.6413 - auc: 0.4750 - val_loss: 0.6533 - val_accuracy: 0.6500 - val_auc: 0.6277\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 159ms/step - loss: 0.6567 - accuracy: 0.6488 - auc: 0.4907 - val_loss: 0.6401 - val_accuracy: 0.6500 - val_auc: 0.7251\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 0.6237 - accuracy: 0.6488 - auc: 0.6641 - val_loss: 0.5820 - val_accuracy: 0.6500 - val_auc: 0.9048\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 162ms/step - loss: 0.4775 - accuracy: 0.6525 - auc: 0.8908 - val_loss: 0.4338 - val_accuracy: 0.7600 - val_auc: 0.9270\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 0.3373 - accuracy: 0.8175 - auc: 0.9664 - val_loss: 0.4603 - val_accuracy: 0.8300 - val_auc: 0.9495\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.2558 - accuracy: 0.9125 - auc: 0.9811 - val_loss: 0.5420 - val_accuracy: 0.8500 - val_auc: 0.9253\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 158ms/step - loss: 0.1778 - accuracy: 0.9438 - auc: 0.9888 - val_loss: 0.4977 - val_accuracy: 0.9000 - val_auc: 0.9149\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 160ms/step - loss: 0.1348 - accuracy: 0.9563 - auc: 0.9878 - val_loss: 0.6254 - val_accuracy: 0.8600 - val_auc: 0.8996\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 161ms/step - loss: 0.1006 - accuracy: 0.9712 - auc: 0.9938 - val_loss: 0.9604 - val_accuracy: 0.8300 - val_auc: 0.8554\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 245ms/step - loss: 0.6835 - accuracy: 0.5775 - auc: 0.5090 - val_loss: 0.6642 - val_accuracy: 0.6500 - val_auc: 0.5473\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.6686 - accuracy: 0.6012 - auc: 0.4965 - val_loss: 0.6481 - val_accuracy: 0.6500 - val_auc: 0.6853\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.6559 - accuracy: 0.6325 - auc: 0.5767 - val_loss: 0.6277 - val_accuracy: 0.6500 - val_auc: 0.8695\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.6031 - accuracy: 0.6687 - auc: 0.6877 - val_loss: 0.4995 - val_accuracy: 0.7400 - val_auc: 0.9163\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.4274 - accuracy: 0.8138 - auc: 0.8961 - val_loss: 0.4350 - val_accuracy: 0.8100 - val_auc: 0.9303\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.2929 - accuracy: 0.9062 - auc: 0.9711 - val_loss: 0.3981 - val_accuracy: 0.8200 - val_auc: 0.9251\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.2116 - accuracy: 0.9613 - auc: 0.9837 - val_loss: 0.4087 - val_accuracy: 0.8600 - val_auc: 0.9160\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.1676 - accuracy: 0.9663 - auc: 0.9952 - val_loss: 0.5260 - val_accuracy: 0.8400 - val_auc: 0.9156\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 178ms/step - loss: 0.1449 - accuracy: 0.9650 - auc: 0.9959 - val_loss: 0.5637 - val_accuracy: 0.8400 - val_auc: 0.9011\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.1167 - accuracy: 0.9725 - auc: 0.9991 - val_loss: 0.6720 - val_accuracy: 0.8400 - val_auc: 0.8829\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.0933 - accuracy: 0.9862 - auc: 0.9988 - val_loss: 0.5870 - val_accuracy: 0.8700 - val_auc: 0.8721\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 89ms/step - loss: 0.6749 - accuracy: 0.6438 - auc: 0.4585 - val_loss: 0.6574 - val_accuracy: 0.6500 - val_auc: 0.4455\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6515 - accuracy: 0.6488 - auc: 0.5004 - val_loss: 0.6564 - val_accuracy: 0.6500 - val_auc: 0.4464\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.6523 - accuracy: 0.6488 - auc: 0.4796 - val_loss: 0.6533 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6490 - accuracy: 0.6488 - auc: 0.5090 - val_loss: 0.6511 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.6492 - accuracy: 0.6488 - auc: 0.4958 - val_loss: 0.6488 - val_accuracy: 0.6500 - val_auc: 0.4767\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6425 - accuracy: 0.6488 - auc: 0.5669 - val_loss: 0.6459 - val_accuracy: 0.6500 - val_auc: 0.5275\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6375 - accuracy: 0.6488 - auc: 0.5834 - val_loss: 0.6412 - val_accuracy: 0.6500 - val_auc: 0.5391\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.6329 - accuracy: 0.6500 - auc: 0.5390 - val_loss: 0.6330 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6227 - accuracy: 0.6562 - auc: 0.5664 - val_loss: 0.6263 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.6188 - accuracy: 0.6637 - auc: 0.5580 - val_loss: 0.6225 - val_accuracy: 0.6500 - val_auc: 0.5521\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.6076 - accuracy: 0.6650 - auc: 0.5902 - val_loss: 0.6290 - val_accuracy: 0.6600 - val_auc: 0.5534\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6101 - accuracy: 0.6687 - auc: 0.5534 - val_loss: 0.6248 - val_accuracy: 0.6500 - val_auc: 0.5534\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6009 - accuracy: 0.6687 - auc: 0.5854 - val_loss: 0.6186 - val_accuracy: 0.6500 - val_auc: 0.5635\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 65ms/step - loss: 0.5948 - accuracy: 0.6662 - auc: 0.5840 - val_loss: 0.6195 - val_accuracy: 0.6600 - val_auc: 0.5862\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6005 - accuracy: 0.6700 - auc: 0.5679 - val_loss: 0.6291 - val_accuracy: 0.6500 - val_auc: 0.5415\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 2s 86ms/step - loss: 0.6773 - accuracy: 0.6313 - auc: 0.4706 - val_loss: 0.6588 - val_accuracy: 0.6500 - val_auc: 0.4440\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.6599 - accuracy: 0.6488 - auc: 0.4393 - val_loss: 0.6554 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6521 - accuracy: 0.6488 - auc: 0.4782 - val_loss: 0.6519 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6488 - accuracy: 0.6488 - auc: 0.5177 - val_loss: 0.6493 - val_accuracy: 0.6500 - val_auc: 0.4477\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6459 - accuracy: 0.6488 - auc: 0.5366 - val_loss: 0.6468 - val_accuracy: 0.6500 - val_auc: 0.5200\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6377 - accuracy: 0.6488 - auc: 0.6017 - val_loss: 0.6425 - val_accuracy: 0.6500 - val_auc: 0.5466\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6348 - accuracy: 0.6488 - auc: 0.5800 - val_loss: 0.6357 - val_accuracy: 0.6500 - val_auc: 0.5710\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6259 - accuracy: 0.6500 - auc: 0.5584 - val_loss: 0.6275 - val_accuracy: 0.6500 - val_auc: 0.5618\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6193 - accuracy: 0.6550 - auc: 0.5537 - val_loss: 0.6274 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6156 - accuracy: 0.6675 - auc: 0.5800 - val_loss: 0.6190 - val_accuracy: 0.6500 - val_auc: 0.5415\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6072 - accuracy: 0.6662 - auc: 0.5759 - val_loss: 0.6331 - val_accuracy: 0.6500 - val_auc: 0.5389\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6078 - accuracy: 0.6687 - auc: 0.5908 - val_loss: 0.6320 - val_accuracy: 0.6500 - val_auc: 0.5389\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6019 - accuracy: 0.6687 - auc: 0.5760 - val_loss: 0.6270 - val_accuracy: 0.6500 - val_auc: 0.5607\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5945 - accuracy: 0.6700 - auc: 0.5981 - val_loss: 0.6215 - val_accuracy: 0.6600 - val_auc: 0.5684\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5935 - accuracy: 0.6700 - auc: 0.5787 - val_loss: 0.6164 - val_accuracy: 0.6600 - val_auc: 0.5609\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 87ms/step - loss: 0.6748 - accuracy: 0.6350 - auc: 0.4635 - val_loss: 0.6577 - val_accuracy: 0.6500 - val_auc: 0.4457\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6579 - accuracy: 0.6488 - auc: 0.4520 - val_loss: 0.6552 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6539 - accuracy: 0.6488 - auc: 0.4724 - val_loss: 0.6527 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6494 - accuracy: 0.6488 - auc: 0.5054 - val_loss: 0.6505 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6497 - accuracy: 0.6488 - auc: 0.4943 - val_loss: 0.6482 - val_accuracy: 0.6500 - val_auc: 0.4824\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6488 - accuracy: 0.6488 - auc: 0.4967 - val_loss: 0.6450 - val_accuracy: 0.6500 - val_auc: 0.5169\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6414 - accuracy: 0.6488 - auc: 0.5237 - val_loss: 0.6395 - val_accuracy: 0.6500 - val_auc: 0.5532\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6300 - accuracy: 0.6488 - auc: 0.5575 - val_loss: 0.6301 - val_accuracy: 0.6500 - val_auc: 0.5582\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6185 - accuracy: 0.6513 - auc: 0.5479 - val_loss: 0.6299 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6220 - accuracy: 0.6600 - auc: 0.5504 - val_loss: 0.6271 - val_accuracy: 0.6500 - val_auc: 0.5591\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6038 - accuracy: 0.6637 - auc: 0.5861 - val_loss: 0.6150 - val_accuracy: 0.6500 - val_auc: 0.5530\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6071 - accuracy: 0.6687 - auc: 0.5853 - val_loss: 0.6042 - val_accuracy: 0.6500 - val_auc: 0.5763\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6450 - accuracy: 0.6662 - auc: 0.5885 - val_loss: 0.6380 - val_accuracy: 0.6400 - val_auc: 0.5389\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6144 - accuracy: 0.6700 - auc: 0.5814 - val_loss: 0.6490 - val_accuracy: 0.6200 - val_auc: 0.5336\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6090 - accuracy: 0.6687 - auc: 0.5835 - val_loss: 0.6484 - val_accuracy: 0.6200 - val_auc: 0.5336\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.5989 - accuracy: 0.6700 - auc: 0.6213 - val_loss: 0.6458 - val_accuracy: 0.6300 - val_auc: 0.5336\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.5994 - accuracy: 0.6700 - auc: 0.5498 - val_loss: 0.6432 - val_accuracy: 0.6200 - val_auc: 0.5099\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 86ms/step - loss: 0.6762 - accuracy: 0.6263 - auc: 0.4878 - val_loss: 0.6590 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6613 - accuracy: 0.6488 - auc: 0.4622 - val_loss: 0.6548 - val_accuracy: 0.6500 - val_auc: 0.4459\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6518 - accuracy: 0.6488 - auc: 0.5061 - val_loss: 0.6533 - val_accuracy: 0.6500 - val_auc: 0.4468\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6541 - accuracy: 0.6488 - auc: 0.4918 - val_loss: 0.6518 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6509 - accuracy: 0.6488 - auc: 0.5113 - val_loss: 0.6500 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6528 - accuracy: 0.6488 - auc: 0.5008 - val_loss: 0.6486 - val_accuracy: 0.6500 - val_auc: 0.4765\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6476 - accuracy: 0.6488 - auc: 0.5280 - val_loss: 0.6463 - val_accuracy: 0.6500 - val_auc: 0.5341\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6457 - accuracy: 0.6488 - auc: 0.5373 - val_loss: 0.6427 - val_accuracy: 0.6500 - val_auc: 0.5391\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6409 - accuracy: 0.6488 - auc: 0.5383 - val_loss: 0.6380 - val_accuracy: 0.6500 - val_auc: 0.5967\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6317 - accuracy: 0.6488 - auc: 0.5452 - val_loss: 0.6287 - val_accuracy: 0.6500 - val_auc: 0.5732\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6261 - accuracy: 0.6488 - auc: 0.5247 - val_loss: 0.6258 - val_accuracy: 0.6500 - val_auc: 0.5631\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6159 - accuracy: 0.6513 - auc: 0.5601 - val_loss: 0.6207 - val_accuracy: 0.6500 - val_auc: 0.5640\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6217 - accuracy: 0.6525 - auc: 0.5608 - val_loss: 0.6330 - val_accuracy: 0.6500 - val_auc: 0.5246\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6180 - accuracy: 0.6587 - auc: 0.5625 - val_loss: 0.6328 - val_accuracy: 0.6500 - val_auc: 0.5248\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6121 - accuracy: 0.6675 - auc: 0.5726 - val_loss: 0.6285 - val_accuracy: 0.6500 - val_auc: 0.5248\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6089 - accuracy: 0.6687 - auc: 0.5688 - val_loss: 0.6249 - val_accuracy: 0.6500 - val_auc: 0.5611\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 87ms/step - loss: 0.6874 - accuracy: 0.6112 - auc: 0.4532 - val_loss: 0.6712 - val_accuracy: 0.6500 - val_auc: 0.4440\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6671 - accuracy: 0.6488 - auc: 0.4609 - val_loss: 0.6544 - val_accuracy: 0.6500 - val_auc: 0.4446\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6557 - accuracy: 0.6488 - auc: 0.4778 - val_loss: 0.6519 - val_accuracy: 0.6500 - val_auc: 0.4464\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6547 - accuracy: 0.6475 - auc: 0.4922 - val_loss: 0.6501 - val_accuracy: 0.6500 - val_auc: 0.4758\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6506 - accuracy: 0.6488 - auc: 0.5129 - val_loss: 0.6466 - val_accuracy: 0.6500 - val_auc: 0.5064\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6428 - accuracy: 0.6488 - auc: 0.5534 - val_loss: 0.6425 - val_accuracy: 0.6500 - val_auc: 0.5600\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6426 - accuracy: 0.6488 - auc: 0.5286 - val_loss: 0.6358 - val_accuracy: 0.6500 - val_auc: 0.5574\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6289 - accuracy: 0.6488 - auc: 0.5618 - val_loss: 0.6257 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6240 - accuracy: 0.6488 - auc: 0.5555 - val_loss: 0.6262 - val_accuracy: 0.6500 - val_auc: 0.5611\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6133 - accuracy: 0.6488 - auc: 0.5985 - val_loss: 0.6262 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6157 - accuracy: 0.6525 - auc: 0.5815 - val_loss: 0.6311 - val_accuracy: 0.6500 - val_auc: 0.5675\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 60ms/step - loss: 0.6122 - accuracy: 0.6587 - auc: 0.5835 - val_loss: 0.6283 - val_accuracy: 0.6500 - val_auc: 0.5723\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 64ms/step - loss: 0.6061 - accuracy: 0.6662 - auc: 0.5750 - val_loss: 0.6276 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 87ms/step - loss: 0.6877 - accuracy: 0.6300 - auc: 0.4425 - val_loss: 0.6733 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 62ms/step - loss: 0.6663 - accuracy: 0.6488 - auc: 0.4686 - val_loss: 0.6558 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 59ms/step - loss: 0.6571 - accuracy: 0.6488 - auc: 0.4809 - val_loss: 0.6539 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6553 - accuracy: 0.6500 - auc: 0.4881 - val_loss: 0.6531 - val_accuracy: 0.6500 - val_auc: 0.4479\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6536 - accuracy: 0.6488 - auc: 0.4937 - val_loss: 0.6506 - val_accuracy: 0.6500 - val_auc: 0.4479\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 63ms/step - loss: 0.6496 - accuracy: 0.6488 - auc: 0.5181 - val_loss: 0.6486 - val_accuracy: 0.6500 - val_auc: 0.4769\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 61ms/step - loss: 0.6494 - accuracy: 0.6488 - auc: 0.5193 - val_loss: 0.6467 - val_accuracy: 0.6500 - val_auc: 0.5273\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 156ms/step - loss: 0.6824 - accuracy: 0.5975 - auc: 0.4941 - val_loss: 0.6625 - val_accuracy: 0.6500 - val_auc: 0.4457\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6627 - accuracy: 0.6488 - auc: 0.4682 - val_loss: 0.6556 - val_accuracy: 0.6500 - val_auc: 0.4448\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6529 - accuracy: 0.6488 - auc: 0.5035 - val_loss: 0.6526 - val_accuracy: 0.6500 - val_auc: 0.4455\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6540 - accuracy: 0.6488 - auc: 0.4910 - val_loss: 0.6502 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6439 - accuracy: 0.6488 - auc: 0.5567 - val_loss: 0.6482 - val_accuracy: 0.6500 - val_auc: 0.4824\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6477 - accuracy: 0.6488 - auc: 0.5277 - val_loss: 0.6449 - val_accuracy: 0.6500 - val_auc: 0.5411\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6482 - accuracy: 0.6475 - auc: 0.5089 - val_loss: 0.6409 - val_accuracy: 0.6500 - val_auc: 0.5440\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6356 - accuracy: 0.6488 - auc: 0.5588 - val_loss: 0.6340 - val_accuracy: 0.6500 - val_auc: 0.5580\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6245 - accuracy: 0.6488 - auc: 0.5681 - val_loss: 0.6314 - val_accuracy: 0.6500 - val_auc: 0.5609\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6218 - accuracy: 0.6612 - auc: 0.5545 - val_loss: 0.6315 - val_accuracy: 0.6500 - val_auc: 0.5622\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6180 - accuracy: 0.6675 - auc: 0.5608 - val_loss: 0.6255 - val_accuracy: 0.6500 - val_auc: 0.5477\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6096 - accuracy: 0.6687 - auc: 0.5889 - val_loss: 0.6304 - val_accuracy: 0.6500 - val_auc: 0.5743\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6031 - accuracy: 0.6687 - auc: 0.5893 - val_loss: 0.6245 - val_accuracy: 0.6500 - val_auc: 0.5618\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 151ms/step - loss: 0.6715 - accuracy: 0.6463 - auc: 0.4624 - val_loss: 0.6574 - val_accuracy: 0.6500 - val_auc: 0.4473\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6499 - accuracy: 0.6488 - auc: 0.5141 - val_loss: 0.6522 - val_accuracy: 0.6500 - val_auc: 0.4464\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6548 - accuracy: 0.6488 - auc: 0.4641 - val_loss: 0.6495 - val_accuracy: 0.6500 - val_auc: 0.4530\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6498 - accuracy: 0.6488 - auc: 0.5058 - val_loss: 0.6459 - val_accuracy: 0.6500 - val_auc: 0.5240\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6441 - accuracy: 0.6488 - auc: 0.5497 - val_loss: 0.6409 - val_accuracy: 0.6500 - val_auc: 0.5578\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6357 - accuracy: 0.6488 - auc: 0.5593 - val_loss: 0.6337 - val_accuracy: 0.6500 - val_auc: 0.5648\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6266 - accuracy: 0.6488 - auc: 0.5582 - val_loss: 0.6327 - val_accuracy: 0.6500 - val_auc: 0.5725\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6357 - accuracy: 0.6575 - auc: 0.5422 - val_loss: 0.6302 - val_accuracy: 0.6500 - val_auc: 0.5721\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6212 - accuracy: 0.6612 - auc: 0.5642 - val_loss: 0.6294 - val_accuracy: 0.6500 - val_auc: 0.5578\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6075 - accuracy: 0.6650 - auc: 0.5935 - val_loss: 0.6321 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6167 - accuracy: 0.6675 - auc: 0.5746 - val_loss: 0.6307 - val_accuracy: 0.6500 - val_auc: 0.5815\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 156ms/step - loss: 0.6754 - accuracy: 0.6375 - auc: 0.4658 - val_loss: 0.6565 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6600 - accuracy: 0.6488 - auc: 0.4523 - val_loss: 0.6536 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6522 - accuracy: 0.6488 - auc: 0.4931 - val_loss: 0.6505 - val_accuracy: 0.6500 - val_auc: 0.4468\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6534 - accuracy: 0.6488 - auc: 0.4821 - val_loss: 0.6480 - val_accuracy: 0.6500 - val_auc: 0.5292\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6446 - accuracy: 0.6488 - auc: 0.5513 - val_loss: 0.6445 - val_accuracy: 0.6500 - val_auc: 0.5244\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6451 - accuracy: 0.6488 - auc: 0.5318 - val_loss: 0.6387 - val_accuracy: 0.6500 - val_auc: 0.5587\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6350 - accuracy: 0.6488 - auc: 0.5498 - val_loss: 0.6311 - val_accuracy: 0.6500 - val_auc: 0.5725\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6317 - accuracy: 0.6500 - auc: 0.5479 - val_loss: 0.6293 - val_accuracy: 0.6500 - val_auc: 0.5618\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6202 - accuracy: 0.6587 - auc: 0.5583 - val_loss: 0.6244 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6161 - accuracy: 0.6600 - auc: 0.5712 - val_loss: 0.6279 - val_accuracy: 0.6500 - val_auc: 0.5582\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6123 - accuracy: 0.6650 - auc: 0.5689 - val_loss: 0.6273 - val_accuracy: 0.6500 - val_auc: 0.5734\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6066 - accuracy: 0.6675 - auc: 0.5870 - val_loss: 0.6321 - val_accuracy: 0.6500 - val_auc: 0.5622\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 155ms/step - loss: 0.6755 - accuracy: 0.6488 - auc: 0.4882 - val_loss: 0.6562 - val_accuracy: 0.6500 - val_auc: 0.4455\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6540 - accuracy: 0.6475 - auc: 0.5119 - val_loss: 0.6523 - val_accuracy: 0.6500 - val_auc: 0.4453\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6630 - accuracy: 0.6463 - auc: 0.4571 - val_loss: 0.6522 - val_accuracy: 0.6500 - val_auc: 0.4743\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6544 - accuracy: 0.6475 - auc: 0.5046 - val_loss: 0.6477 - val_accuracy: 0.6500 - val_auc: 0.5356\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6502 - accuracy: 0.6463 - auc: 0.5252 - val_loss: 0.6449 - val_accuracy: 0.6500 - val_auc: 0.5433\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6491 - accuracy: 0.6475 - auc: 0.5144 - val_loss: 0.6417 - val_accuracy: 0.6500 - val_auc: 0.5582\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6437 - accuracy: 0.6488 - auc: 0.5360 - val_loss: 0.6363 - val_accuracy: 0.6500 - val_auc: 0.5580\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6350 - accuracy: 0.6488 - auc: 0.5499 - val_loss: 0.6321 - val_accuracy: 0.6500 - val_auc: 0.5580\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6287 - accuracy: 0.6488 - auc: 0.5526 - val_loss: 0.6344 - val_accuracy: 0.6500 - val_auc: 0.5611\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6197 - accuracy: 0.6488 - auc: 0.5877 - val_loss: 0.6466 - val_accuracy: 0.6500 - val_auc: 0.5571\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6246 - accuracy: 0.6500 - auc: 0.5627 - val_loss: 0.6280 - val_accuracy: 0.6500 - val_auc: 0.5424\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6136 - accuracy: 0.6463 - auc: 0.5818 - val_loss: 0.6383 - val_accuracy: 0.6500 - val_auc: 0.5574\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6161 - accuracy: 0.6488 - auc: 0.5749 - val_loss: 0.6334 - val_accuracy: 0.6500 - val_auc: 0.5437\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 149ms/step - loss: 0.6715 - accuracy: 0.6438 - auc: 0.4815 - val_loss: 0.6559 - val_accuracy: 0.6500 - val_auc: 0.4431\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6591 - accuracy: 0.6513 - auc: 0.4882 - val_loss: 0.6533 - val_accuracy: 0.6500 - val_auc: 0.4457\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6539 - accuracy: 0.6488 - auc: 0.5094 - val_loss: 0.6518 - val_accuracy: 0.6500 - val_auc: 0.4444\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6588 - accuracy: 0.6488 - auc: 0.4731 - val_loss: 0.6497 - val_accuracy: 0.6500 - val_auc: 0.4444\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6501 - accuracy: 0.6488 - auc: 0.5270 - val_loss: 0.6474 - val_accuracy: 0.6500 - val_auc: 0.5233\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6472 - accuracy: 0.6488 - auc: 0.5384 - val_loss: 0.6448 - val_accuracy: 0.6500 - val_auc: 0.5523\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6479 - accuracy: 0.6488 - auc: 0.5176 - val_loss: 0.6423 - val_accuracy: 0.6500 - val_auc: 0.5576\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6428 - accuracy: 0.6488 - auc: 0.5442 - val_loss: 0.6360 - val_accuracy: 0.6500 - val_auc: 0.5576\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6310 - accuracy: 0.6488 - auc: 0.5467 - val_loss: 0.6380 - val_accuracy: 0.6500 - val_auc: 0.5609\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.6208 - accuracy: 0.6500 - auc: 0.5906 - val_loss: 0.6354 - val_accuracy: 0.6500 - val_auc: 0.5719\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6299 - accuracy: 0.6500 - auc: 0.5544 - val_loss: 0.6367 - val_accuracy: 0.6500 - val_auc: 0.5719\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 162ms/step - loss: 0.6831 - accuracy: 0.6263 - auc: 0.4679 - val_loss: 0.6650 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6672 - accuracy: 0.6438 - auc: 0.4843 - val_loss: 0.6556 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6680 - accuracy: 0.6388 - auc: 0.4678 - val_loss: 0.6591 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.6586 - accuracy: 0.6475 - auc: 0.5011 - val_loss: 0.6540 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6585 - accuracy: 0.6475 - auc: 0.4985 - val_loss: 0.6505 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6569 - accuracy: 0.6475 - auc: 0.4970 - val_loss: 0.6488 - val_accuracy: 0.6500 - val_auc: 0.5215\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.6495 - accuracy: 0.6488 - auc: 0.5373 - val_loss: 0.6461 - val_accuracy: 0.6500 - val_auc: 0.5380\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6571 - accuracy: 0.6488 - auc: 0.4860 - val_loss: 0.6438 - val_accuracy: 0.6500 - val_auc: 0.5501\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6485 - accuracy: 0.6488 - auc: 0.5061 - val_loss: 0.6373 - val_accuracy: 0.6500 - val_auc: 0.5600\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6343 - accuracy: 0.6488 - auc: 0.5427 - val_loss: 0.6348 - val_accuracy: 0.6500 - val_auc: 0.5609\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6300 - accuracy: 0.6538 - auc: 0.5660 - val_loss: 0.6302 - val_accuracy: 0.6500 - val_auc: 0.5536\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.6214 - accuracy: 0.6550 - auc: 0.5743 - val_loss: 0.6211 - val_accuracy: 0.6500 - val_auc: 0.5516\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 107ms/step - loss: 0.6097 - accuracy: 0.6625 - auc: 0.5707 - val_loss: 0.6191 - val_accuracy: 0.6400 - val_auc: 0.5262\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.6232 - accuracy: 0.6650 - auc: 0.5974 - val_loss: 0.6372 - val_accuracy: 0.6400 - val_auc: 0.5422\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6158 - accuracy: 0.6700 - auc: 0.5780 - val_loss: 0.6479 - val_accuracy: 0.6300 - val_auc: 0.5244\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.6103 - accuracy: 0.6687 - auc: 0.5627 - val_loss: 0.6514 - val_accuracy: 0.6300 - val_auc: 0.5462\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.6116 - accuracy: 0.6700 - auc: 0.5470 - val_loss: 0.6437 - val_accuracy: 0.6300 - val_auc: 0.5534\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 1s 110ms/step - loss: 0.6107 - accuracy: 0.6687 - auc: 0.5634 - val_loss: 0.6349 - val_accuracy: 0.6400 - val_auc: 0.5534\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 158ms/step - loss: 0.6744 - accuracy: 0.6350 - auc: 0.4757 - val_loss: 0.6517 - val_accuracy: 0.6500 - val_auc: 0.6257\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: 0.6327 - accuracy: 0.6488 - auc: 0.6160 - val_loss: 0.5945 - val_accuracy: 0.6500 - val_auc: 0.8987\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.4827 - accuracy: 0.7625 - auc: 0.8870 - val_loss: 0.4925 - val_accuracy: 0.8900 - val_auc: 0.9409\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.3260 - accuracy: 0.9125 - auc: 0.9555 - val_loss: 0.3474 - val_accuracy: 0.8700 - val_auc: 0.9499\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 123ms/step - loss: 0.1940 - accuracy: 0.9375 - auc: 0.9784 - val_loss: 0.3179 - val_accuracy: 0.8700 - val_auc: 0.9534\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.1416 - accuracy: 0.9600 - auc: 0.9888 - val_loss: 0.7592 - val_accuracy: 0.8300 - val_auc: 0.8848\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 0.0950 - accuracy: 0.9762 - auc: 0.9917 - val_loss: 0.3374 - val_accuracy: 0.8600 - val_auc: 0.9347\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.0368 - accuracy: 0.9925 - auc: 0.9992 - val_loss: 0.6419 - val_accuracy: 0.8500 - val_auc: 0.8993\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.0177 - accuracy: 0.9937 - auc: 0.9999 - val_loss: 0.6114 - val_accuracy: 0.8600 - val_auc: 0.8974\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: 0.0078 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.7787 - val_accuracy: 0.8500 - val_auc: 0.8884\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 181ms/step - loss: 0.6784 - accuracy: 0.6400 - auc: 0.4650 - val_loss: 0.6531 - val_accuracy: 0.6500 - val_auc: 0.6215\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 0.6363 - accuracy: 0.6488 - auc: 0.5949 - val_loss: 0.6157 - val_accuracy: 0.6500 - val_auc: 0.8582\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.5453 - accuracy: 0.6637 - auc: 0.8668 - val_loss: 0.5396 - val_accuracy: 0.7400 - val_auc: 0.9332\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: 0.4375 - accuracy: 0.8737 - auc: 0.9527 - val_loss: 0.5311 - val_accuracy: 0.7400 - val_auc: 0.9543\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.2623 - accuracy: 0.9200 - auc: 0.9652 - val_loss: 0.3769 - val_accuracy: 0.8700 - val_auc: 0.9591\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.1056 - accuracy: 0.9725 - auc: 0.9893 - val_loss: 0.5091 - val_accuracy: 0.8600 - val_auc: 0.9345\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.0489 - accuracy: 0.9887 - auc: 0.9962 - val_loss: 0.6404 - val_accuracy: 0.8200 - val_auc: 0.9007\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.0203 - accuracy: 0.9950 - auc: 0.9997 - val_loss: 0.4676 - val_accuracy: 0.8500 - val_auc: 0.9207\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.0130 - accuracy: 0.9975 - auc: 0.9999 - val_loss: 1.1713 - val_accuracy: 0.7900 - val_auc: 0.8290\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 123ms/step - loss: 0.0040 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.6430 - val_accuracy: 0.8500 - val_auc: 0.8910\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 159ms/step - loss: 0.6728 - accuracy: 0.6475 - auc: 0.4674 - val_loss: 0.6503 - val_accuracy: 0.6500 - val_auc: 0.6495\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.6268 - accuracy: 0.6488 - auc: 0.6404 - val_loss: 0.5597 - val_accuracy: 0.6500 - val_auc: 0.9070\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 121ms/step - loss: 0.4624 - accuracy: 0.7812 - auc: 0.8965 - val_loss: 0.4791 - val_accuracy: 0.8800 - val_auc: 0.9299\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.3852 - accuracy: 0.9137 - auc: 0.9334 - val_loss: 0.4224 - val_accuracy: 0.8400 - val_auc: 0.9297\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.2360 - accuracy: 0.9438 - auc: 0.9803 - val_loss: 0.3681 - val_accuracy: 0.8300 - val_auc: 0.9400\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 0.1242 - accuracy: 0.9588 - auc: 0.9863 - val_loss: 0.4930 - val_accuracy: 0.8200 - val_auc: 0.9488\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.0477 - accuracy: 0.9887 - auc: 0.9988 - val_loss: 0.6968 - val_accuracy: 0.8000 - val_auc: 0.9110\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.0244 - accuracy: 0.9950 - auc: 0.9992 - val_loss: 0.4742 - val_accuracy: 0.8800 - val_auc: 0.9420\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.0107 - accuracy: 0.9962 - auc: 1.0000 - val_loss: 0.8690 - val_accuracy: 0.8500 - val_auc: 0.8679\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.0060 - accuracy: 1.0000 - auc: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.8700 - val_auc: 0.9295\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 173ms/step - loss: 0.6787 - accuracy: 0.6400 - auc: 0.4779 - val_loss: 0.6573 - val_accuracy: 0.6500 - val_auc: 0.6127\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 133ms/step - loss: 0.6584 - accuracy: 0.6488 - auc: 0.4779 - val_loss: 0.6375 - val_accuracy: 0.6500 - val_auc: 0.7479\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.5883 - accuracy: 0.6513 - auc: 0.7454 - val_loss: 0.5205 - val_accuracy: 0.6500 - val_auc: 0.9308\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 0.4489 - accuracy: 0.7588 - auc: 0.9179 - val_loss: 0.4142 - val_accuracy: 0.8300 - val_auc: 0.9426\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 0.3200 - accuracy: 0.9200 - auc: 0.9708 - val_loss: 0.6593 - val_accuracy: 0.7500 - val_auc: 0.9273\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.2248 - accuracy: 0.9287 - auc: 0.9657 - val_loss: 0.4348 - val_accuracy: 0.8700 - val_auc: 0.9398\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 130ms/step - loss: 0.1236 - accuracy: 0.9663 - auc: 0.9892 - val_loss: 0.3556 - val_accuracy: 0.8500 - val_auc: 0.9235\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.1018 - accuracy: 0.9737 - auc: 0.9937 - val_loss: 0.7375 - val_accuracy: 0.8500 - val_auc: 0.8820\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 0.0543 - accuracy: 0.9887 - auc: 0.9968 - val_loss: 0.7718 - val_accuracy: 0.8700 - val_auc: 0.8640\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 125ms/step - loss: 0.0334 - accuracy: 0.9950 - auc: 0.9988 - val_loss: 0.7954 - val_accuracy: 0.8600 - val_auc: 0.8510\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 127ms/step - loss: 0.0239 - accuracy: 0.9912 - auc: 0.9996 - val_loss: 1.0304 - val_accuracy: 0.8400 - val_auc: 0.8281\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 0.0115 - accuracy: 0.9962 - auc: 1.0000 - val_loss: 1.0731 - val_accuracy: 0.8800 - val_auc: 0.8442\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 170ms/step - loss: 0.6897 - accuracy: 0.5863 - auc: 0.4653 - val_loss: 0.6774 - val_accuracy: 0.6500 - val_auc: 0.5066\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 0.6679 - accuracy: 0.6375 - auc: 0.4969 - val_loss: 0.6417 - val_accuracy: 0.6500 - val_auc: 0.7380\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 128ms/step - loss: 0.6275 - accuracy: 0.6300 - auc: 0.6328 - val_loss: 0.5825 - val_accuracy: 0.6500 - val_auc: 0.9319\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 122ms/step - loss: 0.5205 - accuracy: 0.7200 - auc: 0.8687 - val_loss: 0.4321 - val_accuracy: 0.8700 - val_auc: 0.9431\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 126ms/step - loss: 0.3786 - accuracy: 0.9075 - auc: 0.9447 - val_loss: 0.3053 - val_accuracy: 0.9000 - val_auc: 0.9543\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.2106 - accuracy: 0.9375 - auc: 0.9678 - val_loss: 0.3196 - val_accuracy: 0.8600 - val_auc: 0.9490\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 124ms/step - loss: 0.1213 - accuracy: 0.9675 - auc: 0.9889 - val_loss: 0.3711 - val_accuracy: 0.8300 - val_auc: 0.9284\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.0687 - accuracy: 0.9887 - auc: 0.9950 - val_loss: 0.7334 - val_accuracy: 0.8200 - val_auc: 0.9119\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.0333 - accuracy: 0.9962 - auc: 0.9990 - val_loss: 0.7417 - val_accuracy: 0.8200 - val_auc: 0.8622\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0247 - accuracy: 0.9937 - auc: 0.9995 - val_loss: 0.6803 - val_accuracy: 0.8500 - val_auc: 0.8705\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 161ms/step - loss: 0.6790 - accuracy: 0.6237 - auc: 0.4919 - val_loss: 0.6561 - val_accuracy: 0.6500 - val_auc: 0.6141\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.6502 - accuracy: 0.6475 - auc: 0.5324 - val_loss: 0.6371 - val_accuracy: 0.6500 - val_auc: 0.7413\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6000 - accuracy: 0.6513 - auc: 0.7236 - val_loss: 0.5817 - val_accuracy: 0.6500 - val_auc: 0.9167\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 109ms/step - loss: 0.5016 - accuracy: 0.7275 - auc: 0.8791 - val_loss: 0.4233 - val_accuracy: 0.8000 - val_auc: 0.9431\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.3170 - accuracy: 0.9050 - auc: 0.9473 - val_loss: 0.3356 - val_accuracy: 0.8700 - val_auc: 0.9424\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 112ms/step - loss: 0.1895 - accuracy: 0.9413 - auc: 0.9774 - val_loss: 0.7277 - val_accuracy: 0.8000 - val_auc: 0.9196\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.1072 - accuracy: 0.9650 - auc: 0.9916 - val_loss: 0.5247 - val_accuracy: 0.8400 - val_auc: 0.9196\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 108ms/step - loss: 0.0504 - accuracy: 0.9825 - auc: 0.9983 - val_loss: 0.5058 - val_accuracy: 0.8600 - val_auc: 0.9336\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0351 - accuracy: 0.9937 - auc: 0.9972 - val_loss: 0.7919 - val_accuracy: 0.8500 - val_auc: 0.8501\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 111ms/step - loss: 0.0198 - accuracy: 0.9950 - auc: 0.9994 - val_loss: 0.9640 - val_accuracy: 0.8200 - val_auc: 0.8418\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 8s 286ms/step - loss: 0.6765 - accuracy: 0.6475 - auc: 0.4696 - val_loss: 0.6509 - val_accuracy: 0.6500 - val_auc: 0.6549\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 3s 193ms/step - loss: 0.6388 - accuracy: 0.6488 - auc: 0.5798 - val_loss: 0.6038 - val_accuracy: 0.6500 - val_auc: 0.8435\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 174ms/step - loss: 0.4921 - accuracy: 0.7700 - auc: 0.8720 - val_loss: 0.4569 - val_accuracy: 0.8700 - val_auc: 0.9220\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 165ms/step - loss: 0.3546 - accuracy: 0.8950 - auc: 0.9371 - val_loss: 0.3110 - val_accuracy: 0.8600 - val_auc: 0.9442\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.2223 - accuracy: 0.9362 - auc: 0.9640 - val_loss: 0.5910 - val_accuracy: 0.7900 - val_auc: 0.9310\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.1274 - accuracy: 0.9638 - auc: 0.9869 - val_loss: 0.6920 - val_accuracy: 0.8100 - val_auc: 0.9099\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 173ms/step - loss: 0.0623 - accuracy: 0.9887 - auc: 0.9954 - val_loss: 0.5138 - val_accuracy: 0.8700 - val_auc: 0.9301\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 168ms/step - loss: 0.0365 - accuracy: 0.9925 - auc: 0.9981 - val_loss: 0.9641 - val_accuracy: 0.8100 - val_auc: 0.8226\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 163ms/step - loss: 0.0639 - accuracy: 0.9900 - auc: 0.9921 - val_loss: 0.6788 - val_accuracy: 0.8400 - val_auc: 0.8892\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 263ms/step - loss: 0.6784 - accuracy: 0.6463 - auc: 0.4534 - val_loss: 0.6505 - val_accuracy: 0.6500 - val_auc: 0.6301\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 184ms/step - loss: 0.6389 - accuracy: 0.6488 - auc: 0.5810 - val_loss: 0.6040 - val_accuracy: 0.6500 - val_auc: 0.8530\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.4768 - accuracy: 0.7437 - auc: 0.9062 - val_loss: 0.4204 - val_accuracy: 0.8400 - val_auc: 0.9187\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.2777 - accuracy: 0.9262 - auc: 0.9639 - val_loss: 0.4614 - val_accuracy: 0.8500 - val_auc: 0.9042\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.1706 - accuracy: 0.9600 - auc: 0.9684 - val_loss: 0.5875 - val_accuracy: 0.8200 - val_auc: 0.9024\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.1209 - accuracy: 0.9650 - auc: 0.9871 - val_loss: 0.9157 - val_accuracy: 0.7700 - val_auc: 0.8613\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1089 - accuracy: 0.9638 - auc: 0.9920 - val_loss: 0.7828 - val_accuracy: 0.7900 - val_auc: 0.8848\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 194ms/step - loss: 0.0599 - accuracy: 0.9862 - auc: 0.9976 - val_loss: 0.4457 - val_accuracy: 0.8700 - val_auc: 0.9178\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 262ms/step - loss: 0.6720 - accuracy: 0.6375 - auc: 0.4880 - val_loss: 0.6507 - val_accuracy: 0.6500 - val_auc: 0.6644\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.6300 - accuracy: 0.6488 - auc: 0.6227 - val_loss: 0.5876 - val_accuracy: 0.6500 - val_auc: 0.8813\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.4399 - accuracy: 0.7788 - auc: 0.9062 - val_loss: 0.3464 - val_accuracy: 0.8700 - val_auc: 0.9288\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.2041 - accuracy: 0.9475 - auc: 0.9632 - val_loss: 0.2875 - val_accuracy: 0.8800 - val_auc: 0.9571\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1139 - accuracy: 0.9725 - auc: 0.9815 - val_loss: 0.6761 - val_accuracy: 0.8400 - val_auc: 0.9180\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 194ms/step - loss: 0.0921 - accuracy: 0.9762 - auc: 0.9879 - val_loss: 0.4659 - val_accuracy: 0.8500 - val_auc: 0.9426\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.0550 - accuracy: 0.9850 - auc: 0.9966 - val_loss: 0.4561 - val_accuracy: 0.8400 - val_auc: 0.9389\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.0421 - accuracy: 0.9912 - auc: 0.9961 - val_loss: 0.6921 - val_accuracy: 0.8300 - val_auc: 0.8974\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.0252 - accuracy: 0.9950 - auc: 0.9982 - val_loss: 0.4580 - val_accuracy: 0.8900 - val_auc: 0.9211\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 259ms/step - loss: 0.6763 - accuracy: 0.6288 - auc: 0.4828 - val_loss: 0.6536 - val_accuracy: 0.6500 - val_auc: 0.6127\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 180ms/step - loss: 0.6569 - accuracy: 0.6400 - auc: 0.5009 - val_loss: 0.6358 - val_accuracy: 0.6500 - val_auc: 0.7574\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 177ms/step - loss: 0.5997 - accuracy: 0.6500 - auc: 0.7077 - val_loss: 0.4997 - val_accuracy: 0.6500 - val_auc: 0.9156\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 182ms/step - loss: 0.4767 - accuracy: 0.6888 - auc: 0.8798 - val_loss: 0.4960 - val_accuracy: 0.6600 - val_auc: 0.9229\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 179ms/step - loss: 0.3664 - accuracy: 0.7513 - auc: 0.9439 - val_loss: 0.5860 - val_accuracy: 0.7900 - val_auc: 0.9354\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 187ms/step - loss: 0.3192 - accuracy: 0.8537 - auc: 0.9523 - val_loss: 0.4736 - val_accuracy: 0.8700 - val_auc: 0.9121\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 0.2928 - accuracy: 0.8800 - auc: 0.9752 - val_loss: 0.4883 - val_accuracy: 0.8800 - val_auc: 0.9105\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 181ms/step - loss: 0.2704 - accuracy: 0.8888 - auc: 0.9702 - val_loss: 0.9483 - val_accuracy: 0.8000 - val_auc: 0.8275\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.2395 - accuracy: 0.8975 - auc: 0.9823 - val_loss: 0.4671 - val_accuracy: 0.8300 - val_auc: 0.8930\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.1927 - accuracy: 0.9125 - auc: 0.9853 - val_loss: 0.5806 - val_accuracy: 0.8400 - val_auc: 0.8629\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.1419 - accuracy: 0.9425 - auc: 0.9878 - val_loss: 0.6744 - val_accuracy: 0.8500 - val_auc: 0.8695\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 7s 258ms/step - loss: 0.6775 - accuracy: 0.6488 - auc: 0.4693 - val_loss: 0.6537 - val_accuracy: 0.6500 - val_auc: 0.5642\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 191ms/step - loss: 0.6514 - accuracy: 0.6488 - auc: 0.5305 - val_loss: 0.6291 - val_accuracy: 0.6500 - val_auc: 0.8347\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.5652 - accuracy: 0.6488 - auc: 0.7845 - val_loss: 0.5328 - val_accuracy: 0.6500 - val_auc: 0.9068\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.4441 - accuracy: 0.6488 - auc: 0.9231 - val_loss: 0.4301 - val_accuracy: 0.6500 - val_auc: 0.9404\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.3467 - accuracy: 0.6538 - auc: 0.9698 - val_loss: 0.6868 - val_accuracy: 0.7100 - val_auc: 0.9547\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 183ms/step - loss: 0.3279 - accuracy: 0.9013 - auc: 0.9649 - val_loss: 0.4957 - val_accuracy: 0.8700 - val_auc: 0.9400\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 185ms/step - loss: 0.3135 - accuracy: 0.9575 - auc: 0.9687 - val_loss: 0.5002 - val_accuracy: 0.8200 - val_auc: 0.9521\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 188ms/step - loss: 0.2548 - accuracy: 0.9450 - auc: 0.9851 - val_loss: 0.8067 - val_accuracy: 0.8300 - val_auc: 0.8958\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 186ms/step - loss: 0.1962 - accuracy: 0.9700 - auc: 0.9874 - val_loss: 0.7368 - val_accuracy: 0.8600 - val_auc: 0.8862\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 8s 265ms/step - loss: 0.6835 - accuracy: 0.6263 - auc: 0.4767 - val_loss: 0.6579 - val_accuracy: 0.6500 - val_auc: 0.5947\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.6579 - accuracy: 0.6225 - auc: 0.5162 - val_loss: 0.6240 - val_accuracy: 0.6500 - val_auc: 0.8268\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.5917 - accuracy: 0.7312 - auc: 0.7495 - val_loss: 0.4990 - val_accuracy: 0.8000 - val_auc: 0.8409\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 189ms/step - loss: 0.4237 - accuracy: 0.8750 - auc: 0.9086 - val_loss: 0.3422 - val_accuracy: 0.8900 - val_auc: 0.9510\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 191ms/step - loss: 0.4124 - accuracy: 0.8825 - auc: 0.8821 - val_loss: 0.4516 - val_accuracy: 0.8000 - val_auc: 0.9229\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 3s 196ms/step - loss: 0.2750 - accuracy: 0.9337 - auc: 0.9637 - val_loss: 0.5456 - val_accuracy: 0.7900 - val_auc: 0.9090\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 191ms/step - loss: 0.2009 - accuracy: 0.9513 - auc: 0.9824 - val_loss: 0.4305 - val_accuracy: 0.8600 - val_auc: 0.9097\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 190ms/step - loss: 0.1538 - accuracy: 0.9638 - auc: 0.9803 - val_loss: 0.4224 - val_accuracy: 0.8800 - val_auc: 0.9147\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 3s 197ms/step - loss: 0.1211 - accuracy: 0.9663 - auc: 0.9924 - val_loss: 0.4439 - val_accuracy: 0.8800 - val_auc: 0.9130\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 96ms/step - loss: 0.6851 - accuracy: 0.5938 - auc: 0.4620 - val_loss: 0.6634 - val_accuracy: 0.6500 - val_auc: 0.4413\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.6616 - accuracy: 0.6488 - auc: 0.4618 - val_loss: 0.6556 - val_accuracy: 0.6500 - val_auc: 0.4440\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6544 - accuracy: 0.6488 - auc: 0.4711 - val_loss: 0.6534 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.6534 - accuracy: 0.6488 - auc: 0.4802 - val_loss: 0.6489 - val_accuracy: 0.6500 - val_auc: 0.4607\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6464 - accuracy: 0.6488 - auc: 0.5302 - val_loss: 0.6450 - val_accuracy: 0.6500 - val_auc: 0.5286\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6434 - accuracy: 0.6488 - auc: 0.5408 - val_loss: 0.6370 - val_accuracy: 0.6500 - val_auc: 0.5385\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6404 - accuracy: 0.6488 - auc: 0.5937 - val_loss: 0.6462 - val_accuracy: 0.6500 - val_auc: 0.5842\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6490 - accuracy: 0.6488 - auc: 0.5599 - val_loss: 0.6511 - val_accuracy: 0.6500 - val_auc: 0.5578\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6418 - accuracy: 0.6488 - auc: 0.5527 - val_loss: 0.6393 - val_accuracy: 0.6500 - val_auc: 0.5655\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6295 - accuracy: 0.6488 - auc: 0.5939 - val_loss: 0.6350 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6206 - accuracy: 0.6488 - auc: 0.6037 - val_loss: 0.6292 - val_accuracy: 0.6500 - val_auc: 0.5618\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 93ms/step - loss: 0.6833 - accuracy: 0.6175 - auc: 0.4523 - val_loss: 0.6613 - val_accuracy: 0.6500 - val_auc: 0.4607\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6610 - accuracy: 0.6488 - auc: 0.4474 - val_loss: 0.6548 - val_accuracy: 0.6500 - val_auc: 0.4435\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6597 - accuracy: 0.6488 - auc: 0.4365 - val_loss: 0.6539 - val_accuracy: 0.6500 - val_auc: 0.4470\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6528 - accuracy: 0.6488 - auc: 0.4928 - val_loss: 0.6483 - val_accuracy: 0.6500 - val_auc: 0.4752\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6498 - accuracy: 0.6488 - auc: 0.5013 - val_loss: 0.6439 - val_accuracy: 0.6500 - val_auc: 0.5459\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6422 - accuracy: 0.6488 - auc: 0.5525 - val_loss: 0.6379 - val_accuracy: 0.6500 - val_auc: 0.5596\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6377 - accuracy: 0.6488 - auc: 0.5408 - val_loss: 0.6308 - val_accuracy: 0.6500 - val_auc: 0.6123\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6230 - accuracy: 0.6488 - auc: 0.5562 - val_loss: 0.6279 - val_accuracy: 0.6500 - val_auc: 0.5503\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6196 - accuracy: 0.6513 - auc: 0.5892 - val_loss: 0.6224 - val_accuracy: 0.6500 - val_auc: 0.5664\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6027 - accuracy: 0.6538 - auc: 0.6175 - val_loss: 0.6172 - val_accuracy: 0.6500 - val_auc: 0.5525\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6123 - accuracy: 0.6662 - auc: 0.5618 - val_loss: 0.6130 - val_accuracy: 0.6500 - val_auc: 0.5565\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5926 - accuracy: 0.6675 - auc: 0.6514 - val_loss: 0.6121 - val_accuracy: 0.6500 - val_auc: 0.5497\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6077 - accuracy: 0.6687 - auc: 0.5886 - val_loss: 0.6134 - val_accuracy: 0.6500 - val_auc: 0.5793\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.5969 - accuracy: 0.6687 - auc: 0.5894 - val_loss: 0.6043 - val_accuracy: 0.6500 - val_auc: 0.5824\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5794 - accuracy: 0.6700 - auc: 0.6616 - val_loss: 0.6151 - val_accuracy: 0.6500 - val_auc: 0.5771\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6041 - accuracy: 0.6712 - auc: 0.5922 - val_loss: 0.6222 - val_accuracy: 0.6600 - val_auc: 0.5655\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5936 - accuracy: 0.6712 - auc: 0.5821 - val_loss: 0.6064 - val_accuracy: 0.6500 - val_auc: 0.6114\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5744 - accuracy: 0.6787 - auc: 0.6293 - val_loss: 0.5300 - val_accuracy: 0.7400 - val_auc: 0.6818\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5520 - accuracy: 0.6875 - auc: 0.6781 - val_loss: 0.6096 - val_accuracy: 0.6500 - val_auc: 0.5930\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5885 - accuracy: 0.6687 - auc: 0.6233 - val_loss: 0.6096 - val_accuracy: 0.6500 - val_auc: 0.5771\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5894 - accuracy: 0.6700 - auc: 0.6026 - val_loss: 0.6037 - val_accuracy: 0.6500 - val_auc: 0.5793\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5734 - accuracy: 0.6700 - auc: 0.6456 - val_loss: 0.6657 - val_accuracy: 0.6500 - val_auc: 0.6974\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.5793 - accuracy: 0.6700 - auc: 0.6207 - val_loss: 0.6113 - val_accuracy: 0.6500 - val_auc: 0.5767\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 96ms/step - loss: 0.6833 - accuracy: 0.6150 - auc: 0.4576 - val_loss: 0.6625 - val_accuracy: 0.6500 - val_auc: 0.4330\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6596 - accuracy: 0.6488 - auc: 0.4725 - val_loss: 0.6552 - val_accuracy: 0.6500 - val_auc: 0.4448\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6565 - accuracy: 0.6488 - auc: 0.4713 - val_loss: 0.6533 - val_accuracy: 0.6500 - val_auc: 0.4475\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6537 - accuracy: 0.6488 - auc: 0.4759 - val_loss: 0.6486 - val_accuracy: 0.6500 - val_auc: 0.4833\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6450 - accuracy: 0.6488 - auc: 0.5478 - val_loss: 0.6449 - val_accuracy: 0.6500 - val_auc: 0.5176\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6402 - accuracy: 0.6488 - auc: 0.5680 - val_loss: 0.6393 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6355 - accuracy: 0.6488 - auc: 0.5440 - val_loss: 0.6290 - val_accuracy: 0.6500 - val_auc: 0.5587\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6272 - accuracy: 0.6488 - auc: 0.5594 - val_loss: 0.6350 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6295 - accuracy: 0.6562 - auc: 0.5727 - val_loss: 0.6345 - val_accuracy: 0.6500 - val_auc: 0.5316\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6190 - accuracy: 0.6600 - auc: 0.5863 - val_loss: 0.6254 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6084 - accuracy: 0.6625 - auc: 0.5761 - val_loss: 0.6272 - val_accuracy: 0.6500 - val_auc: 0.5809\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6007 - accuracy: 0.6650 - auc: 0.5839 - val_loss: 0.6134 - val_accuracy: 0.6500 - val_auc: 0.5560\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6010 - accuracy: 0.6687 - auc: 0.5703 - val_loss: 0.6654 - val_accuracy: 0.6500 - val_auc: 0.6147\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6292 - accuracy: 0.6675 - auc: 0.5906 - val_loss: 0.6412 - val_accuracy: 0.6500 - val_auc: 0.5611\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 66ms/step - loss: 0.6135 - accuracy: 0.6687 - auc: 0.5883 - val_loss: 0.6289 - val_accuracy: 0.6400 - val_auc: 0.5466\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6039 - accuracy: 0.6687 - auc: 0.5710 - val_loss: 0.6231 - val_accuracy: 0.6500 - val_auc: 0.5714\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.5935 - accuracy: 0.6700 - auc: 0.5930 - val_loss: 0.6105 - val_accuracy: 0.6500 - val_auc: 0.5495\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 97ms/step - loss: 0.6796 - accuracy: 0.6463 - auc: 0.4439 - val_loss: 0.6598 - val_accuracy: 0.6500 - val_auc: 0.4418\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6574 - accuracy: 0.6488 - auc: 0.4848 - val_loss: 0.6553 - val_accuracy: 0.6500 - val_auc: 0.4444\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6579 - accuracy: 0.6488 - auc: 0.4505 - val_loss: 0.6540 - val_accuracy: 0.6500 - val_auc: 0.4321\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6551 - accuracy: 0.6488 - auc: 0.4773 - val_loss: 0.6491 - val_accuracy: 0.6500 - val_auc: 0.4598\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.6516 - accuracy: 0.6488 - auc: 0.4923 - val_loss: 0.6452 - val_accuracy: 0.6500 - val_auc: 0.5600\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6410 - accuracy: 0.6488 - auc: 0.5492 - val_loss: 0.6302 - val_accuracy: 0.6500 - val_auc: 0.5791\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6356 - accuracy: 0.6488 - auc: 0.5397 - val_loss: 0.6295 - val_accuracy: 0.6500 - val_auc: 0.5620\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.6272 - accuracy: 0.6488 - auc: 0.5633 - val_loss: 0.6247 - val_accuracy: 0.6500 - val_auc: 0.5398\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6121 - accuracy: 0.6488 - auc: 0.5775 - val_loss: 0.6371 - val_accuracy: 0.6500 - val_auc: 0.5879\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6051 - accuracy: 0.6488 - auc: 0.5786 - val_loss: 0.6058 - val_accuracy: 0.6500 - val_auc: 0.5497\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6002 - accuracy: 0.6488 - auc: 0.6351 - val_loss: 0.6368 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6190 - accuracy: 0.6488 - auc: 0.5907 - val_loss: 0.6242 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6051 - accuracy: 0.6488 - auc: 0.6278 - val_loss: 0.6196 - val_accuracy: 0.6500 - val_auc: 0.5624\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6075 - accuracy: 0.6488 - auc: 0.5712 - val_loss: 0.6226 - val_accuracy: 0.6500 - val_auc: 0.5640\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6046 - accuracy: 0.6488 - auc: 0.5862 - val_loss: 0.6309 - val_accuracy: 0.6500 - val_auc: 0.5525\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 95ms/step - loss: 0.6860 - accuracy: 0.6150 - auc: 0.4613 - val_loss: 0.6680 - val_accuracy: 0.6500 - val_auc: 0.4448\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6626 - accuracy: 0.6488 - auc: 0.4931 - val_loss: 0.6565 - val_accuracy: 0.6500 - val_auc: 0.4321\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6579 - accuracy: 0.6488 - auc: 0.4844 - val_loss: 0.6557 - val_accuracy: 0.6500 - val_auc: 0.4457\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6582 - accuracy: 0.6475 - auc: 0.4754 - val_loss: 0.6516 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6498 - accuracy: 0.6488 - auc: 0.5153 - val_loss: 0.6487 - val_accuracy: 0.6500 - val_auc: 0.4888\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 71ms/step - loss: 0.6454 - accuracy: 0.6488 - auc: 0.5555 - val_loss: 0.6456 - val_accuracy: 0.6500 - val_auc: 0.5264\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6408 - accuracy: 0.6488 - auc: 0.5653 - val_loss: 0.6391 - val_accuracy: 0.6500 - val_auc: 0.5536\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6304 - accuracy: 0.6488 - auc: 0.5731 - val_loss: 0.6269 - val_accuracy: 0.6500 - val_auc: 0.5624\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6279 - accuracy: 0.6488 - auc: 0.5531 - val_loss: 0.6211 - val_accuracy: 0.6500 - val_auc: 0.5857\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6104 - accuracy: 0.6488 - auc: 0.6127 - val_loss: 0.6378 - val_accuracy: 0.6500 - val_auc: 0.5255\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6284 - accuracy: 0.6525 - auc: 0.5645 - val_loss: 0.6356 - val_accuracy: 0.6500 - val_auc: 0.5257\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6152 - accuracy: 0.6562 - auc: 0.6009 - val_loss: 0.6268 - val_accuracy: 0.6500 - val_auc: 0.5413\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 70ms/step - loss: 0.6055 - accuracy: 0.6637 - auc: 0.6189 - val_loss: 0.6210 - val_accuracy: 0.6500 - val_auc: 0.5521\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 3s 96ms/step - loss: 0.6814 - accuracy: 0.6450 - auc: 0.4706 - val_loss: 0.6644 - val_accuracy: 0.6500 - val_auc: 0.4299\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6637 - accuracy: 0.6488 - auc: 0.4452 - val_loss: 0.6561 - val_accuracy: 0.6500 - val_auc: 0.4442\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6561 - accuracy: 0.6488 - auc: 0.4796 - val_loss: 0.6537 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6497 - accuracy: 0.6488 - auc: 0.5154 - val_loss: 0.6501 - val_accuracy: 0.6500 - val_auc: 0.4303\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6518 - accuracy: 0.6488 - auc: 0.4958 - val_loss: 0.6471 - val_accuracy: 0.6500 - val_auc: 0.5334\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6455 - accuracy: 0.6488 - auc: 0.5419 - val_loss: 0.6390 - val_accuracy: 0.6500 - val_auc: 0.5615\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6361 - accuracy: 0.6488 - auc: 0.5883 - val_loss: 0.6386 - val_accuracy: 0.6500 - val_auc: 0.5620\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6385 - accuracy: 0.6488 - auc: 0.5633 - val_loss: 0.6360 - val_accuracy: 0.6500 - val_auc: 0.5727\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6275 - accuracy: 0.6488 - auc: 0.5758 - val_loss: 0.6284 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6151 - accuracy: 0.6488 - auc: 0.6005 - val_loss: 0.6255 - val_accuracy: 0.6500 - val_auc: 0.5622\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6107 - accuracy: 0.6488 - auc: 0.5638 - val_loss: 0.6258 - val_accuracy: 0.6500 - val_auc: 0.5684\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6038 - accuracy: 0.6488 - auc: 0.5967 - val_loss: 0.6128 - val_accuracy: 0.6500 - val_auc: 0.5881\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6037 - accuracy: 0.6500 - auc: 0.6028 - val_loss: 0.6150 - val_accuracy: 0.6500 - val_auc: 0.5868\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 1s 69ms/step - loss: 0.6007 - accuracy: 0.6587 - auc: 0.5956 - val_loss: 0.6384 - val_accuracy: 0.6500 - val_auc: 0.5543\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6047 - accuracy: 0.6637 - auc: 0.5949 - val_loss: 0.6271 - val_accuracy: 0.6500 - val_auc: 0.5510\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 1s 68ms/step - loss: 0.6078 - accuracy: 0.6625 - auc: 0.5861 - val_loss: 0.6256 - val_accuracy: 0.6500 - val_auc: 0.5510\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 67ms/step - loss: 0.6003 - accuracy: 0.6687 - auc: 0.6221 - val_loss: 0.6223 - val_accuracy: 0.6500 - val_auc: 0.5842\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 157ms/step - loss: 0.6766 - accuracy: 0.6463 - auc: 0.4615 - val_loss: 0.6587 - val_accuracy: 0.6500 - val_auc: 0.4400\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6585 - accuracy: 0.6488 - auc: 0.4530 - val_loss: 0.6555 - val_accuracy: 0.6500 - val_auc: 0.4402\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6519 - accuracy: 0.6488 - auc: 0.5028 - val_loss: 0.6518 - val_accuracy: 0.6500 - val_auc: 0.4415\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6485 - accuracy: 0.6488 - auc: 0.5157 - val_loss: 0.6485 - val_accuracy: 0.6500 - val_auc: 0.4960\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6490 - accuracy: 0.6488 - auc: 0.5131 - val_loss: 0.6443 - val_accuracy: 0.6500 - val_auc: 0.5358\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6396 - accuracy: 0.6488 - auc: 0.5676 - val_loss: 0.6358 - val_accuracy: 0.6500 - val_auc: 0.5389\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6310 - accuracy: 0.6488 - auc: 0.5431 - val_loss: 0.6309 - val_accuracy: 0.6500 - val_auc: 0.5391\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6250 - accuracy: 0.6500 - auc: 0.5759 - val_loss: 0.6254 - val_accuracy: 0.6500 - val_auc: 0.5741\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6123 - accuracy: 0.6538 - auc: 0.5740 - val_loss: 0.6222 - val_accuracy: 0.6500 - val_auc: 0.5534\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6383 - accuracy: 0.6600 - auc: 0.5867 - val_loss: 0.6313 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6246 - accuracy: 0.6575 - auc: 0.5838 - val_loss: 0.6314 - val_accuracy: 0.6500 - val_auc: 0.5613\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6142 - accuracy: 0.6550 - auc: 0.5968 - val_loss: 0.6196 - val_accuracy: 0.6500 - val_auc: 0.5631\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6072 - accuracy: 0.6687 - auc: 0.5797 - val_loss: 0.6248 - val_accuracy: 0.6500 - val_auc: 0.5488\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 4s 160ms/step - loss: 0.6785 - accuracy: 0.6325 - auc: 0.4589 - val_loss: 0.6574 - val_accuracy: 0.6500 - val_auc: 0.4431\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6528 - accuracy: 0.6488 - auc: 0.4986 - val_loss: 0.6536 - val_accuracy: 0.6500 - val_auc: 0.4466\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6512 - accuracy: 0.6488 - auc: 0.4987 - val_loss: 0.6507 - val_accuracy: 0.6500 - val_auc: 0.4314\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6511 - accuracy: 0.6488 - auc: 0.5050 - val_loss: 0.6475 - val_accuracy: 0.6500 - val_auc: 0.5358\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6484 - accuracy: 0.6488 - auc: 0.5241 - val_loss: 0.6413 - val_accuracy: 0.6500 - val_auc: 0.5484\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6368 - accuracy: 0.6488 - auc: 0.5400 - val_loss: 0.6317 - val_accuracy: 0.6500 - val_auc: 0.5859\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6336 - accuracy: 0.6488 - auc: 0.5252 - val_loss: 0.6181 - val_accuracy: 0.6500 - val_auc: 0.5754\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6090 - accuracy: 0.6488 - auc: 0.5836 - val_loss: 0.6256 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6074 - accuracy: 0.6488 - auc: 0.5964 - val_loss: 0.6289 - val_accuracy: 0.6500 - val_auc: 0.5754\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.5966 - accuracy: 0.6500 - auc: 0.5986 - val_loss: 0.6607 - val_accuracy: 0.6500 - val_auc: 0.5978\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.5956 - accuracy: 0.6525 - auc: 0.6226 - val_loss: 0.5983 - val_accuracy: 0.6500 - val_auc: 0.5543\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.5896 - accuracy: 0.6675 - auc: 0.6291 - val_loss: 0.5917 - val_accuracy: 0.6500 - val_auc: 0.6064\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.5855 - accuracy: 0.6700 - auc: 0.6287 - val_loss: 0.5907 - val_accuracy: 0.6500 - val_auc: 0.6156\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.5887 - accuracy: 0.6700 - auc: 0.6137 - val_loss: 0.6404 - val_accuracy: 0.6500 - val_auc: 0.6385\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.7684 - accuracy: 0.6587 - auc: 0.7763 - val_loss: 0.4971 - val_accuracy: 0.6500 - val_auc: 0.8721\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.4804 - accuracy: 0.7475 - auc: 0.8351 - val_loss: 0.4549 - val_accuracy: 0.7900 - val_auc: 0.8404\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.5291 - accuracy: 0.7412 - auc: 0.7648 - val_loss: 0.7659 - val_accuracy: 0.4800 - val_auc: 0.6112\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6047 - accuracy: 0.5725 - auc: 0.6421 - val_loss: 0.4600 - val_accuracy: 0.6500 - val_auc: 0.8422\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.4539 - accuracy: 0.7325 - auc: 0.8406 - val_loss: 0.4706 - val_accuracy: 0.8200 - val_auc: 0.8475\n",
      "Epoch 20/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.4469 - accuracy: 0.7887 - auc: 0.8469 - val_loss: 0.4331 - val_accuracy: 0.8500 - val_auc: 0.8741\n",
      "Epoch 21/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.4369 - accuracy: 0.8075 - auc: 0.8468 - val_loss: 0.4433 - val_accuracy: 0.8500 - val_auc: 0.8589\n",
      "Epoch 22/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.4314 - accuracy: 0.8263 - auc: 0.8382 - val_loss: 0.4476 - val_accuracy: 0.8300 - val_auc: 0.8457\n",
      "Epoch 23/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.4217 - accuracy: 0.8225 - auc: 0.8445 - val_loss: 0.4240 - val_accuracy: 0.8400 - val_auc: 0.8527\n",
      "Epoch 24/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.4186 - accuracy: 0.8275 - auc: 0.8466 - val_loss: 0.4370 - val_accuracy: 0.8300 - val_auc: 0.8431\n",
      "Epoch 25/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.4112 - accuracy: 0.8238 - auc: 0.8484 - val_loss: 0.4290 - val_accuracy: 0.8400 - val_auc: 0.8527\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 160ms/step - loss: 0.6803 - accuracy: 0.6300 - auc: 0.4679 - val_loss: 0.6581 - val_accuracy: 0.6500 - val_auc: 0.4657\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6538 - accuracy: 0.6475 - auc: 0.5059 - val_loss: 0.6525 - val_accuracy: 0.6500 - val_auc: 0.4431\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6551 - accuracy: 0.6488 - auc: 0.4948 - val_loss: 0.6506 - val_accuracy: 0.6500 - val_auc: 0.4741\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6552 - accuracy: 0.6488 - auc: 0.4736 - val_loss: 0.6446 - val_accuracy: 0.6500 - val_auc: 0.5598\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6480 - accuracy: 0.6488 - auc: 0.5163 - val_loss: 0.6349 - val_accuracy: 0.6500 - val_auc: 0.5519\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6383 - accuracy: 0.6488 - auc: 0.5360 - val_loss: 0.6281 - val_accuracy: 0.6500 - val_auc: 0.5466\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6258 - accuracy: 0.6488 - auc: 0.5427 - val_loss: 0.6352 - val_accuracy: 0.6500 - val_auc: 0.5807\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.6163 - accuracy: 0.6488 - auc: 0.5653 - val_loss: 0.6226 - val_accuracy: 0.6500 - val_auc: 0.5631\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6061 - accuracy: 0.6525 - auc: 0.5999 - val_loss: 0.6310 - val_accuracy: 0.6500 - val_auc: 0.5549\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.5967 - accuracy: 0.6612 - auc: 0.6066 - val_loss: 0.6336 - val_accuracy: 0.6500 - val_auc: 0.5916\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6292 - accuracy: 0.6687 - auc: 0.6569 - val_loss: 0.6110 - val_accuracy: 0.6500 - val_auc: 0.5543\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6097 - accuracy: 0.6675 - auc: 0.5802 - val_loss: 0.6396 - val_accuracy: 0.6500 - val_auc: 0.6402\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 2s 120ms/step - loss: 0.6046 - accuracy: 0.6525 - auc: 0.6080 - val_loss: 0.6142 - val_accuracy: 0.6500 - val_auc: 0.6053\n",
      "Epoch 14/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.5985 - accuracy: 0.6637 - auc: 0.6099 - val_loss: 0.5900 - val_accuracy: 0.6500 - val_auc: 0.5886\n",
      "Epoch 15/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.5876 - accuracy: 0.6700 - auc: 0.6320 - val_loss: 0.6594 - val_accuracy: 0.6500 - val_auc: 0.6042\n",
      "Epoch 16/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.5857 - accuracy: 0.6687 - auc: 0.6136 - val_loss: 0.5915 - val_accuracy: 0.6500 - val_auc: 0.6068\n",
      "Epoch 17/50\n",
      "13/13 [==============================] - 2s 119ms/step - loss: 0.5767 - accuracy: 0.6712 - auc: 0.6452 - val_loss: 0.5819 - val_accuracy: 0.6700 - val_auc: 0.6244\n",
      "Epoch 18/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.5954 - accuracy: 0.6787 - auc: 0.6059 - val_loss: 0.6614 - val_accuracy: 0.6200 - val_auc: 0.5156\n",
      "Epoch 19/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6109 - accuracy: 0.6825 - auc: 0.6155 - val_loss: 0.5980 - val_accuracy: 0.6700 - val_auc: 0.6000\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 172ms/step - loss: 0.6802 - accuracy: 0.6288 - auc: 0.4847 - val_loss: 0.6583 - val_accuracy: 0.6500 - val_auc: 0.4422\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6649 - accuracy: 0.6513 - auc: 0.4486 - val_loss: 0.6566 - val_accuracy: 0.6500 - val_auc: 0.4376\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.6581 - accuracy: 0.6488 - auc: 0.4887 - val_loss: 0.6515 - val_accuracy: 0.6500 - val_auc: 0.4462\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6604 - accuracy: 0.6488 - auc: 0.4673 - val_loss: 0.6494 - val_accuracy: 0.6500 - val_auc: 0.5055\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6490 - accuracy: 0.6488 - auc: 0.5279 - val_loss: 0.6448 - val_accuracy: 0.6500 - val_auc: 0.5723\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6410 - accuracy: 0.6488 - auc: 0.5574 - val_loss: 0.6332 - val_accuracy: 0.6500 - val_auc: 0.5530\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6336 - accuracy: 0.6475 - auc: 0.5461 - val_loss: 0.6318 - val_accuracy: 0.6500 - val_auc: 0.5626\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6326 - accuracy: 0.6488 - auc: 0.5478 - val_loss: 0.6168 - val_accuracy: 0.6500 - val_auc: 0.5644\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6208 - accuracy: 0.6488 - auc: 0.5702 - val_loss: 0.6151 - val_accuracy: 0.6500 - val_auc: 0.5666\n",
      "Epoch 10/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6213 - accuracy: 0.6488 - auc: 0.5638 - val_loss: 0.6111 - val_accuracy: 0.6500 - val_auc: 0.5543\n",
      "Epoch 11/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.6179 - accuracy: 0.6488 - auc: 0.6438 - val_loss: 0.6311 - val_accuracy: 0.6500 - val_auc: 0.5763\n",
      "Epoch 12/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6352 - accuracy: 0.6488 - auc: 0.5541 - val_loss: 0.6472 - val_accuracy: 0.6500 - val_auc: 0.5607\n",
      "Epoch 13/50\n",
      "13/13 [==============================] - 2s 117ms/step - loss: 0.6276 - accuracy: 0.6488 - auc: 0.5541 - val_loss: 0.6276 - val_accuracy: 0.6500 - val_auc: 0.5536\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 161ms/step - loss: 0.6921 - accuracy: 0.6212 - auc: 0.4753 - val_loss: 0.6892 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 2s 118ms/step - loss: 0.6865 - accuracy: 0.6225 - auc: 0.4838 - val_loss: 0.6770 - val_accuracy: 0.6500 - val_auc: 0.4295\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6718 - accuracy: 0.6275 - auc: 0.4908 - val_loss: 0.6517 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6614 - accuracy: 0.6400 - auc: 0.4850 - val_loss: 0.6512 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6580 - accuracy: 0.6463 - auc: 0.4864 - val_loss: 0.6495 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6558 - accuracy: 0.6450 - auc: 0.5064 - val_loss: 0.6492 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6483 - accuracy: 0.6500 - auc: 0.5345 - val_loss: 0.6480 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6571 - accuracy: 0.6463 - auc: 0.4907 - val_loss: 0.6484 - val_accuracy: 0.6500 - val_auc: 0.5000\n",
      "Epoch 1/50\n",
      "13/13 [==============================] - 5s 161ms/step - loss: 0.6793 - accuracy: 0.6488 - auc: 0.4633 - val_loss: 0.6582 - val_accuracy: 0.6500 - val_auc: 0.4607\n",
      "Epoch 2/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6652 - accuracy: 0.6488 - auc: 0.4563 - val_loss: 0.6525 - val_accuracy: 0.6500 - val_auc: 0.4398\n",
      "Epoch 3/50\n",
      "13/13 [==============================] - 1s 113ms/step - loss: 0.6567 - accuracy: 0.6463 - auc: 0.4924 - val_loss: 0.6483 - val_accuracy: 0.6500 - val_auc: 0.5240\n",
      "Epoch 4/50\n",
      "13/13 [==============================] - 1s 116ms/step - loss: 0.6508 - accuracy: 0.6488 - auc: 0.5122 - val_loss: 0.6390 - val_accuracy: 0.6500 - val_auc: 0.5695\n",
      "Epoch 5/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6902 - accuracy: 0.6488 - auc: 0.5046 - val_loss: 0.7249 - val_accuracy: 0.6500 - val_auc: 0.5538\n",
      "Epoch 6/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6740 - accuracy: 0.6450 - auc: 0.5163 - val_loss: 0.6501 - val_accuracy: 0.6500 - val_auc: 0.4846\n",
      "Epoch 7/50\n",
      "13/13 [==============================] - 2s 116ms/step - loss: 0.6583 - accuracy: 0.6475 - auc: 0.4992 - val_loss: 0.6473 - val_accuracy: 0.6500 - val_auc: 0.5308\n",
      "Epoch 8/50\n",
      "13/13 [==============================] - 1s 115ms/step - loss: 0.6562 - accuracy: 0.6475 - auc: 0.5050 - val_loss: 0.6485 - val_accuracy: 0.6500 - val_auc: 0.5571\n",
      "Epoch 9/50\n",
      "13/13 [==============================] - 1s 114ms/step - loss: 0.6553 - accuracy: 0.6463 - auc: 0.5079 - val_loss: 0.6471 - val_accuracy: 0.6500 - val_auc: 0.5501\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>14</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>16</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>26</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>27</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>15</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>12</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>20</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6306</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>23</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.3543</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>18</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2731</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>20</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3452</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>26</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>29</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.6062</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.5921</td>\n",
       "      <td>17</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.6152</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>15</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>18</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0   0.3393    0.3916        0.8367   0.9313        14            gru   \n",
       "1   0.3538    0.3969        0.8567   0.9319        16            gru   \n",
       "2   0.2811    0.3721        0.8233   0.9245        26            gru   \n",
       "3   0.4258    0.4184        0.7500   0.9302        27            gru   \n",
       "4   0.6138    0.6153        0.6500   0.5566        15            gru   \n",
       "5   0.6404    0.6358        0.6500   0.5241        12            gru   \n",
       "6   0.6354    0.6329        0.6500   0.5651        20            gru   \n",
       "7   0.6306    0.6320        0.6467   0.5455        23            gru   \n",
       "8   0.2308    0.3543        0.8567   0.9508        18           lstm   \n",
       "9   0.2731    0.3321        0.8733   0.9401        20           lstm   \n",
       "10  0.3452    0.3396        0.8600   0.9400        26           lstm   \n",
       "11  0.3957    0.4153        0.8033   0.9345        29           lstm   \n",
       "12  0.6062    0.5935        0.6800   0.5921        17           lstm   \n",
       "13  0.6131    0.6152        0.6500   0.5667        15           lstm   \n",
       "14  0.5568    0.5495        0.7167   0.6789        32           lstm   \n",
       "15  0.6517    0.6358        0.6500   0.5446        18           lstm   \n",
       "\n",
       "    bi_directional  rnn_layers  dense_layers  \n",
       "0             True           1             1  \n",
       "1             True           1             2  \n",
       "2             True           2             1  \n",
       "3             True           2             2  \n",
       "4            False           1             1  \n",
       "5            False           1             2  \n",
       "6            False           2             1  \n",
       "7            False           2             2  \n",
       "8             True           1             1  \n",
       "9             True           1             2  \n",
       "10            True           2             1  \n",
       "11            True           2             2  \n",
       "12           False           1             1  \n",
       "13           False           1             2  \n",
       "14           False           2             1  \n",
       "15           False           2             2  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_ds, val_ds, vocab_size, sequence_length, batch_size = load_and_prepare_data(\n",
    "    path='data/Airline_review.csv', \n",
    "    include_validation=True, \n",
    "    sample_size=1000, \n",
    "    stop_words=None, \n",
    "    lemmatize=False, \n",
    "    max_tokens=10000, \n",
    "    percentile_len=0.9, \n",
    "    batch_size=64\n",
    ")\n",
    "def run_experiment(recurrent_type, bi_directional, rnn_layers, dense_layers, runs, train_ds, val_ds, epochs, sequence_length, vocab_size):\n",
    "    \"\"\"\n",
    "    Runs the experiment for a specific configuration and returns the average metrics.\n",
    "    \"\"\"\n",
    "    model_function = lambda: build_rnn_model(\n",
    "        rnn_layers=rnn_layers,\n",
    "        dense_layers=dense_layers,\n",
    "        recurrent_type=recurrent_type,\n",
    "        bi_directional=bi_directional,\n",
    "        dropout_rate=0.2,\n",
    "        units=64,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    return calculate_average_metrics(runs, model_function, train_ds, val_ds, epochs)\n",
    "\n",
    "# Configuration options\n",
    "param_dict = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'bi_directional': [True, False],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2]\n",
    "}\n",
    "\n",
    "configurations = generate_configurations(param_dict)\n",
    "\n",
    "results = []\n",
    "runs = 3\n",
    "epochs = 50\n",
    "\n",
    "# Run experiments\n",
    "for config in configurations:\n",
    "    metrics = run_experiment(\n",
    "        recurrent_type=config['recurrent_type'],\n",
    "        bi_directional=config['bi_directional'],\n",
    "        rnn_layers=config['rnn_layers'],\n",
    "        dense_layers=config['dense_layers'],\n",
    "        runs=runs,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=epochs,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    results.append({\n",
    "        **metrics,\n",
    "        **config  # Unpack configuration into the results\n",
    "    })\n",
    "\n",
    "# Create DataFrame and format\n",
    "df = pd.DataFrame(results)\n",
    "df = df.round({'loss': 4, 'val_loss': 4, 'val_accuracy': 4, 'val_auc': 4})\n",
    "df['duration'] = df['duration'].round(0).astype(int)\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a951880f-dd05-40c8-a30a-1b618dd8efdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2731</td>\n",
       "      <td>0.3321</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9401</td>\n",
       "      <td>20</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.3452</td>\n",
       "      <td>0.3396</td>\n",
       "      <td>0.8600</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>26</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2308</td>\n",
       "      <td>0.3543</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9508</td>\n",
       "      <td>18</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.3721</td>\n",
       "      <td>0.8233</td>\n",
       "      <td>0.9245</td>\n",
       "      <td>26</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3393</td>\n",
       "      <td>0.3916</td>\n",
       "      <td>0.8367</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>14</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3538</td>\n",
       "      <td>0.3969</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>16</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3957</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.8033</td>\n",
       "      <td>0.9345</td>\n",
       "      <td>29</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4258</td>\n",
       "      <td>0.4184</td>\n",
       "      <td>0.7500</td>\n",
       "      <td>0.9302</td>\n",
       "      <td>27</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.5568</td>\n",
       "      <td>0.5495</td>\n",
       "      <td>0.7167</td>\n",
       "      <td>0.6789</td>\n",
       "      <td>32</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.6062</td>\n",
       "      <td>0.5935</td>\n",
       "      <td>0.6800</td>\n",
       "      <td>0.5921</td>\n",
       "      <td>17</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.6131</td>\n",
       "      <td>0.6152</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5667</td>\n",
       "      <td>15</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6138</td>\n",
       "      <td>0.6153</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>15</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.6306</td>\n",
       "      <td>0.6320</td>\n",
       "      <td>0.6467</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>23</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.6354</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5651</td>\n",
       "      <td>20</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5241</td>\n",
       "      <td>12</td>\n",
       "      <td>gru</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.6517</td>\n",
       "      <td>0.6358</td>\n",
       "      <td>0.6500</td>\n",
       "      <td>0.5446</td>\n",
       "      <td>18</td>\n",
       "      <td>lstm</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "9   0.2731    0.3321        0.8733   0.9401        20           lstm   \n",
       "10  0.3452    0.3396        0.8600   0.9400        26           lstm   \n",
       "8   0.2308    0.3543        0.8567   0.9508        18           lstm   \n",
       "2   0.2811    0.3721        0.8233   0.9245        26            gru   \n",
       "0   0.3393    0.3916        0.8367   0.9313        14            gru   \n",
       "1   0.3538    0.3969        0.8567   0.9319        16            gru   \n",
       "11  0.3957    0.4153        0.8033   0.9345        29           lstm   \n",
       "3   0.4258    0.4184        0.7500   0.9302        27            gru   \n",
       "14  0.5568    0.5495        0.7167   0.6789        32           lstm   \n",
       "12  0.6062    0.5935        0.6800   0.5921        17           lstm   \n",
       "13  0.6131    0.6152        0.6500   0.5667        15           lstm   \n",
       "4   0.6138    0.6153        0.6500   0.5566        15            gru   \n",
       "7   0.6306    0.6320        0.6467   0.5455        23            gru   \n",
       "6   0.6354    0.6329        0.6500   0.5651        20            gru   \n",
       "5   0.6404    0.6358        0.6500   0.5241        12            gru   \n",
       "15  0.6517    0.6358        0.6500   0.5446        18           lstm   \n",
       "\n",
       "    bi_directional  rnn_layers  dense_layers  \n",
       "9             True           1             2  \n",
       "10            True           2             1  \n",
       "8             True           1             1  \n",
       "2             True           2             1  \n",
       "0             True           1             1  \n",
       "1             True           1             2  \n",
       "11            True           2             2  \n",
       "3             True           2             2  \n",
       "14           False           2             1  \n",
       "12           False           1             1  \n",
       "13           False           1             2  \n",
       "4            False           1             1  \n",
       "7            False           2             2  \n",
       "6            False           2             1  \n",
       "5            False           1             2  \n",
       "15           False           2             2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30021b51-e319-4275-932d-319a8617c619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>65</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>100</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>63</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>50</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>88</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>49</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>105</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>85</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "4  0.2238    0.2753        0.8920   0.9526        65           lstm   \n",
       "6  0.3036    0.2966        0.8660   0.9426       100           lstm   \n",
       "5  0.3040    0.3118        0.8653   0.9359        63           lstm   \n",
       "1  0.3542    0.3133        0.8667   0.9450        50            gru   \n",
       "3  0.4056    0.3188        0.8673   0.9363        88            gru   \n",
       "0  0.2950    0.3189        0.8593   0.9357        49            gru   \n",
       "7  0.3686    0.3464        0.8673   0.9344       105           lstm   \n",
       "2  0.3838    0.3534        0.8493   0.9289        85            gru   \n",
       "\n",
       "   bi_directional  rnn_layers  dense_layers  \n",
       "4            True           1             1  \n",
       "6            True           2             1  \n",
       "5            True           1             2  \n",
       "1            True           1             2  \n",
       "3            True           2             2  \n",
       "0            True           1             1  \n",
       "7            True           2             2  \n",
       "2            True           2             1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sort_values('val_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "581fa0e7-d4fe-4d9f-94db-cf0abfc5c6ad",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 106ms/step - loss: 0.5989 - accuracy: 0.6765 - auc: 0.6463 - val_loss: 0.3529 - val_accuracy: 0.8580 - val_auc: 0.9264\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 6s 102ms/step - loss: 0.2929 - accuracy: 0.8810 - auc: 0.9404 - val_loss: 0.3281 - val_accuracy: 0.8580 - val_auc: 0.9313\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.1663 - accuracy: 0.9380 - auc: 0.9799 - val_loss: 0.3539 - val_accuracy: 0.8760 - val_auc: 0.9405\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.1046 - accuracy: 0.9640 - auc: 0.9917 - val_loss: 0.4708 - val_accuracy: 0.8860 - val_auc: 0.9360\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0796 - accuracy: 0.9740 - auc: 0.9947 - val_loss: 0.4634 - val_accuracy: 0.8700 - val_auc: 0.9258\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.0705 - accuracy: 0.9772 - auc: 0.9962 - val_loss: 0.7486 - val_accuracy: 0.8380 - val_auc: 0.8912\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 0.0748 - accuracy: 0.9770 - auc: 0.9956 - val_loss: 0.6801 - val_accuracy: 0.8640 - val_auc: 0.8979\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 111ms/step - loss: 0.5908 - accuracy: 0.6862 - auc: 0.6714 - val_loss: 0.3750 - val_accuracy: 0.8400 - val_auc: 0.9164\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.2897 - accuracy: 0.8802 - auc: 0.9424 - val_loss: 0.3126 - val_accuracy: 0.8540 - val_auc: 0.9379\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.1539 - accuracy: 0.9413 - auc: 0.9836 - val_loss: 0.4425 - val_accuracy: 0.8360 - val_auc: 0.9321\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.1059 - accuracy: 0.9645 - auc: 0.9913 - val_loss: 0.4791 - val_accuracy: 0.8660 - val_auc: 0.9289\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.1254 - accuracy: 0.9560 - auc: 0.9884 - val_loss: 0.6115 - val_accuracy: 0.8660 - val_auc: 0.9074\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.0828 - accuracy: 0.9735 - auc: 0.9946 - val_loss: 0.7203 - val_accuracy: 0.8580 - val_auc: 0.8931\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 6s 103ms/step - loss: 0.0799 - accuracy: 0.9745 - auc: 0.9945 - val_loss: 0.6430 - val_accuracy: 0.8540 - val_auc: 0.9032\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 110ms/step - loss: 0.5759 - accuracy: 0.6913 - auc: 0.6960 - val_loss: 0.3713 - val_accuracy: 0.8340 - val_auc: 0.9193\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.3025 - accuracy: 0.8725 - auc: 0.9369 - val_loss: 0.3161 - val_accuracy: 0.8660 - val_auc: 0.9380\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.1756 - accuracy: 0.9370 - auc: 0.9778 - val_loss: 0.3675 - val_accuracy: 0.8420 - val_auc: 0.9173\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 0.0995 - accuracy: 0.9668 - auc: 0.9920 - val_loss: 0.4877 - val_accuracy: 0.8100 - val_auc: 0.9132\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 0.0617 - accuracy: 0.9820 - auc: 0.9959 - val_loss: 0.6974 - val_accuracy: 0.7780 - val_auc: 0.8958\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0809 - accuracy: 0.9710 - auc: 0.9945 - val_loss: 0.5620 - val_accuracy: 0.8240 - val_auc: 0.9009\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.0842 - accuracy: 0.9690 - auc: 0.9948 - val_loss: 0.7423 - val_accuracy: 0.8480 - val_auc: 0.8852\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 117ms/step - loss: 0.6193 - accuracy: 0.6615 - auc: 0.5934 - val_loss: 0.9632 - val_accuracy: 0.7660 - val_auc: 0.8463\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 0.3653 - accuracy: 0.8503 - auc: 0.9108 - val_loss: 0.3389 - val_accuracy: 0.8520 - val_auc: 0.9497\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.2565 - accuracy: 0.9078 - auc: 0.9548 - val_loss: 0.3382 - val_accuracy: 0.8740 - val_auc: 0.9446\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.1401 - accuracy: 0.9567 - auc: 0.9852 - val_loss: 0.3719 - val_accuracy: 0.8780 - val_auc: 0.9406\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 110ms/step - loss: 0.0854 - accuracy: 0.9750 - auc: 0.9930 - val_loss: 0.6034 - val_accuracy: 0.8480 - val_auc: 0.9163\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0494 - accuracy: 0.9875 - auc: 0.9969 - val_loss: 0.4988 - val_accuracy: 0.8640 - val_auc: 0.9203\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 0.2067 - accuracy: 0.9210 - auc: 0.9718 - val_loss: 0.4787 - val_accuracy: 0.8200 - val_auc: 0.9026\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 113ms/step - loss: 0.6317 - accuracy: 0.6590 - auc: 0.5792 - val_loss: 0.4569 - val_accuracy: 0.8340 - val_auc: 0.9078\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.3404 - accuracy: 0.8610 - auc: 0.9194 - val_loss: 0.2771 - val_accuracy: 0.8920 - val_auc: 0.9469\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.2128 - accuracy: 0.9237 - auc: 0.9679 - val_loss: 0.3323 - val_accuracy: 0.8680 - val_auc: 0.9319\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.1302 - accuracy: 0.9580 - auc: 0.9864 - val_loss: 0.4589 - val_accuracy: 0.8360 - val_auc: 0.9328\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.1081 - accuracy: 0.9622 - auc: 0.9915 - val_loss: 0.5326 - val_accuracy: 0.8800 - val_auc: 0.9316\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0719 - accuracy: 0.9783 - auc: 0.9947 - val_loss: 0.6909 - val_accuracy: 0.8400 - val_auc: 0.8929\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0752 - accuracy: 0.9758 - auc: 0.9953 - val_loss: 0.5996 - val_accuracy: 0.8700 - val_auc: 0.9090\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 119ms/step - loss: 0.6105 - accuracy: 0.6625 - auc: 0.6271 - val_loss: 0.4566 - val_accuracy: 0.6780 - val_auc: 0.9020\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.3570 - accuracy: 0.8505 - auc: 0.9218 - val_loss: 0.3240 - val_accuracy: 0.8560 - val_auc: 0.9386\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.1869 - accuracy: 0.9295 - auc: 0.9744 - val_loss: 0.3443 - val_accuracy: 0.8680 - val_auc: 0.9322\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 0.1051 - accuracy: 0.9665 - auc: 0.9909 - val_loss: 0.4143 - val_accuracy: 0.8680 - val_auc: 0.9285\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.1044 - accuracy: 0.9655 - auc: 0.9914 - val_loss: 0.4651 - val_accuracy: 0.8580 - val_auc: 0.9210\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.1280 - accuracy: 0.9567 - auc: 0.9876 - val_loss: 0.6077 - val_accuracy: 0.8640 - val_auc: 0.9127\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 0.0550 - accuracy: 0.9837 - auc: 0.9966 - val_loss: 0.5582 - val_accuracy: 0.8620 - val_auc: 0.9110\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 203ms/step - loss: 0.5644 - accuracy: 0.7085 - auc: 0.7223 - val_loss: 0.3874 - val_accuracy: 0.8460 - val_auc: 0.9146\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.2847 - accuracy: 0.8857 - auc: 0.9435 - val_loss: 0.3516 - val_accuracy: 0.8620 - val_auc: 0.9160\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 185ms/step - loss: 0.1506 - accuracy: 0.9495 - auc: 0.9818 - val_loss: 0.4391 - val_accuracy: 0.8480 - val_auc: 0.9104\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.0914 - accuracy: 0.9720 - auc: 0.9917 - val_loss: 0.6921 - val_accuracy: 0.8120 - val_auc: 0.9165\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.0705 - accuracy: 0.9775 - auc: 0.9951 - val_loss: 0.6612 - val_accuracy: 0.8420 - val_auc: 0.9221\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.0537 - accuracy: 0.9815 - auc: 0.9975 - val_loss: 0.7456 - val_accuracy: 0.8180 - val_auc: 0.8939\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.1168 - accuracy: 0.9597 - auc: 0.9887 - val_loss: 0.5799 - val_accuracy: 0.8360 - val_auc: 0.8999\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 210ms/step - loss: 0.5786 - accuracy: 0.7028 - auc: 0.6821 - val_loss: 0.3772 - val_accuracy: 0.8360 - val_auc: 0.9322\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.2744 - accuracy: 0.8932 - auc: 0.9464 - val_loss: 0.3673 - val_accuracy: 0.8620 - val_auc: 0.9446\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.1455 - accuracy: 0.9548 - auc: 0.9820 - val_loss: 0.3958 - val_accuracy: 0.8680 - val_auc: 0.9442\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 196ms/step - loss: 0.0898 - accuracy: 0.9703 - auc: 0.9926 - val_loss: 0.4632 - val_accuracy: 0.8800 - val_auc: 0.9394\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.0824 - accuracy: 0.9753 - auc: 0.9931 - val_loss: 0.5979 - val_accuracy: 0.8760 - val_auc: 0.9103\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.0462 - accuracy: 0.9875 - auc: 0.9975 - val_loss: 0.6686 - val_accuracy: 0.8420 - val_auc: 0.8864\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 205ms/step - loss: 0.5714 - accuracy: 0.7035 - auc: 0.7040 - val_loss: 0.3517 - val_accuracy: 0.8460 - val_auc: 0.9238\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 190ms/step - loss: 0.2881 - accuracy: 0.8863 - auc: 0.9421 - val_loss: 0.3313 - val_accuracy: 0.8500 - val_auc: 0.9384\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.1503 - accuracy: 0.9495 - auc: 0.9833 - val_loss: 0.3749 - val_accuracy: 0.8740 - val_auc: 0.9441\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.0859 - accuracy: 0.9722 - auc: 0.9933 - val_loss: 0.4812 - val_accuracy: 0.8800 - val_auc: 0.9320\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.1187 - accuracy: 0.9572 - auc: 0.9889 - val_loss: 0.4593 - val_accuracy: 0.8880 - val_auc: 0.9295\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 192ms/step - loss: 0.0481 - accuracy: 0.9847 - auc: 0.9973 - val_loss: 0.6254 - val_accuracy: 0.8620 - val_auc: 0.8931\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 12s 191ms/step - loss: 0.0416 - accuracy: 0.9875 - auc: 0.9977 - val_loss: 0.7032 - val_accuracy: 0.8260 - val_auc: 0.8994\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 201ms/step - loss: 0.6575 - accuracy: 0.6482 - auc: 0.5161 - val_loss: 0.5919 - val_accuracy: 0.6620 - val_auc: 0.8766\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 190ms/step - loss: 0.4520 - accuracy: 0.7760 - auc: 0.8568 - val_loss: 0.3395 - val_accuracy: 0.8620 - val_auc: 0.9310\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.2766 - accuracy: 0.8985 - auc: 0.9467 - val_loss: 0.3823 - val_accuracy: 0.8580 - val_auc: 0.9219\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.2032 - accuracy: 0.9365 - auc: 0.9688 - val_loss: 0.4211 - val_accuracy: 0.8260 - val_auc: 0.9010\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.1405 - accuracy: 0.9630 - auc: 0.9849 - val_loss: 0.4826 - val_accuracy: 0.8560 - val_auc: 0.9273\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.0900 - accuracy: 0.9768 - auc: 0.9917 - val_loss: 0.5570 - val_accuracy: 0.8700 - val_auc: 0.9087\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.0890 - accuracy: 0.9770 - auc: 0.9926 - val_loss: 0.8021 - val_accuracy: 0.8340 - val_auc: 0.8587\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 198ms/step - loss: 0.6000 - accuracy: 0.6773 - auc: 0.6456 - val_loss: 0.4044 - val_accuracy: 0.8320 - val_auc: 0.9088\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.3475 - accuracy: 0.8662 - auc: 0.9194 - val_loss: 0.3198 - val_accuracy: 0.8640 - val_auc: 0.9335\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.2126 - accuracy: 0.9277 - auc: 0.9690 - val_loss: 0.4886 - val_accuracy: 0.8320 - val_auc: 0.9321\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.1358 - accuracy: 0.9610 - auc: 0.9855 - val_loss: 0.7692 - val_accuracy: 0.8340 - val_auc: 0.9087\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.4894 - accuracy: 0.8267 - auc: 0.8767 - val_loss: 0.4461 - val_accuracy: 0.8140 - val_auc: 0.8738\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.2787 - accuracy: 0.8982 - auc: 0.9497 - val_loss: 0.4091 - val_accuracy: 0.8280 - val_auc: 0.9189\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.1987 - accuracy: 0.9398 - auc: 0.9726 - val_loss: 0.4455 - val_accuracy: 0.8520 - val_auc: 0.9276\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 17s 204ms/step - loss: 0.6527 - accuracy: 0.6535 - auc: 0.5222 - val_loss: 0.5724 - val_accuracy: 0.6660 - val_auc: 0.8668\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.4171 - accuracy: 0.8282 - auc: 0.8767 - val_loss: 0.2972 - val_accuracy: 0.8760 - val_auc: 0.9445\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 12s 186ms/step - loss: 0.2386 - accuracy: 0.9240 - auc: 0.9583 - val_loss: 0.3913 - val_accuracy: 0.8760 - val_auc: 0.9296\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.1783 - accuracy: 0.9465 - auc: 0.9759 - val_loss: 0.4051 - val_accuracy: 0.8980 - val_auc: 0.9362\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 12s 187ms/step - loss: 0.1090 - accuracy: 0.9735 - auc: 0.9886 - val_loss: 0.4720 - val_accuracy: 0.8620 - val_auc: 0.9174\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 12s 189ms/step - loss: 0.0860 - accuracy: 0.9778 - auc: 0.9922 - val_loss: 0.6503 - val_accuracy: 0.8360 - val_auc: 0.8867\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 12s 188ms/step - loss: 0.0815 - accuracy: 0.9755 - auc: 0.9931 - val_loss: 0.6273 - val_accuracy: 0.8580 - val_auc: 0.8934\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 143ms/step - loss: 0.5394 - accuracy: 0.7275 - auc: 0.7518 - val_loss: 0.5369 - val_accuracy: 0.7860 - val_auc: 0.9364\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.2560 - accuracy: 0.8990 - auc: 0.9546 - val_loss: 0.2792 - val_accuracy: 0.8800 - val_auc: 0.9451\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 8s 131ms/step - loss: 0.1445 - accuracy: 0.9513 - auc: 0.9840 - val_loss: 0.3394 - val_accuracy: 0.8640 - val_auc: 0.9378\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 8s 134ms/step - loss: 0.0861 - accuracy: 0.9730 - auc: 0.9929 - val_loss: 0.3841 - val_accuracy: 0.8840 - val_auc: 0.9429\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.0587 - accuracy: 0.9840 - auc: 0.9956 - val_loss: 0.3855 - val_accuracy: 0.8680 - val_auc: 0.9371\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 130ms/step - loss: 0.0296 - accuracy: 0.9925 - auc: 0.9984 - val_loss: 0.4920 - val_accuracy: 0.8380 - val_auc: 0.9089\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 8s 134ms/step - loss: 0.0258 - accuracy: 0.9925 - auc: 0.9989 - val_loss: 0.5290 - val_accuracy: 0.8980 - val_auc: 0.9282\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 141ms/step - loss: 0.5701 - accuracy: 0.6967 - auc: 0.6976 - val_loss: 0.3273 - val_accuracy: 0.8620 - val_auc: 0.9309\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 9s 138ms/step - loss: 0.2789 - accuracy: 0.8875 - auc: 0.9453 - val_loss: 0.3183 - val_accuracy: 0.8620 - val_auc: 0.9409\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.1649 - accuracy: 0.9415 - auc: 0.9794 - val_loss: 0.2979 - val_accuracy: 0.8980 - val_auc: 0.9542\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 10s 156ms/step - loss: 0.0896 - accuracy: 0.9705 - auc: 0.9922 - val_loss: 0.4124 - val_accuracy: 0.8840 - val_auc: 0.9483\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 142ms/step - loss: 0.0468 - accuracy: 0.9877 - auc: 0.9970 - val_loss: 0.4197 - val_accuracy: 0.8720 - val_auc: 0.9315\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 121ms/step - loss: 0.0351 - accuracy: 0.9912 - auc: 0.9974 - val_loss: 0.6325 - val_accuracy: 0.8680 - val_auc: 0.9022\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 8s 132ms/step - loss: 0.0274 - accuracy: 0.9930 - auc: 0.9983 - val_loss: 0.5116 - val_accuracy: 0.8760 - val_auc: 0.9153\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 8s 135ms/step - loss: 0.0166 - accuracy: 0.9965 - auc: 0.9987 - val_loss: 0.5974 - val_accuracy: 0.8620 - val_auc: 0.9187\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 144ms/step - loss: 0.5420 - accuracy: 0.7190 - auc: 0.7410 - val_loss: 0.3069 - val_accuracy: 0.8740 - val_auc: 0.9424\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 8s 132ms/step - loss: 0.2504 - accuracy: 0.8995 - auc: 0.9561 - val_loss: 0.2487 - val_accuracy: 0.8980 - val_auc: 0.9585\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.1435 - accuracy: 0.9525 - auc: 0.9832 - val_loss: 0.3413 - val_accuracy: 0.8600 - val_auc: 0.9511\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 8s 135ms/step - loss: 0.0906 - accuracy: 0.9728 - auc: 0.9918 - val_loss: 0.3428 - val_accuracy: 0.8780 - val_auc: 0.9403\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.0654 - accuracy: 0.9790 - auc: 0.9957 - val_loss: 0.3751 - val_accuracy: 0.8840 - val_auc: 0.9411\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 132ms/step - loss: 0.0384 - accuracy: 0.9893 - auc: 0.9976 - val_loss: 0.5069 - val_accuracy: 0.8700 - val_auc: 0.9187\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 8s 135ms/step - loss: 0.0268 - accuracy: 0.9912 - auc: 0.9980 - val_loss: 0.5483 - val_accuracy: 0.8720 - val_auc: 0.9146\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 145ms/step - loss: 0.5882 - accuracy: 0.7003 - auc: 0.6962 - val_loss: 0.3975 - val_accuracy: 0.8280 - val_auc: 0.9200\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 9s 138ms/step - loss: 0.3028 - accuracy: 0.8783 - auc: 0.9353 - val_loss: 0.3125 - val_accuracy: 0.8700 - val_auc: 0.9403\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 9s 139ms/step - loss: 0.1750 - accuracy: 0.9423 - auc: 0.9767 - val_loss: 0.3084 - val_accuracy: 0.8840 - val_auc: 0.9426\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 8s 133ms/step - loss: 0.1071 - accuracy: 0.9685 - auc: 0.9898 - val_loss: 0.4033 - val_accuracy: 0.8540 - val_auc: 0.9131\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.0848 - accuracy: 0.9808 - auc: 0.9919 - val_loss: 0.4368 - val_accuracy: 0.8800 - val_auc: 0.9314\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 134ms/step - loss: 0.0446 - accuracy: 0.9902 - auc: 0.9969 - val_loss: 0.5447 - val_accuracy: 0.8740 - val_auc: 0.9313\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.0448 - accuracy: 0.9862 - auc: 0.9969 - val_loss: 0.6614 - val_accuracy: 0.8120 - val_auc: 0.9113\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 144ms/step - loss: 0.5759 - accuracy: 0.7065 - auc: 0.7097 - val_loss: 0.3750 - val_accuracy: 0.8600 - val_auc: 0.9279\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.2997 - accuracy: 0.8820 - auc: 0.9360 - val_loss: 0.3091 - val_accuracy: 0.8580 - val_auc: 0.9355\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.1739 - accuracy: 0.9408 - auc: 0.9766 - val_loss: 0.3050 - val_accuracy: 0.8900 - val_auc: 0.9507\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.1007 - accuracy: 0.9700 - auc: 0.9910 - val_loss: 0.4139 - val_accuracy: 0.8760 - val_auc: 0.9460\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 0.0836 - accuracy: 0.9760 - auc: 0.9936 - val_loss: 0.4615 - val_accuracy: 0.8340 - val_auc: 0.9268\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 0.0735 - accuracy: 0.9808 - auc: 0.9939 - val_loss: 0.4622 - val_accuracy: 0.8720 - val_auc: 0.9267\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.0758 - accuracy: 0.9793 - auc: 0.9933 - val_loss: 0.4838 - val_accuracy: 0.8680 - val_auc: 0.9233\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 12s 147ms/step - loss: 0.5765 - accuracy: 0.7030 - auc: 0.6997 - val_loss: 0.4595 - val_accuracy: 0.8260 - val_auc: 0.9028\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 8s 135ms/step - loss: 0.3096 - accuracy: 0.8800 - auc: 0.9319 - val_loss: 0.3139 - val_accuracy: 0.8680 - val_auc: 0.9319\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.2202 - accuracy: 0.9245 - auc: 0.9643 - val_loss: 0.3150 - val_accuracy: 0.8860 - val_auc: 0.9497\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 9s 136ms/step - loss: 0.1218 - accuracy: 0.9640 - auc: 0.9859 - val_loss: 0.3739 - val_accuracy: 0.8620 - val_auc: 0.9425\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 9s 137ms/step - loss: 0.0795 - accuracy: 0.9780 - auc: 0.9928 - val_loss: 0.4369 - val_accuracy: 0.8660 - val_auc: 0.9361\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 9s 139ms/step - loss: 0.0572 - accuracy: 0.9847 - auc: 0.9962 - val_loss: 0.5024 - val_accuracy: 0.8740 - val_auc: 0.9277\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 9s 140ms/step - loss: 0.0404 - accuracy: 0.9887 - auc: 0.9977 - val_loss: 0.6015 - val_accuracy: 0.8740 - val_auc: 0.9290\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 235ms/step - loss: 0.5725 - accuracy: 0.7038 - auc: 0.7016 - val_loss: 0.3799 - val_accuracy: 0.8500 - val_auc: 0.9089\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 220ms/step - loss: 0.3096 - accuracy: 0.8795 - auc: 0.9304 - val_loss: 0.2734 - val_accuracy: 0.8820 - val_auc: 0.9493\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.1771 - accuracy: 0.9430 - auc: 0.9722 - val_loss: 0.3088 - val_accuracy: 0.8980 - val_auc: 0.9527\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.1137 - accuracy: 0.9703 - auc: 0.9855 - val_loss: 0.4170 - val_accuracy: 0.8740 - val_auc: 0.9289\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.1511 - accuracy: 0.9470 - auc: 0.9812 - val_loss: 0.4374 - val_accuracy: 0.8660 - val_auc: 0.9362\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.0703 - accuracy: 0.9790 - auc: 0.9938 - val_loss: 0.4995 - val_accuracy: 0.8720 - val_auc: 0.9204\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 0.0411 - accuracy: 0.9898 - auc: 0.9961 - val_loss: 0.6654 - val_accuracy: 0.8620 - val_auc: 0.8907\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 233ms/step - loss: 0.5609 - accuracy: 0.7225 - auc: 0.7308 - val_loss: 0.3871 - val_accuracy: 0.8640 - val_auc: 0.9252\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 219ms/step - loss: 0.2818 - accuracy: 0.8923 - auc: 0.9441 - val_loss: 0.3015 - val_accuracy: 0.8680 - val_auc: 0.9387\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 219ms/step - loss: 0.1559 - accuracy: 0.9513 - auc: 0.9794 - val_loss: 0.4257 - val_accuracy: 0.8200 - val_auc: 0.9288\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.0852 - accuracy: 0.9785 - auc: 0.9912 - val_loss: 0.5001 - val_accuracy: 0.8620 - val_auc: 0.9310\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.0526 - accuracy: 0.9862 - auc: 0.9956 - val_loss: 0.5564 - val_accuracy: 0.8360 - val_auc: 0.9223\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 13s 213ms/step - loss: 0.0558 - accuracy: 0.9852 - auc: 0.9958 - val_loss: 0.5209 - val_accuracy: 0.8300 - val_auc: 0.9236\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 214ms/step - loss: 0.0552 - accuracy: 0.9847 - auc: 0.9967 - val_loss: 0.6648 - val_accuracy: 0.7600 - val_auc: 0.9132\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 18s 227ms/step - loss: 0.5608 - accuracy: 0.7125 - auc: 0.7131 - val_loss: 0.5019 - val_accuracy: 0.8300 - val_auc: 0.8805\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 219ms/step - loss: 0.3193 - accuracy: 0.8730 - auc: 0.9268 - val_loss: 0.3148 - val_accuracy: 0.8480 - val_auc: 0.9396\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 13s 215ms/step - loss: 0.1753 - accuracy: 0.9402 - auc: 0.9759 - val_loss: 0.3908 - val_accuracy: 0.8540 - val_auc: 0.9356\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 13s 212ms/step - loss: 0.1257 - accuracy: 0.9588 - auc: 0.9859 - val_loss: 0.4654 - val_accuracy: 0.8680 - val_auc: 0.9249\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 13s 208ms/step - loss: 0.1041 - accuracy: 0.9670 - auc: 0.9892 - val_loss: 0.4443 - val_accuracy: 0.8640 - val_auc: 0.9225\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 0.0614 - accuracy: 0.9833 - auc: 0.9943 - val_loss: 0.6143 - val_accuracy: 0.8580 - val_auc: 0.8942\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.0301 - accuracy: 0.9945 - auc: 0.9969 - val_loss: 0.6864 - val_accuracy: 0.8740 - val_auc: 0.8820\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 229ms/step - loss: 0.5939 - accuracy: 0.6622 - auc: 0.6576 - val_loss: 0.4544 - val_accuracy: 0.6620 - val_auc: 0.9182\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.4104 - accuracy: 0.7870 - auc: 0.9051 - val_loss: 0.3830 - val_accuracy: 0.8680 - val_auc: 0.9136\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.3454 - accuracy: 0.8997 - auc: 0.9398 - val_loss: 0.3670 - val_accuracy: 0.8840 - val_auc: 0.9279\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.3088 - accuracy: 0.9247 - auc: 0.9559 - val_loss: 0.3733 - val_accuracy: 0.8520 - val_auc: 0.8870\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 219ms/step - loss: 0.2885 - accuracy: 0.9335 - auc: 0.9606 - val_loss: 0.4402 - val_accuracy: 0.8780 - val_auc: 0.9215\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 218ms/step - loss: 0.2578 - accuracy: 0.9475 - auc: 0.9702 - val_loss: 0.4725 - val_accuracy: 0.8640 - val_auc: 0.9128\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 13s 214ms/step - loss: 0.2286 - accuracy: 0.9607 - auc: 0.9767 - val_loss: 0.4509 - val_accuracy: 0.8620 - val_auc: 0.9039\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.2130 - accuracy: 0.9665 - auc: 0.9766 - val_loss: 0.5019 - val_accuracy: 0.8740 - val_auc: 0.8991\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 231ms/step - loss: 0.5801 - accuracy: 0.7110 - auc: 0.7092 - val_loss: 0.4013 - val_accuracy: 0.8240 - val_auc: 0.9206\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.3900 - accuracy: 0.8655 - auc: 0.8991 - val_loss: 0.3293 - val_accuracy: 0.8620 - val_auc: 0.9400\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.2930 - accuracy: 0.9168 - auc: 0.9414 - val_loss: 0.3388 - val_accuracy: 0.8600 - val_auc: 0.9329\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 221ms/step - loss: 0.1962 - accuracy: 0.9555 - auc: 0.9718 - val_loss: 0.4382 - val_accuracy: 0.8660 - val_auc: 0.9273\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 216ms/step - loss: 0.1682 - accuracy: 0.9615 - auc: 0.9744 - val_loss: 0.4998 - val_accuracy: 0.8600 - val_auc: 0.9202\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.1475 - accuracy: 0.9680 - auc: 0.9789 - val_loss: 0.4805 - val_accuracy: 0.8760 - val_auc: 0.9168\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 218ms/step - loss: 0.0989 - accuracy: 0.9822 - auc: 0.9881 - val_loss: 0.5442 - val_accuracy: 0.8680 - val_auc: 0.9147\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 231ms/step - loss: 0.5912 - accuracy: 0.6733 - auc: 0.6720 - val_loss: 0.4494 - val_accuracy: 0.8460 - val_auc: 0.9300\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 14s 219ms/step - loss: 0.3703 - accuracy: 0.8450 - auc: 0.9061 - val_loss: 0.3431 - val_accuracy: 0.8560 - val_auc: 0.9352\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 14s 220ms/step - loss: 0.2568 - accuracy: 0.9032 - auc: 0.9548 - val_loss: 0.3470 - val_accuracy: 0.8600 - val_auc: 0.9256\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.2218 - accuracy: 0.9170 - auc: 0.9645 - val_loss: 0.3368 - val_accuracy: 0.8460 - val_auc: 0.9365\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.1635 - accuracy: 0.9377 - auc: 0.9811 - val_loss: 0.3810 - val_accuracy: 0.8520 - val_auc: 0.9230\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 14s 215ms/step - loss: 0.1290 - accuracy: 0.9538 - auc: 0.9864 - val_loss: 0.5124 - val_accuracy: 0.8600 - val_auc: 0.9090\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 14s 217ms/step - loss: 0.1058 - accuracy: 0.9737 - auc: 0.9907 - val_loss: 0.5806 - val_accuracy: 0.8620 - val_auc: 0.9031\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2950</td>\n",
       "      <td>0.3189</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9357</td>\n",
       "      <td>49</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3542</td>\n",
       "      <td>0.3133</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.9450</td>\n",
       "      <td>50</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3838</td>\n",
       "      <td>0.3534</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.9289</td>\n",
       "      <td>85</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4056</td>\n",
       "      <td>0.3188</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.9363</td>\n",
       "      <td>88</td>\n",
       "      <td>gru</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2238</td>\n",
       "      <td>0.2753</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>65</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3040</td>\n",
       "      <td>0.3118</td>\n",
       "      <td>0.8653</td>\n",
       "      <td>0.9359</td>\n",
       "      <td>63</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3036</td>\n",
       "      <td>0.2966</td>\n",
       "      <td>0.8660</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>100</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.3686</td>\n",
       "      <td>0.3464</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>105</td>\n",
       "      <td>lstm</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2950    0.3189        0.8593   0.9357        49            gru   \n",
       "1  0.3542    0.3133        0.8667   0.9450        50            gru   \n",
       "2  0.3838    0.3534        0.8493   0.9289        85            gru   \n",
       "3  0.4056    0.3188        0.8673   0.9363        88            gru   \n",
       "4  0.2238    0.2753        0.8920   0.9526        65           lstm   \n",
       "5  0.3040    0.3118        0.8653   0.9359        63           lstm   \n",
       "6  0.3036    0.2966        0.8660   0.9426       100           lstm   \n",
       "7  0.3686    0.3464        0.8673   0.9344       105           lstm   \n",
       "\n",
       "   bi_directional  rnn_layers  dense_layers  \n",
       "0            True           1             1  \n",
       "1            True           1             2  \n",
       "2            True           2             1  \n",
       "3            True           2             2  \n",
       "4            True           1             1  \n",
       "5            True           1             2  \n",
       "6            True           2             1  \n",
       "7            True           2             2  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bidirectional it is! 1 parameter down!\n",
    "\n",
    "train_ds, val_ds, vocab_size, sequence_length, batch_size = load_and_prepare_data(\n",
    "    path='data/Airline_review.csv', \n",
    "    include_validation=True, \n",
    "    sample_size=5000, \n",
    "    stop_words=None, \n",
    "    lemmatize=False, \n",
    "    max_tokens=10000, \n",
    "    percentile_len=0.9, \n",
    "    batch_size=64\n",
    ")\n",
    "def run_experiment(recurrent_type, bi_directional, rnn_layers, dense_layers, runs, train_ds, val_ds, epochs, sequence_length, vocab_size):\n",
    "    \"\"\"\n",
    "    Runs the experiment for a specific configuration and returns the average metrics.\n",
    "    \"\"\"\n",
    "    model_function = lambda: build_rnn_model(\n",
    "        rnn_layers=rnn_layers,\n",
    "        dense_layers=dense_layers,\n",
    "        recurrent_type=recurrent_type,\n",
    "        bi_directional=bi_directional,\n",
    "        dropout_rate=0.2,\n",
    "        units=64,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    return calculate_average_metrics(runs, model_function, train_ds, val_ds, epochs)\n",
    "\n",
    "# Configuration options\n",
    "param_dict = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'bi_directional': [True],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2]\n",
    "}\n",
    "\n",
    "configurations = generate_configurations(param_dict)\n",
    "\n",
    "results = []\n",
    "runs = 3\n",
    "epochs = 50\n",
    "\n",
    "# Run experiments\n",
    "for config in configurations:\n",
    "    metrics = run_experiment(\n",
    "        recurrent_type=config['recurrent_type'],\n",
    "        bi_directional=config['bi_directional'],\n",
    "        rnn_layers=config['rnn_layers'],\n",
    "        dense_layers=config['dense_layers'],\n",
    "        runs=runs,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=epochs,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    results.append({\n",
    "        **metrics,\n",
    "        **config  # Unpack configuration into the results\n",
    "    })\n",
    "\n",
    "# Create DataFrame and format\n",
    "df = pd.DataFrame(results)\n",
    "df = df.round({'loss': 4, 'val_loss': 4, 'val_accuracy': 4, 'val_auc': 4})\n",
    "df['duration'] = df['duration'].round(0).astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a78d0d8-5919-429f-9f1f-b0d2a5077680",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a09a216c3dc4b729ad93183c92b03e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/50\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "63/63 [==============================] - 51s 777ms/step - loss: 0.4822 - accuracy: 0.7607 - auc: 0.8163 - val_loss: 0.3788 - val_accuracy: 0.8240 - val_auc: 0.9054\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 50s 788ms/step - loss: 0.2244 - accuracy: 0.9122 - auc: 0.9643 - val_loss: 0.4816 - val_accuracy: 0.8300 - val_auc: 0.9044\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 49s 772ms/step - loss: 0.1234 - accuracy: 0.9597 - auc: 0.9867 - val_loss: 0.7205 - val_accuracy: 0.8240 - val_auc: 0.8930\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 49s 773ms/step - loss: 0.0772 - accuracy: 0.9747 - auc: 0.9944 - val_loss: 0.7240 - val_accuracy: 0.8080 - val_auc: 0.8716\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 50s 792ms/step - loss: 0.1219 - accuracy: 0.9582 - auc: 0.9901 - val_loss: 0.6939 - val_accuracy: 0.8180 - val_auc: 0.8684\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 49s 783ms/step - loss: 0.0518 - accuracy: 0.9822 - auc: 0.9976 - val_loss: 1.0951 - val_accuracy: 0.8040 - val_auc: 0.8375\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 54s 817ms/step - loss: 0.4868 - accuracy: 0.7617 - auc: 0.8143 - val_loss: 0.3698 - val_accuracy: 0.8240 - val_auc: 0.9079\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 49s 782ms/step - loss: 0.2219 - accuracy: 0.9165 - auc: 0.9647 - val_loss: 0.5064 - val_accuracy: 0.8260 - val_auc: 0.9086\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 49s 772ms/step - loss: 0.1182 - accuracy: 0.9643 - auc: 0.9874 - val_loss: 0.6670 - val_accuracy: 0.8260 - val_auc: 0.8826\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 50s 792ms/step - loss: 0.0992 - accuracy: 0.9670 - auc: 0.9912 - val_loss: 0.8783 - val_accuracy: 0.7920 - val_auc: 0.8363\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 49s 779ms/step - loss: 0.0888 - accuracy: 0.9690 - auc: 0.9937 - val_loss: 1.4239 - val_accuracy: 0.8060 - val_auc: 0.8162\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 49s 779ms/step - loss: 0.0810 - accuracy: 0.9730 - auc: 0.9942 - val_loss: 1.0134 - val_accuracy: 0.7920 - val_auc: 0.8358\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 41s 612ms/step - loss: 0.5085 - accuracy: 0.7500 - auc: 0.8048 - val_loss: 0.3778 - val_accuracy: 0.8380 - val_auc: 0.9075\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 38s 600ms/step - loss: 0.2324 - accuracy: 0.9118 - auc: 0.9612 - val_loss: 0.3438 - val_accuracy: 0.8580 - val_auc: 0.9188\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 38s 609ms/step - loss: 0.1429 - accuracy: 0.9520 - auc: 0.9838 - val_loss: 0.6851 - val_accuracy: 0.8520 - val_auc: 0.8896\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 37s 587ms/step - loss: 0.1491 - accuracy: 0.9492 - auc: 0.9832 - val_loss: 0.8423 - val_accuracy: 0.8480 - val_auc: 0.8684\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 38s 603ms/step - loss: 0.0798 - accuracy: 0.9758 - auc: 0.9936 - val_loss: 0.7404 - val_accuracy: 0.8220 - val_auc: 0.8500\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 38s 599ms/step - loss: 0.0460 - accuracy: 0.9860 - auc: 0.9973 - val_loss: 0.8130 - val_accuracy: 0.8320 - val_auc: 0.8608\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 38s 609ms/step - loss: 0.0230 - accuracy: 0.9933 - auc: 0.9989 - val_loss: 0.8938 - val_accuracy: 0.8280 - val_auc: 0.8511\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 53s 803ms/step - loss: 0.4631 - accuracy: 0.7918 - auc: 0.8469 - val_loss: 0.3301 - val_accuracy: 0.8700 - val_auc: 0.9294\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 49s 778ms/step - loss: 0.1973 - accuracy: 0.9323 - auc: 0.9699 - val_loss: 0.4346 - val_accuracy: 0.8260 - val_auc: 0.9184\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 49s 770ms/step - loss: 0.1266 - accuracy: 0.9570 - auc: 0.9858 - val_loss: 0.4790 - val_accuracy: 0.8400 - val_auc: 0.8989\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 50s 789ms/step - loss: 0.0995 - accuracy: 0.9680 - auc: 0.9917 - val_loss: 0.6475 - val_accuracy: 0.8520 - val_auc: 0.8881\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 50s 795ms/step - loss: 0.0831 - accuracy: 0.9725 - auc: 0.9934 - val_loss: 0.6972 - val_accuracy: 0.8220 - val_auc: 0.8829\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 50s 793ms/step - loss: 0.0537 - accuracy: 0.9833 - auc: 0.9966 - val_loss: 0.7713 - val_accuracy: 0.8120 - val_auc: 0.8774\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.3743</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.9066</td>\n",
       "      <td>299</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3477</td>\n",
       "      <td>0.3369</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>284</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.4845    0.3743         0.824   0.9066       299            gru   \n",
       "1  0.3477    0.3369         0.864   0.9241       284           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  \n",
       "0           1             1    256  \n",
       "1           1             1    256  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bidirectional it is! 1 parameter down!\n",
    "\n",
    "train_ds, val_ds, vocab_size, sequence_length, batch_size = load_and_prepare_data(\n",
    "    path='data/Airline_review.csv', \n",
    "    include_validation=True, \n",
    "    sample_size=5000, \n",
    "    stop_words=None, \n",
    "    lemmatize=False, \n",
    "    max_tokens=10000, \n",
    "    percentile_len=0.9, \n",
    "    batch_size=64\n",
    ")\n",
    "def run_experiment(units, recurrent_type, rnn_layers, dense_layers, runs, train_ds, val_ds, epochs, sequence_length, vocab_size, dropout_rate):\n",
    "    \"\"\"\n",
    "    Runs the experiment for a specific configuration and returns the average metrics.\n",
    "    \"\"\"\n",
    "    model_function = lambda: build_rnn_model(\n",
    "        rnn_layers=rnn_layers,\n",
    "        dense_layers=dense_layers,\n",
    "        recurrent_type=recurrent_type,\n",
    "        bi_directional=True,\n",
    "        dropout_rate=dropout_rate,\n",
    "        units=units,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    return calculate_average_metrics(runs, model_function, train_ds, val_ds, epochs)\n",
    "\n",
    "# Configuration options\n",
    "param_dict = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [256]\n",
    "}\n",
    "\n",
    "configurations = generate_configurations(param_dict)\n",
    "\n",
    "results = []\n",
    "runs = 2\n",
    "epochs = 50\n",
    "\n",
    "# Run experiments\n",
    "for config in tqdm(configurations,\"Running Configurations\"):\n",
    "    metrics = run_experiment(\n",
    "        units=config['units'],\n",
    "        recurrent_type=config['recurrent_type'],\n",
    "        rnn_layers=config['rnn_layers'],\n",
    "        dense_layers=config['dense_layers'],\n",
    "        dropout_rate = 0.2,\n",
    "        runs=runs,\n",
    "        train_ds=train_ds,\n",
    "        val_ds=val_ds,\n",
    "        epochs=epochs,\n",
    "        sequence_length=sequence_length,\n",
    "        vocab_size=vocab_size\n",
    "    )\n",
    "    results.append({\n",
    "        **metrics,\n",
    "        **config  # Unpack configuration into the results\n",
    "    })\n",
    "\n",
    "# Create DataFrame and format\n",
    "df = pd.DataFrame(results)\n",
    "df = df.round({'loss': 4, 'val_loss': 4, 'val_accuracy': 4, 'val_auc': 4})\n",
    "df['duration'] = df['duration'].round(0).astype(int)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20e10257-fa55-4a8f-bc1b-907c865649f4",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def iterate(sample_size,\n",
    "            max_tokens,\n",
    "            percentile_len,\n",
    "            batch_size,\n",
    "            param_dict,\n",
    "            runs,\n",
    "            epochs):\n",
    "\n",
    "    train_ds, val_ds, vocab_size, sequence_length, batch_size = load_and_prepare_data(\n",
    "        path='data/Airline_review.csv', \n",
    "        include_validation=True, \n",
    "        sample_size=sample_size, \n",
    "        stop_words=None, \n",
    "        lemmatize=False, \n",
    "        max_tokens=max_tokens, \n",
    "        percentile_len=percentile_len, \n",
    "        batch_size=batch_size\n",
    "    )\n",
    "    def run_experiment(units, recurrent_type, rnn_layers, dense_layers, runs, train_ds, val_ds, epochs, sequence_length, vocab_size, dropout_rate, bi_directional):\n",
    "        \"\"\"\n",
    "        Runs the experiment for a specific configuration and returns the average metrics.\n",
    "        \"\"\"\n",
    "        model_function = lambda: build_rnn_model(\n",
    "            rnn_layers=rnn_layers,\n",
    "            dense_layers=dense_layers,\n",
    "            recurrent_type=recurrent_type,\n",
    "            bi_directional=bi_directional,\n",
    "            dropout_rate=dropout_rate,\n",
    "            units=units,\n",
    "            sequence_length=sequence_length,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "        return calculate_average_metrics(runs, model_function, train_ds, val_ds, epochs)\n",
    "    \n",
    "    configurations = generate_configurations(param_dict)\n",
    "    \n",
    "    results = []\n",
    "  \n",
    "    for config in tqdm(configurations,\"Running Configurations\"):\n",
    "        metrics = run_experiment(\n",
    "            units=config['units'],\n",
    "            recurrent_type=config['recurrent_type'],\n",
    "            rnn_layers=config['rnn_layers'],\n",
    "            dense_layers=config['dense_layers'],\n",
    "            dropout_rate = config['dropout_rate'],\n",
    "            bi_directional=config['bi_directional'],\n",
    "            runs=runs,\n",
    "            train_ds=train_ds,\n",
    "            val_ds=val_ds,\n",
    "            epochs=epochs,\n",
    "            sequence_length=sequence_length,\n",
    "            vocab_size=vocab_size\n",
    "        )\n",
    "        results.append({\n",
    "            **metrics,\n",
    "            **config  # Unpack configuration into the results\n",
    "        })\n",
    "    \n",
    "    # Create DataFrame and format\n",
    "    df = pd.DataFrame(results)\n",
    "    df = df.round({'loss': 4, 'val_loss': 4, 'val_accuracy': 4, 'val_auc': 4})\n",
    "    df['duration'] = df['duration'].round(0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18d3a4d5-7512-49f2-874e-34615088161c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5773bf8efe44518d9de43b13d72af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 28s 104ms/step - loss: 0.3703 - accuracy: 0.8313 - auc: 0.9009 - val_loss: 0.2554 - val_accuracy: 0.8940 - val_auc: 0.9546\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 0.1980 - accuracy: 0.9246 - auc: 0.9717 - val_loss: 0.2723 - val_accuracy: 0.8955 - val_auc: 0.9529\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 25s 99ms/step - loss: 0.1802 - accuracy: 0.9353 - auc: 0.9758 - val_loss: 0.2697 - val_accuracy: 0.9005 - val_auc: 0.9552\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 24s 98ms/step - loss: 0.1390 - accuracy: 0.9506 - auc: 0.9846 - val_loss: 0.4593 - val_accuracy: 0.8910 - val_auc: 0.9221\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.1135 - accuracy: 0.9620 - auc: 0.9890 - val_loss: 0.3579 - val_accuracy: 0.9015 - val_auc: 0.9464\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 25s 100ms/step - loss: 0.1163 - accuracy: 0.9594 - auc: 0.9888 - val_loss: 0.3955 - val_accuracy: 0.8985 - val_auc: 0.9412\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 27s 98ms/step - loss: 0.4005 - accuracy: 0.8129 - auc: 0.8813 - val_loss: 0.2855 - val_accuracy: 0.8810 - val_auc: 0.9438\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 24s 95ms/step - loss: 0.2225 - accuracy: 0.9154 - auc: 0.9651 - val_loss: 0.2704 - val_accuracy: 0.8960 - val_auc: 0.9527\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 24s 97ms/step - loss: 0.1638 - accuracy: 0.9416 - auc: 0.9801 - val_loss: 0.3050 - val_accuracy: 0.8950 - val_auc: 0.9503\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 24s 96ms/step - loss: 0.1293 - accuracy: 0.9581 - auc: 0.9865 - val_loss: 0.3477 - val_accuracy: 0.8905 - val_auc: 0.9431\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 24s 96ms/step - loss: 0.1209 - accuracy: 0.9588 - auc: 0.9885 - val_loss: 0.3391 - val_accuracy: 0.8925 - val_auc: 0.9456\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 24s 94ms/step - loss: 0.1045 - accuracy: 0.9650 - auc: 0.9910 - val_loss: 0.3759 - val_accuracy: 0.8755 - val_auc: 0.9442\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 23s 93ms/step - loss: 0.1027 - accuracy: 0.9636 - auc: 0.9916 - val_loss: 0.3704 - val_accuracy: 0.8930 - val_auc: 0.9414\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 40s 149ms/step - loss: 0.3578 - accuracy: 0.8392 - auc: 0.9095 - val_loss: 0.2451 - val_accuracy: 0.9000 - val_auc: 0.9590\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 34s 136ms/step - loss: 0.1988 - accuracy: 0.9277 - auc: 0.9709 - val_loss: 0.2410 - val_accuracy: 0.9070 - val_auc: 0.9601\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 33s 133ms/step - loss: 0.1541 - accuracy: 0.9467 - auc: 0.9813 - val_loss: 0.4515 - val_accuracy: 0.8875 - val_auc: 0.9200\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 32s 128ms/step - loss: 0.1283 - accuracy: 0.9564 - auc: 0.9865 - val_loss: 0.3356 - val_accuracy: 0.9055 - val_auc: 0.9459\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1144 - accuracy: 0.9626 - auc: 0.9888 - val_loss: 0.3000 - val_accuracy: 0.8970 - val_auc: 0.9483\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.1077 - accuracy: 0.9624 - auc: 0.9905 - val_loss: 0.3883 - val_accuracy: 0.8940 - val_auc: 0.9449\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 32s 118ms/step - loss: 0.3525 - accuracy: 0.8446 - auc: 0.9126 - val_loss: 0.2667 - val_accuracy: 0.8885 - val_auc: 0.9611\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1921 - accuracy: 0.9327 - auc: 0.9722 - val_loss: 0.3143 - val_accuracy: 0.8910 - val_auc: 0.9549\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1692 - accuracy: 0.9421 - auc: 0.9772 - val_loss: 0.2637 - val_accuracy: 0.9140 - val_auc: 0.9596\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1328 - accuracy: 0.9561 - auc: 0.9853 - val_loss: 0.3453 - val_accuracy: 0.9030 - val_auc: 0.9482\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 30s 119ms/step - loss: 0.1288 - accuracy: 0.9556 - auc: 0.9865 - val_loss: 0.3154 - val_accuracy: 0.9005 - val_auc: 0.9541\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0878 - accuracy: 0.9736 - auc: 0.9922 - val_loss: 0.3830 - val_accuracy: 0.8920 - val_auc: 0.9468\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2964</td>\n",
       "      <td>0.2629</td>\n",
       "      <td>0.8950</td>\n",
       "      <td>0.9536</td>\n",
       "      <td>161</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3552</td>\n",
       "      <td>0.2559</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>191</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2964    0.2629        0.8950   0.9536       161            gru   \n",
       "1  0.3552    0.2559        0.8942   0.9600       191           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     64           0.2            True  \n",
       "1           1             1     64           0.2            True  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [64],\n",
    "    'dropout_rate': [0.2],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=20000,\n",
    "        max_tokens=10000,\n",
    "        percentile_len=0.9,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "50457f57-453e-4b9a-9f6f-881a65c13e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34fe3ae5e0ca49c19cfa60186e634dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 110ms/step - loss: 0.5846 - accuracy: 0.7023 - auc: 0.6726 - val_loss: 0.3628 - val_accuracy: 0.8440 - val_auc: 0.9219\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.2925 - accuracy: 0.8780 - auc: 0.9411 - val_loss: 0.3066 - val_accuracy: 0.8780 - val_auc: 0.9485\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.1480 - accuracy: 0.9500 - auc: 0.9831 - val_loss: 0.3396 - val_accuracy: 0.8920 - val_auc: 0.9479\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 6s 103ms/step - loss: 0.0690 - accuracy: 0.9818 - auc: 0.9946 - val_loss: 0.4326 - val_accuracy: 0.8820 - val_auc: 0.9361\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 6s 94ms/step - loss: 0.0528 - accuracy: 0.9827 - auc: 0.9975 - val_loss: 0.7267 - val_accuracy: 0.8620 - val_auc: 0.8847\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 6s 103ms/step - loss: 0.0592 - accuracy: 0.9778 - auc: 0.9967 - val_loss: 0.6714 - val_accuracy: 0.8580 - val_auc: 0.8965\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0268 - accuracy: 0.9915 - auc: 0.9991 - val_loss: 0.8272 - val_accuracy: 0.8460 - val_auc: 0.8755\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 106ms/step - loss: 0.5978 - accuracy: 0.6833 - auc: 0.6405 - val_loss: 0.3714 - val_accuracy: 0.8360 - val_auc: 0.9196\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 6s 97ms/step - loss: 0.3088 - accuracy: 0.8742 - auc: 0.9336 - val_loss: 0.2988 - val_accuracy: 0.8800 - val_auc: 0.9446\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 6s 96ms/step - loss: 0.1592 - accuracy: 0.9425 - auc: 0.9812 - val_loss: 0.3384 - val_accuracy: 0.8840 - val_auc: 0.9404\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 6s 99ms/step - loss: 0.0836 - accuracy: 0.9718 - auc: 0.9930 - val_loss: 0.3619 - val_accuracy: 0.8780 - val_auc: 0.9336\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 6s 95ms/step - loss: 0.0719 - accuracy: 0.9770 - auc: 0.9952 - val_loss: 0.5610 - val_accuracy: 0.8620 - val_auc: 0.9189\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 6s 100ms/step - loss: 0.0445 - accuracy: 0.9860 - auc: 0.9975 - val_loss: 0.4905 - val_accuracy: 0.8700 - val_auc: 0.9194\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 6s 96ms/step - loss: 0.0126 - accuracy: 0.9967 - auc: 0.9991 - val_loss: 0.7496 - val_accuracy: 0.8580 - val_auc: 0.8872\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 11s 135ms/step - loss: 0.5715 - accuracy: 0.7040 - auc: 0.6996 - val_loss: 0.3401 - val_accuracy: 0.8820 - val_auc: 0.9272\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 8s 126ms/step - loss: 0.2735 - accuracy: 0.8915 - auc: 0.9472 - val_loss: 0.3144 - val_accuracy: 0.8560 - val_auc: 0.9342\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 8s 126ms/step - loss: 0.1363 - accuracy: 0.9550 - auc: 0.9854 - val_loss: 0.3035 - val_accuracy: 0.8760 - val_auc: 0.9461\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 8s 128ms/step - loss: 0.0668 - accuracy: 0.9818 - auc: 0.9944 - val_loss: 0.8442 - val_accuracy: 0.8180 - val_auc: 0.8949\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 8s 123ms/step - loss: 0.0725 - accuracy: 0.9785 - auc: 0.9947 - val_loss: 0.5814 - val_accuracy: 0.8660 - val_auc: 0.9020\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 124ms/step - loss: 0.0275 - accuracy: 0.9915 - auc: 0.9985 - val_loss: 0.5180 - val_accuracy: 0.8680 - val_auc: 0.9176\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 8s 126ms/step - loss: 0.0175 - accuracy: 0.9952 - auc: 0.9994 - val_loss: 0.5335 - val_accuracy: 0.8720 - val_auc: 0.9144\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 7s 118ms/step - loss: 0.0155 - accuracy: 0.9948 - auc: 0.9996 - val_loss: 0.5520 - val_accuracy: 0.8540 - val_auc: 0.9066\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 126ms/step - loss: 0.5655 - accuracy: 0.7107 - auc: 0.7057 - val_loss: 0.3379 - val_accuracy: 0.8740 - val_auc: 0.9319\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 8s 120ms/step - loss: 0.2685 - accuracy: 0.8947 - auc: 0.9489 - val_loss: 0.2840 - val_accuracy: 0.8840 - val_auc: 0.9460\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 8s 123ms/step - loss: 0.1362 - accuracy: 0.9542 - auc: 0.9847 - val_loss: 0.3301 - val_accuracy: 0.8980 - val_auc: 0.9488\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 8s 122ms/step - loss: 0.0647 - accuracy: 0.9808 - auc: 0.9954 - val_loss: 0.4726 - val_accuracy: 0.8820 - val_auc: 0.9168\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 8s 122ms/step - loss: 0.0358 - accuracy: 0.9887 - auc: 0.9978 - val_loss: 0.4368 - val_accuracy: 0.8720 - val_auc: 0.9274\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 8s 121ms/step - loss: 0.0287 - accuracy: 0.9908 - auc: 0.9991 - val_loss: 0.5425 - val_accuracy: 0.8400 - val_auc: 0.9144\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 8s 125ms/step - loss: 0.0265 - accuracy: 0.9925 - auc: 0.9983 - val_loss: 0.5685 - val_accuracy: 0.8720 - val_auc: 0.8969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3007</td>\n",
       "      <td>0.3027</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>47</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.9460</td>\n",
       "      <td>61</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.3007    0.3027         0.879   0.9465        47            gru   \n",
       "1  0.2024    0.2937         0.880   0.9460        61           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     64           0.2            True  \n",
       "1           1             1     64           0.2            True  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [64],\n",
    "    'dropout_rate': [0.2],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=20000,\n",
    "        percentile_len=0.9,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36699659-b7e8-41a0-b6fb-ddb86e9e006c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f4298eea8094c04b64827e572a7a6f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "250/250 [==============================] - 32s 118ms/step - loss: 0.3684 - accuracy: 0.8345 - auc: 0.9019 - val_loss: 0.2414 - val_accuracy: 0.9075 - val_auc: 0.9589\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.1976 - accuracy: 0.9272 - auc: 0.9711 - val_loss: 0.2835 - val_accuracy: 0.8850 - val_auc: 0.9541\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1483 - accuracy: 0.9491 - auc: 0.9824 - val_loss: 0.2879 - val_accuracy: 0.8865 - val_auc: 0.9511\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.1187 - accuracy: 0.9617 - auc: 0.9878 - val_loss: 0.2758 - val_accuracy: 0.9005 - val_auc: 0.9568\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.1016 - accuracy: 0.9653 - auc: 0.9911 - val_loss: 0.3125 - val_accuracy: 0.9015 - val_auc: 0.9561\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1073 - accuracy: 0.9616 - auc: 0.9906 - val_loss: 0.2988 - val_accuracy: 0.8880 - val_auc: 0.9519\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 32s 120ms/step - loss: 0.3692 - accuracy: 0.8333 - auc: 0.9004 - val_loss: 0.2436 - val_accuracy: 0.9010 - val_auc: 0.9601\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 30s 118ms/step - loss: 0.1985 - accuracy: 0.9256 - auc: 0.9713 - val_loss: 0.2570 - val_accuracy: 0.8975 - val_auc: 0.9572\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 29s 116ms/step - loss: 0.1494 - accuracy: 0.9486 - auc: 0.9824 - val_loss: 0.2752 - val_accuracy: 0.8995 - val_auc: 0.9558\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1213 - accuracy: 0.9581 - auc: 0.9874 - val_loss: 0.2928 - val_accuracy: 0.8925 - val_auc: 0.9524\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 29s 117ms/step - loss: 0.1006 - accuracy: 0.9666 - auc: 0.9909 - val_loss: 0.2945 - val_accuracy: 0.8945 - val_auc: 0.9522\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 29s 118ms/step - loss: 0.0997 - accuracy: 0.9652 - auc: 0.9916 - val_loss: 0.2863 - val_accuracy: 0.8935 - val_auc: 0.9517\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 33s 124ms/step - loss: 0.3939 - accuracy: 0.8211 - auc: 0.8908 - val_loss: 0.2418 - val_accuracy: 0.9035 - val_auc: 0.9599\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 31s 124ms/step - loss: 0.2060 - accuracy: 0.9256 - auc: 0.9693 - val_loss: 0.2662 - val_accuracy: 0.8880 - val_auc: 0.9583\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1547 - accuracy: 0.9473 - auc: 0.9819 - val_loss: 0.2565 - val_accuracy: 0.9110 - val_auc: 0.9628\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 31s 123ms/step - loss: 0.1287 - accuracy: 0.9547 - auc: 0.9866 - val_loss: 0.3223 - val_accuracy: 0.8900 - val_auc: 0.9565\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1060 - accuracy: 0.9644 - auc: 0.9910 - val_loss: 0.2824 - val_accuracy: 0.8935 - val_auc: 0.9556\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.0880 - accuracy: 0.9703 - auc: 0.9931 - val_loss: 0.3535 - val_accuracy: 0.8900 - val_auc: 0.9497\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 34s 125ms/step - loss: 0.3990 - accuracy: 0.8212 - auc: 0.8847 - val_loss: 0.2506 - val_accuracy: 0.9015 - val_auc: 0.9570\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.2034 - accuracy: 0.9260 - auc: 0.9705 - val_loss: 0.2539 - val_accuracy: 0.9010 - val_auc: 0.9578\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1610 - accuracy: 0.9436 - auc: 0.9805 - val_loss: 0.3146 - val_accuracy: 0.8595 - val_auc: 0.9324\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.1408 - accuracy: 0.9517 - auc: 0.9848 - val_loss: 0.2919 - val_accuracy: 0.8865 - val_auc: 0.9524\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 30s 121ms/step - loss: 0.1037 - accuracy: 0.9656 - auc: 0.9907 - val_loss: 0.3072 - val_accuracy: 0.8960 - val_auc: 0.9538\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 30s 120ms/step - loss: 0.0871 - accuracy: 0.9718 - auc: 0.9929 - val_loss: 0.3419 - val_accuracy: 0.8955 - val_auc: 0.9507\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 57s 210ms/step - loss: 0.3831 - accuracy: 0.8289 - auc: 0.8941 - val_loss: 0.2533 - val_accuracy: 0.8965 - val_auc: 0.9569\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 51s 203ms/step - loss: 0.1990 - accuracy: 0.9271 - auc: 0.9702 - val_loss: 0.2570 - val_accuracy: 0.8990 - val_auc: 0.9551\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 50s 202ms/step - loss: 0.1440 - accuracy: 0.9510 - auc: 0.9830 - val_loss: 0.2861 - val_accuracy: 0.8930 - val_auc: 0.9510\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 51s 206ms/step - loss: 0.1032 - accuracy: 0.9669 - auc: 0.9899 - val_loss: 0.3176 - val_accuracy: 0.8820 - val_auc: 0.9493\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 53s 212ms/step - loss: 0.1031 - accuracy: 0.9651 - auc: 0.9908 - val_loss: 0.3309 - val_accuracy: 0.8870 - val_auc: 0.9492\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.0976 - accuracy: 0.9665 - auc: 0.9921 - val_loss: 0.3524 - val_accuracy: 0.8965 - val_auc: 0.9473\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 57s 213ms/step - loss: 0.3747 - accuracy: 0.8306 - auc: 0.8993 - val_loss: 0.2481 - val_accuracy: 0.9005 - val_auc: 0.9589\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 53s 211ms/step - loss: 0.1986 - accuracy: 0.9274 - auc: 0.9707 - val_loss: 0.2781 - val_accuracy: 0.8975 - val_auc: 0.9548\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 53s 210ms/step - loss: 0.1441 - accuracy: 0.9516 - auc: 0.9823 - val_loss: 0.2823 - val_accuracy: 0.9030 - val_auc: 0.9566\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 51s 206ms/step - loss: 0.1125 - accuracy: 0.9621 - auc: 0.9883 - val_loss: 0.3079 - val_accuracy: 0.8960 - val_auc: 0.9535\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 51s 205ms/step - loss: 0.1017 - accuracy: 0.9663 - auc: 0.9907 - val_loss: 0.3369 - val_accuracy: 0.8670 - val_auc: 0.9410\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 51s 206ms/step - loss: 0.0923 - accuracy: 0.9701 - auc: 0.9918 - val_loss: 0.3086 - val_accuracy: 0.8945 - val_auc: 0.9491\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 54s 201ms/step - loss: 0.4202 - accuracy: 0.8192 - auc: 0.8702 - val_loss: 0.2546 - val_accuracy: 0.9010 - val_auc: 0.9549\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 49s 196ms/step - loss: 0.2375 - accuracy: 0.9208 - auc: 0.9614 - val_loss: 0.2847 - val_accuracy: 0.8800 - val_auc: 0.9518\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 49s 195ms/step - loss: 0.1776 - accuracy: 0.9466 - auc: 0.9771 - val_loss: 0.2597 - val_accuracy: 0.8980 - val_auc: 0.9587\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 0.1453 - accuracy: 0.9582 - auc: 0.9840 - val_loss: 0.2778 - val_accuracy: 0.9035 - val_auc: 0.9594\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 48s 190ms/step - loss: 0.1279 - accuracy: 0.9644 - auc: 0.9868 - val_loss: 0.3160 - val_accuracy: 0.8940 - val_auc: 0.9547\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 48s 190ms/step - loss: 0.1109 - accuracy: 0.9694 - auc: 0.9901 - val_loss: 0.3523 - val_accuracy: 0.8910 - val_auc: 0.9488\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 55s 202ms/step - loss: 0.4253 - accuracy: 0.8111 - auc: 0.8668 - val_loss: 0.2773 - val_accuracy: 0.8795 - val_auc: 0.9520\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.2311 - accuracy: 0.9175 - auc: 0.9628 - val_loss: 0.2448 - val_accuracy: 0.8970 - val_auc: 0.9629\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.1643 - accuracy: 0.9452 - auc: 0.9800 - val_loss: 0.2982 - val_accuracy: 0.8850 - val_auc: 0.9599\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.1269 - accuracy: 0.9603 - auc: 0.9868 - val_loss: 0.3359 - val_accuracy: 0.9040 - val_auc: 0.9564\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 50s 201ms/step - loss: 0.0954 - accuracy: 0.9724 - auc: 0.9917 - val_loss: 0.3515 - val_accuracy: 0.8955 - val_auc: 0.9501\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.0785 - accuracy: 0.9774 - auc: 0.9941 - val_loss: 0.4622 - val_accuracy: 0.8980 - val_auc: 0.9287\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 50s 199ms/step - loss: 0.0771 - accuracy: 0.9765 - auc: 0.9944 - val_loss: 0.4928 - val_accuracy: 0.8870 - val_auc: 0.9265\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 40s 152ms/step - loss: 0.3312 - accuracy: 0.8564 - auc: 0.9220 - val_loss: 0.2389 - val_accuracy: 0.9095 - val_auc: 0.9636\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 38s 150ms/step - loss: 0.1830 - accuracy: 0.9327 - auc: 0.9746 - val_loss: 0.2436 - val_accuracy: 0.9040 - val_auc: 0.9649\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.1390 - accuracy: 0.9516 - auc: 0.9837 - val_loss: 0.2647 - val_accuracy: 0.8915 - val_auc: 0.9566\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.1125 - accuracy: 0.9635 - auc: 0.9891 - val_loss: 0.3027 - val_accuracy: 0.8820 - val_auc: 0.9459\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.1127 - accuracy: 0.9605 - auc: 0.9897 - val_loss: 0.3111 - val_accuracy: 0.8870 - val_auc: 0.9473\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.0775 - accuracy: 0.9737 - auc: 0.9947 - val_loss: 0.4174 - val_accuracy: 0.8695 - val_auc: 0.9315\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 40s 151ms/step - loss: 0.3512 - accuracy: 0.8465 - auc: 0.9117 - val_loss: 0.2242 - val_accuracy: 0.9090 - val_auc: 0.9655\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.1854 - accuracy: 0.9334 - auc: 0.9739 - val_loss: 0.2393 - val_accuracy: 0.9040 - val_auc: 0.9620\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.1464 - accuracy: 0.9485 - auc: 0.9831 - val_loss: 0.2458 - val_accuracy: 0.9060 - val_auc: 0.9630\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.1202 - accuracy: 0.9596 - auc: 0.9879 - val_loss: 0.2642 - val_accuracy: 0.9035 - val_auc: 0.9582\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.0996 - accuracy: 0.9686 - auc: 0.9911 - val_loss: 0.3115 - val_accuracy: 0.9060 - val_auc: 0.9540\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 38s 151ms/step - loss: 0.0960 - accuracy: 0.9649 - auc: 0.9927 - val_loss: 0.4042 - val_accuracy: 0.8960 - val_auc: 0.9395\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 40s 153ms/step - loss: 0.3700 - accuracy: 0.8389 - auc: 0.9049 - val_loss: 0.2520 - val_accuracy: 0.8940 - val_auc: 0.9599\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 37s 150ms/step - loss: 0.2020 - accuracy: 0.9295 - auc: 0.9695 - val_loss: 0.2754 - val_accuracy: 0.8870 - val_auc: 0.9555\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.1802 - accuracy: 0.9371 - auc: 0.9755 - val_loss: 0.2715 - val_accuracy: 0.8920 - val_auc: 0.9549\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 37s 150ms/step - loss: 0.1351 - accuracy: 0.9547 - auc: 0.9853 - val_loss: 0.2762 - val_accuracy: 0.8975 - val_auc: 0.9551\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 38s 152ms/step - loss: 0.1039 - accuracy: 0.9676 - auc: 0.9904 - val_loss: 0.3780 - val_accuracy: 0.8900 - val_auc: 0.9443\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 37s 149ms/step - loss: 0.0878 - accuracy: 0.9714 - auc: 0.9929 - val_loss: 0.4061 - val_accuracy: 0.8860 - val_auc: 0.9397\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 40s 150ms/step - loss: 0.3722 - accuracy: 0.8384 - auc: 0.9030 - val_loss: 0.2327 - val_accuracy: 0.9055 - val_auc: 0.9625\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 36s 145ms/step - loss: 0.2131 - accuracy: 0.9227 - auc: 0.9670 - val_loss: 0.2724 - val_accuracy: 0.8905 - val_auc: 0.9608\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.1519 - accuracy: 0.9485 - auc: 0.9819 - val_loss: 0.2715 - val_accuracy: 0.8940 - val_auc: 0.9626\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 37s 148ms/step - loss: 0.1346 - accuracy: 0.9561 - auc: 0.9858 - val_loss: 0.2987 - val_accuracy: 0.8970 - val_auc: 0.9549\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.1143 - accuracy: 0.9619 - auc: 0.9893 - val_loss: 0.3147 - val_accuracy: 0.9020 - val_auc: 0.9557\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 37s 147ms/step - loss: 0.0863 - accuracy: 0.9719 - auc: 0.9932 - val_loss: 0.4174 - val_accuracy: 0.8925 - val_auc: 0.9403\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 62s 232ms/step - loss: 0.3608 - accuracy: 0.8446 - auc: 0.9064 - val_loss: 0.2245 - val_accuracy: 0.9150 - val_auc: 0.9651\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 58s 232ms/step - loss: 0.1893 - accuracy: 0.9334 - auc: 0.9729 - val_loss: 0.2246 - val_accuracy: 0.9140 - val_auc: 0.9674\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 60s 241ms/step - loss: 0.1388 - accuracy: 0.9532 - auc: 0.9842 - val_loss: 0.2636 - val_accuracy: 0.8945 - val_auc: 0.9611\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.1108 - accuracy: 0.9632 - auc: 0.9887 - val_loss: 0.2919 - val_accuracy: 0.8855 - val_auc: 0.9508\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.0985 - accuracy: 0.9682 - auc: 0.9909 - val_loss: 0.3366 - val_accuracy: 0.8690 - val_auc: 0.9392\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 59s 234ms/step - loss: 0.0853 - accuracy: 0.9718 - auc: 0.9930 - val_loss: 0.4105 - val_accuracy: 0.8850 - val_auc: 0.9361\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 63s 235ms/step - loss: 0.3785 - accuracy: 0.8418 - auc: 0.8957 - val_loss: 0.2443 - val_accuracy: 0.8960 - val_auc: 0.9620\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 58s 231ms/step - loss: 0.2019 - accuracy: 0.9285 - auc: 0.9682 - val_loss: 0.2478 - val_accuracy: 0.8990 - val_auc: 0.9651\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 57s 227ms/step - loss: 0.1474 - accuracy: 0.9494 - auc: 0.9815 - val_loss: 0.2529 - val_accuracy: 0.9095 - val_auc: 0.9647\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 57s 229ms/step - loss: 0.1040 - accuracy: 0.9674 - auc: 0.9891 - val_loss: 0.3030 - val_accuracy: 0.9100 - val_auc: 0.9555\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 57s 230ms/step - loss: 0.0840 - accuracy: 0.9737 - auc: 0.9925 - val_loss: 0.3428 - val_accuracy: 0.8970 - val_auc: 0.9445\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 57s 228ms/step - loss: 0.0788 - accuracy: 0.9762 - auc: 0.9930 - val_loss: 0.3750 - val_accuracy: 0.8890 - val_auc: 0.9388\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 64s 241ms/step - loss: 0.5113 - accuracy: 0.7540 - auc: 0.7948 - val_loss: 0.2847 - val_accuracy: 0.8795 - val_auc: 0.9493\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 60s 240ms/step - loss: 0.2638 - accuracy: 0.9061 - auc: 0.9508 - val_loss: 0.2446 - val_accuracy: 0.9050 - val_auc: 0.9589\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.1986 - accuracy: 0.9362 - auc: 0.9708 - val_loss: 0.2396 - val_accuracy: 0.9040 - val_auc: 0.9622\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.1479 - accuracy: 0.9523 - auc: 0.9821 - val_loss: 0.2688 - val_accuracy: 0.9100 - val_auc: 0.9619\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 59s 237ms/step - loss: 0.1147 - accuracy: 0.9658 - auc: 0.9889 - val_loss: 0.3115 - val_accuracy: 0.8960 - val_auc: 0.9553\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 59s 236ms/step - loss: 0.0932 - accuracy: 0.9728 - auc: 0.9917 - val_loss: 0.4115 - val_accuracy: 0.8990 - val_auc: 0.9394\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 59s 235ms/step - loss: 0.0937 - accuracy: 0.9733 - auc: 0.9915 - val_loss: 0.4407 - val_accuracy: 0.8910 - val_auc: 0.9372\n",
      "Epoch 1/50\n",
      "250/250 [==============================] - 64s 240ms/step - loss: 0.5490 - accuracy: 0.7362 - auc: 0.7332 - val_loss: 0.3440 - val_accuracy: 0.8320 - val_auc: 0.9376\n",
      "Epoch 2/50\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.2950 - accuracy: 0.8913 - auc: 0.9381 - val_loss: 0.2530 - val_accuracy: 0.8970 - val_auc: 0.9571\n",
      "Epoch 3/50\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.2480 - accuracy: 0.9153 - auc: 0.9556 - val_loss: 0.3552 - val_accuracy: 0.8700 - val_auc: 0.9068\n",
      "Epoch 4/50\n",
      "250/250 [==============================] - 60s 238ms/step - loss: 0.2480 - accuracy: 0.9174 - auc: 0.9539 - val_loss: 0.2621 - val_accuracy: 0.9020 - val_auc: 0.9555\n",
      "Epoch 5/50\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.1823 - accuracy: 0.9421 - auc: 0.9747 - val_loss: 0.2971 - val_accuracy: 0.9010 - val_auc: 0.9536\n",
      "Epoch 6/50\n",
      "250/250 [==============================] - 60s 242ms/step - loss: 0.1515 - accuracy: 0.9526 - auc: 0.9809 - val_loss: 0.2907 - val_accuracy: 0.9040 - val_auc: 0.9559\n",
      "Epoch 7/50\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.1262 - accuracy: 0.9626 - auc: 0.9855 - val_loss: 0.3184 - val_accuracy: 0.9030 - val_auc: 0.9518\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3688</td>\n",
       "      <td>0.2425</td>\n",
       "      <td>0.9043</td>\n",
       "      <td>0.9595</td>\n",
       "      <td>178</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.3964</td>\n",
       "      <td>0.2462</td>\n",
       "      <td>0.9025</td>\n",
       "      <td>0.9585</td>\n",
       "      <td>185</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.9579</td>\n",
       "      <td>316</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3256</td>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.9589</td>\n",
       "      <td>324</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3412</td>\n",
       "      <td>0.2316</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.9646</td>\n",
       "      <td>228</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3711</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.9612</td>\n",
       "      <td>225</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3697</td>\n",
       "      <td>0.2344</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>352</td>\n",
       "      <td>lstm</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.2488</td>\n",
       "      <td>0.9010</td>\n",
       "      <td>0.9580</td>\n",
       "      <td>422</td>\n",
       "      <td>lstm</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.3688    0.2425        0.9043   0.9595       178            gru   \n",
       "1  0.3964    0.2462        0.9025   0.9585       185            gru   \n",
       "2  0.3789    0.2507        0.8985   0.9579       316            gru   \n",
       "3  0.3256    0.2497        0.8990   0.9589       324            gru   \n",
       "4  0.3412    0.2316        0.9092   0.9646       228           lstm   \n",
       "5  0.3711    0.2424        0.8997   0.9612       225           lstm   \n",
       "6  0.3697    0.2344        0.9055   0.9636       352           lstm   \n",
       "7  0.2794    0.2488        0.9010   0.9580       422           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     64           0.2            True  \n",
       "1           1             2     64           0.2            True  \n",
       "2           2             1     64           0.2            True  \n",
       "3           2             2     64           0.2            True  \n",
       "4           1             1     64           0.2            True  \n",
       "5           1             2     64           0.2            True  \n",
       "6           2             1     64           0.2            True  \n",
       "7           2             2     64           0.2            True  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2],\n",
    "    'units': [64],\n",
    "    'dropout_rate': [0.2],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=20000,\n",
    "        max_tokens=20000,\n",
    "        percentile_len=0.9,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1c62ac4-6597-4b1a-967f-95ae26feb19f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a14182b4f2f46b0b61c76b8f1490976",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 18s 252ms/step - loss: 0.5716 - accuracy: 0.7035 - auc: 0.7010 - val_loss: 0.4002 - val_accuracy: 0.8040 - val_auc: 0.8960\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 15s 246ms/step - loss: 0.2741 - accuracy: 0.8907 - auc: 0.9472 - val_loss: 0.3187 - val_accuracy: 0.8600 - val_auc: 0.9294\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 0.1464 - accuracy: 0.9517 - auc: 0.9830 - val_loss: 0.3732 - val_accuracy: 0.8520 - val_auc: 0.9237\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 15s 246ms/step - loss: 0.0894 - accuracy: 0.9735 - auc: 0.9927 - val_loss: 0.4665 - val_accuracy: 0.8420 - val_auc: 0.9040\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 15s 245ms/step - loss: 0.0482 - accuracy: 0.9845 - auc: 0.9972 - val_loss: 0.5291 - val_accuracy: 0.8380 - val_auc: 0.9015\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 16s 248ms/step - loss: 0.0318 - accuracy: 0.9890 - auc: 0.9992 - val_loss: 0.6882 - val_accuracy: 0.8460 - val_auc: 0.8806\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 16s 251ms/step - loss: 0.0504 - accuracy: 0.9797 - auc: 0.9983 - val_loss: 0.6081 - val_accuracy: 0.8260 - val_auc: 0.8975\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 19s 254ms/step - loss: 0.6053 - accuracy: 0.6948 - auc: 0.6692 - val_loss: 0.4888 - val_accuracy: 0.8040 - val_auc: 0.8943\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 16s 249ms/step - loss: 0.3085 - accuracy: 0.8767 - auc: 0.9353 - val_loss: 0.3214 - val_accuracy: 0.8640 - val_auc: 0.9365\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 16s 247ms/step - loss: 0.1589 - accuracy: 0.9455 - auc: 0.9808 - val_loss: 0.3710 - val_accuracy: 0.8680 - val_auc: 0.9311\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 16s 252ms/step - loss: 0.1026 - accuracy: 0.9670 - auc: 0.9908 - val_loss: 0.4588 - val_accuracy: 0.8500 - val_auc: 0.9244\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 16s 250ms/step - loss: 0.0730 - accuracy: 0.9758 - auc: 0.9948 - val_loss: 0.7264 - val_accuracy: 0.8360 - val_auc: 0.8867\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 16s 254ms/step - loss: 0.0695 - accuracy: 0.9760 - auc: 0.9957 - val_loss: 0.6459 - val_accuracy: 0.8440 - val_auc: 0.8856\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 16s 256ms/step - loss: 0.0720 - accuracy: 0.9765 - auc: 0.9959 - val_loss: 0.5942 - val_accuracy: 0.8320 - val_auc: 0.9072\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 21s 299ms/step - loss: 0.5251 - accuracy: 0.7418 - auc: 0.7818 - val_loss: 0.3931 - val_accuracy: 0.8260 - val_auc: 0.9112\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.2498 - accuracy: 0.9075 - auc: 0.9549 - val_loss: 0.2827 - val_accuracy: 0.8780 - val_auc: 0.9496\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 18s 289ms/step - loss: 0.1290 - accuracy: 0.9567 - auc: 0.9867 - val_loss: 0.3307 - val_accuracy: 0.8720 - val_auc: 0.9420\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 18s 288ms/step - loss: 0.0895 - accuracy: 0.9730 - auc: 0.9927 - val_loss: 0.3782 - val_accuracy: 0.8880 - val_auc: 0.9405\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 18s 284ms/step - loss: 0.0478 - accuracy: 0.9850 - auc: 0.9974 - val_loss: 0.4095 - val_accuracy: 0.8760 - val_auc: 0.9453\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 18s 287ms/step - loss: 0.0306 - accuracy: 0.9910 - auc: 0.9988 - val_loss: 0.6381 - val_accuracy: 0.8800 - val_auc: 0.9140\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 18s 289ms/step - loss: 0.0309 - accuracy: 0.9925 - auc: 0.9981 - val_loss: 0.4600 - val_accuracy: 0.8660 - val_auc: 0.9294\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 20s 291ms/step - loss: 0.5483 - accuracy: 0.7195 - auc: 0.7560 - val_loss: 0.4873 - val_accuracy: 0.8040 - val_auc: 0.9031\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 18s 289ms/step - loss: 0.2776 - accuracy: 0.8932 - auc: 0.9460 - val_loss: 0.3234 - val_accuracy: 0.8760 - val_auc: 0.9432\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 18s 292ms/step - loss: 0.1401 - accuracy: 0.9545 - auc: 0.9833 - val_loss: 0.3516 - val_accuracy: 0.8740 - val_auc: 0.9404\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 18s 291ms/step - loss: 0.0713 - accuracy: 0.9810 - auc: 0.9937 - val_loss: 0.4150 - val_accuracy: 0.8520 - val_auc: 0.9292\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.0565 - accuracy: 0.9835 - auc: 0.9955 - val_loss: 0.4288 - val_accuracy: 0.8340 - val_auc: 0.9048\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 18s 290ms/step - loss: 0.0708 - accuracy: 0.9750 - auc: 0.9957 - val_loss: 0.5139 - val_accuracy: 0.8660 - val_auc: 0.8979\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 19s 295ms/step - loss: 0.0331 - accuracy: 0.9910 - auc: 0.9980 - val_loss: 0.7002 - val_accuracy: 0.8560 - val_auc: 0.8970\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2913</td>\n",
       "      <td>0.320</td>\n",
       "      <td>0.862</td>\n",
       "      <td>0.9330</td>\n",
       "      <td>113</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2637</td>\n",
       "      <td>0.303</td>\n",
       "      <td>0.877</td>\n",
       "      <td>0.9464</td>\n",
       "      <td>130</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2913     0.320         0.862   0.9330       113            gru   \n",
       "1  0.2637     0.303         0.877   0.9464       130           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     64           0.2            True  \n",
       "1           1             1     64           0.2            True  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [64],\n",
    "    'dropout_rate': [0.2],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=10000,\n",
    "        percentile_len=0.99,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3437d7d7-c464-4e17-930c-9021fc029fcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2886a7c9e91411895b49fed074d4501",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 8s 88ms/step - loss: 0.5635 - accuracy: 0.7100 - auc: 0.7335 - val_loss: 0.3811 - val_accuracy: 0.8420 - val_auc: 0.9090\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.2670 - accuracy: 0.8978 - auc: 0.9511 - val_loss: 0.3338 - val_accuracy: 0.8600 - val_auc: 0.9325\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.1366 - accuracy: 0.9542 - auc: 0.9858 - val_loss: 0.3976 - val_accuracy: 0.8640 - val_auc: 0.9242\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.0843 - accuracy: 0.9730 - auc: 0.9940 - val_loss: 0.4851 - val_accuracy: 0.8600 - val_auc: 0.9231\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.0519 - accuracy: 0.9843 - auc: 0.9975 - val_loss: 0.6315 - val_accuracy: 0.8380 - val_auc: 0.9158\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.0415 - accuracy: 0.9870 - auc: 0.9985 - val_loss: 0.6759 - val_accuracy: 0.8300 - val_auc: 0.9121\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.0624 - accuracy: 0.9768 - auc: 0.9968 - val_loss: 0.6425 - val_accuracy: 0.8720 - val_auc: 0.9054\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 8s 86ms/step - loss: 0.5877 - accuracy: 0.6880 - auc: 0.6781 - val_loss: 0.3726 - val_accuracy: 0.8320 - val_auc: 0.9085\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 77ms/step - loss: 0.2687 - accuracy: 0.8923 - auc: 0.9499 - val_loss: 0.3461 - val_accuracy: 0.8840 - val_auc: 0.9362\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.1488 - accuracy: 0.9475 - auc: 0.9838 - val_loss: 0.3704 - val_accuracy: 0.8700 - val_auc: 0.9304\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.0912 - accuracy: 0.9710 - auc: 0.9933 - val_loss: 0.4680 - val_accuracy: 0.8360 - val_auc: 0.9141\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 79ms/step - loss: 0.0589 - accuracy: 0.9825 - auc: 0.9960 - val_loss: 0.5342 - val_accuracy: 0.8600 - val_auc: 0.9106\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.0519 - accuracy: 0.9833 - auc: 0.9975 - val_loss: 0.7196 - val_accuracy: 0.8560 - val_auc: 0.8961\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 78ms/step - loss: 0.0345 - accuracy: 0.9893 - auc: 0.9980 - val_loss: 0.6522 - val_accuracy: 0.8480 - val_auc: 0.9121\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 118ms/step - loss: 0.5471 - accuracy: 0.7140 - auc: 0.7579 - val_loss: 0.4056 - val_accuracy: 0.8240 - val_auc: 0.9082\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 107ms/step - loss: 0.2735 - accuracy: 0.8947 - auc: 0.9468 - val_loss: 0.3133 - val_accuracy: 0.8620 - val_auc: 0.9337\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.1441 - accuracy: 0.9510 - auc: 0.9842 - val_loss: 0.3375 - val_accuracy: 0.8660 - val_auc: 0.9309\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0905 - accuracy: 0.9703 - auc: 0.9920 - val_loss: 0.3747 - val_accuracy: 0.8740 - val_auc: 0.9194\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 109ms/step - loss: 0.0597 - accuracy: 0.9795 - auc: 0.9968 - val_loss: 0.4923 - val_accuracy: 0.8780 - val_auc: 0.9313\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 108ms/step - loss: 0.0540 - accuracy: 0.9822 - auc: 0.9971 - val_loss: 0.6267 - val_accuracy: 0.8720 - val_auc: 0.9227\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 7s 106ms/step - loss: 0.0459 - accuracy: 0.9858 - auc: 0.9983 - val_loss: 0.5291 - val_accuracy: 0.8860 - val_auc: 0.9212\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 113ms/step - loss: 0.5388 - accuracy: 0.7433 - auc: 0.7711 - val_loss: 0.3476 - val_accuracy: 0.8620 - val_auc: 0.9262\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 7s 115ms/step - loss: 0.2527 - accuracy: 0.9030 - auc: 0.9550 - val_loss: 0.2948 - val_accuracy: 0.8900 - val_auc: 0.9444\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.1355 - accuracy: 0.9548 - auc: 0.9853 - val_loss: 0.3345 - val_accuracy: 0.8900 - val_auc: 0.9362\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 7s 103ms/step - loss: 0.0767 - accuracy: 0.9783 - auc: 0.9937 - val_loss: 0.3994 - val_accuracy: 0.8720 - val_auc: 0.9286\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 7s 104ms/step - loss: 0.0461 - accuracy: 0.9855 - auc: 0.9984 - val_loss: 0.5872 - val_accuracy: 0.8720 - val_auc: 0.9055\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 7s 105ms/step - loss: 0.0585 - accuracy: 0.9780 - auc: 0.9976 - val_loss: 0.4819 - val_accuracy: 0.8920 - val_auc: 0.9323\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 6s 101ms/step - loss: 0.0299 - accuracy: 0.9905 - auc: 0.9992 - val_loss: 0.5668 - val_accuracy: 0.8880 - val_auc: 0.9204\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2678</td>\n",
       "      <td>0.3400</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.9344</td>\n",
       "      <td>38</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2631</td>\n",
       "      <td>0.3041</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.9390</td>\n",
       "      <td>50</td>\n",
       "      <td>lstm</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2678    0.3400         0.872   0.9344        38            gru   \n",
       "1  0.2631    0.3041         0.876   0.9390        50           lstm   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     64           0.2            True  \n",
       "1           1             1     64           0.2            True  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru', 'lstm'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [64],\n",
    "    'dropout_rate': [0.2],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=10000,\n",
    "        percentile_len=0.85,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1710ca67-d1e9-4f54-830b-1c686f38eaf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc6533fa8619404c90187ae57ad4d722",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 47ms/step - loss: 0.6304 - accuracy: 0.6607 - auc: 0.5800 - val_loss: 0.4803 - val_accuracy: 0.7060 - val_auc: 0.9002\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.3383 - accuracy: 0.8580 - auc: 0.9222 - val_loss: 0.3162 - val_accuracy: 0.8620 - val_auc: 0.9413\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1867 - accuracy: 0.9252 - auc: 0.9760 - val_loss: 0.2739 - val_accuracy: 0.8840 - val_auc: 0.9475\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1173 - accuracy: 0.9613 - auc: 0.9887 - val_loss: 0.3731 - val_accuracy: 0.8320 - val_auc: 0.9261\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0883 - accuracy: 0.9712 - auc: 0.9935 - val_loss: 0.3766 - val_accuracy: 0.8840 - val_auc: 0.9362\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.0594 - accuracy: 0.9805 - auc: 0.9963 - val_loss: 0.4776 - val_accuracy: 0.8760 - val_auc: 0.9222\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0291 - accuracy: 0.9930 - auc: 0.9978 - val_loss: 0.5155 - val_accuracy: 0.8540 - val_auc: 0.9125\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0181 - accuracy: 0.9962 - auc: 0.9990 - val_loss: 0.5780 - val_accuracy: 0.8700 - val_auc: 0.8951\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 6s 48ms/step - loss: 0.6256 - accuracy: 0.6685 - auc: 0.5944 - val_loss: 0.5026 - val_accuracy: 0.7160 - val_auc: 0.8756\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.3579 - accuracy: 0.8485 - auc: 0.9127 - val_loss: 0.2982 - val_accuracy: 0.8860 - val_auc: 0.9370\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.1825 - accuracy: 0.9283 - auc: 0.9767 - val_loss: 0.2928 - val_accuracy: 0.8700 - val_auc: 0.9396\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0979 - accuracy: 0.9693 - auc: 0.9920 - val_loss: 0.3762 - val_accuracy: 0.8680 - val_auc: 0.9288\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0507 - accuracy: 0.9847 - auc: 0.9974 - val_loss: 0.5296 - val_accuracy: 0.8660 - val_auc: 0.9019\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0716 - accuracy: 0.9747 - auc: 0.9949 - val_loss: 0.5246 - val_accuracy: 0.8060 - val_auc: 0.9183\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 39ms/step - loss: 0.0800 - accuracy: 0.9703 - auc: 0.9955 - val_loss: 0.4511 - val_accuracy: 0.8520 - val_auc: 0.9167\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 44ms/step - loss: 0.6479 - accuracy: 0.6655 - auc: 0.5192 - val_loss: 0.6157 - val_accuracy: 0.6680 - val_auc: 0.8082\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.5105 - accuracy: 0.7300 - auc: 0.8519 - val_loss: 0.3474 - val_accuracy: 0.8520 - val_auc: 0.9220\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.2663 - accuracy: 0.8915 - auc: 0.9545 - val_loss: 0.2743 - val_accuracy: 0.8900 - val_auc: 0.9494\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1608 - accuracy: 0.9405 - auc: 0.9824 - val_loss: 0.2911 - val_accuracy: 0.8860 - val_auc: 0.9431\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0981 - accuracy: 0.9678 - auc: 0.9925 - val_loss: 0.3518 - val_accuracy: 0.8740 - val_auc: 0.9311\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0728 - accuracy: 0.9772 - auc: 0.9956 - val_loss: 0.4270 - val_accuracy: 0.8760 - val_auc: 0.9253\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0693 - accuracy: 0.9795 - auc: 0.9958 - val_loss: 0.4074 - val_accuracy: 0.8500 - val_auc: 0.9249\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0692 - accuracy: 0.9803 - auc: 0.9954 - val_loss: 0.5607 - val_accuracy: 0.8100 - val_auc: 0.9229\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 44ms/step - loss: 0.6428 - accuracy: 0.6650 - auc: 0.5517 - val_loss: 0.5911 - val_accuracy: 0.6680 - val_auc: 0.8479\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.4642 - accuracy: 0.7598 - auc: 0.8724 - val_loss: 0.3415 - val_accuracy: 0.8680 - val_auc: 0.9329\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.2537 - accuracy: 0.8972 - auc: 0.9605 - val_loss: 0.2784 - val_accuracy: 0.8900 - val_auc: 0.9502\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.1609 - accuracy: 0.9413 - auc: 0.9819 - val_loss: 0.2829 - val_accuracy: 0.8900 - val_auc: 0.9492\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1156 - accuracy: 0.9620 - auc: 0.9902 - val_loss: 0.3046 - val_accuracy: 0.9000 - val_auc: 0.9460\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0749 - accuracy: 0.9758 - auc: 0.9951 - val_loss: 0.4120 - val_accuracy: 0.8500 - val_auc: 0.9328\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0546 - accuracy: 0.9843 - auc: 0.9967 - val_loss: 0.4607 - val_accuracy: 0.8280 - val_auc: 0.9268\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0722 - accuracy: 0.9762 - auc: 0.9943 - val_loss: 0.6306 - val_accuracy: 0.7760 - val_auc: 0.9147\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 6s 48ms/step - loss: 0.6475 - accuracy: 0.6650 - auc: 0.5246 - val_loss: 0.5700 - val_accuracy: 0.6680 - val_auc: 0.8661\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.3984 - accuracy: 0.8142 - auc: 0.8925 - val_loss: 0.3092 - val_accuracy: 0.8780 - val_auc: 0.9314\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.2173 - accuracy: 0.9118 - auc: 0.9680 - val_loss: 0.2882 - val_accuracy: 0.8780 - val_auc: 0.9431\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1268 - accuracy: 0.9542 - auc: 0.9879 - val_loss: 0.3916 - val_accuracy: 0.8360 - val_auc: 0.9265\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0682 - accuracy: 0.9812 - auc: 0.9949 - val_loss: 0.5136 - val_accuracy: 0.8340 - val_auc: 0.9176\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0498 - accuracy: 0.9860 - auc: 0.9966 - val_loss: 0.5973 - val_accuracy: 0.8100 - val_auc: 0.9069\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 3s 40ms/step - loss: 0.0734 - accuracy: 0.9735 - auc: 0.9954 - val_loss: 0.5034 - val_accuracy: 0.8300 - val_auc: 0.9150\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0798 - accuracy: 0.9715 - auc: 0.9951 - val_loss: 0.6678 - val_accuracy: 0.8440 - val_auc: 0.8818\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 47ms/step - loss: 0.6469 - accuracy: 0.6622 - auc: 0.5352 - val_loss: 0.5549 - val_accuracy: 0.6680 - val_auc: 0.8805\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.3720 - accuracy: 0.8275 - auc: 0.9056 - val_loss: 0.3141 - val_accuracy: 0.8700 - val_auc: 0.9282\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 3s 42ms/step - loss: 0.2307 - accuracy: 0.9068 - auc: 0.9635 - val_loss: 0.3008 - val_accuracy: 0.8820 - val_auc: 0.9402\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1595 - accuracy: 0.9448 - auc: 0.9814 - val_loss: 0.3337 - val_accuracy: 0.8620 - val_auc: 0.9364\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.1306 - accuracy: 0.9510 - auc: 0.9868 - val_loss: 0.3677 - val_accuracy: 0.8760 - val_auc: 0.9424\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0771 - accuracy: 0.9740 - auc: 0.9947 - val_loss: 0.4318 - val_accuracy: 0.8620 - val_auc: 0.9312\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0471 - accuracy: 0.9852 - auc: 0.9975 - val_loss: 0.5426 - val_accuracy: 0.8300 - val_auc: 0.9225\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 3s 41ms/step - loss: 0.0495 - accuracy: 0.9855 - auc: 0.9972 - val_loss: 0.5396 - val_accuracy: 0.8420 - val_auc: 0.9172\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 44ms/step - loss: 0.6515 - accuracy: 0.6645 - auc: 0.5190 - val_loss: 0.6034 - val_accuracy: 0.6680 - val_auc: 0.8283\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.5108 - accuracy: 0.6927 - auc: 0.8550 - val_loss: 0.4083 - val_accuracy: 0.8420 - val_auc: 0.9212\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.3001 - accuracy: 0.8965 - auc: 0.9502 - val_loss: 0.3040 - val_accuracy: 0.8900 - val_auc: 0.9431\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1678 - accuracy: 0.9440 - auc: 0.9813 - val_loss: 0.3020 - val_accuracy: 0.8820 - val_auc: 0.9388\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.1262 - accuracy: 0.9578 - auc: 0.9879 - val_loss: 0.3488 - val_accuracy: 0.8620 - val_auc: 0.9349\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0997 - accuracy: 0.9705 - auc: 0.9908 - val_loss: 0.5149 - val_accuracy: 0.7960 - val_auc: 0.9234\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0983 - accuracy: 0.9682 - auc: 0.9910 - val_loss: 0.4232 - val_accuracy: 0.8480 - val_auc: 0.9191\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0696 - accuracy: 0.9793 - auc: 0.9944 - val_loss: 0.5237 - val_accuracy: 0.8540 - val_auc: 0.9018\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 5s 45ms/step - loss: 0.6689 - accuracy: 0.6643 - auc: 0.4873 - val_loss: 0.6261 - val_accuracy: 0.6680 - val_auc: 0.7194\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.5399 - accuracy: 0.7237 - auc: 0.8388 - val_loss: 0.3689 - val_accuracy: 0.8620 - val_auc: 0.9266\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.2784 - accuracy: 0.8865 - auc: 0.9496 - val_loss: 0.2944 - val_accuracy: 0.8940 - val_auc: 0.9431\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.1795 - accuracy: 0.9350 - auc: 0.9776 - val_loss: 0.2943 - val_accuracy: 0.8960 - val_auc: 0.9443\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.1384 - accuracy: 0.9503 - auc: 0.9856 - val_loss: 0.3074 - val_accuracy: 0.8860 - val_auc: 0.9378\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 2s 36ms/step - loss: 0.0912 - accuracy: 0.9732 - auc: 0.9932 - val_loss: 0.3916 - val_accuracy: 0.8460 - val_auc: 0.9274\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0704 - accuracy: 0.9797 - auc: 0.9949 - val_loss: 0.3875 - val_accuracy: 0.8620 - val_auc: 0.9269\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 2s 37ms/step - loss: 0.0827 - accuracy: 0.9747 - auc: 0.9932 - val_loss: 0.4735 - val_accuracy: 0.8300 - val_auc: 0.9138\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 96ms/step - loss: 0.6205 - accuracy: 0.6697 - auc: 0.6134 - val_loss: 0.4883 - val_accuracy: 0.7760 - val_auc: 0.8779\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.3285 - accuracy: 0.8640 - auc: 0.9243 - val_loss: 0.2845 - val_accuracy: 0.8860 - val_auc: 0.9484\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.1587 - accuracy: 0.9392 - auc: 0.9820 - val_loss: 0.3192 - val_accuracy: 0.8680 - val_auc: 0.9330\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.0869 - accuracy: 0.9735 - auc: 0.9924 - val_loss: 0.4314 - val_accuracy: 0.8540 - val_auc: 0.9195\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0758 - accuracy: 0.9743 - auc: 0.9945 - val_loss: 0.4964 - val_accuracy: 0.8620 - val_auc: 0.8969\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0374 - accuracy: 0.9887 - auc: 0.9982 - val_loss: 0.5904 - val_accuracy: 0.8220 - val_auc: 0.9190\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0435 - accuracy: 0.9852 - auc: 0.9980 - val_loss: 0.6648 - val_accuracy: 0.8080 - val_auc: 0.9253\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 95ms/step - loss: 0.6162 - accuracy: 0.6740 - auc: 0.6230 - val_loss: 0.4839 - val_accuracy: 0.7840 - val_auc: 0.8749\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.3404 - accuracy: 0.8658 - auc: 0.9200 - val_loss: 0.2909 - val_accuracy: 0.8820 - val_auc: 0.9413\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.1757 - accuracy: 0.9335 - auc: 0.9776 - val_loss: 0.2939 - val_accuracy: 0.8740 - val_auc: 0.9419\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.1062 - accuracy: 0.9657 - auc: 0.9900 - val_loss: 0.3980 - val_accuracy: 0.8480 - val_auc: 0.9124\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0946 - accuracy: 0.9685 - auc: 0.9916 - val_loss: 0.4069 - val_accuracy: 0.8540 - val_auc: 0.9122\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0609 - accuracy: 0.9825 - auc: 0.9957 - val_loss: 0.5471 - val_accuracy: 0.8180 - val_auc: 0.9154\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.0701 - accuracy: 0.9758 - auc: 0.9944 - val_loss: 0.4717 - val_accuracy: 0.8600 - val_auc: 0.9157\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 9s 87ms/step - loss: 0.6383 - accuracy: 0.6678 - auc: 0.5584 - val_loss: 0.5949 - val_accuracy: 0.6680 - val_auc: 0.8412\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 0.4809 - accuracy: 0.7558 - auc: 0.8686 - val_loss: 0.3917 - val_accuracy: 0.8600 - val_auc: 0.9278\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.3159 - accuracy: 0.9005 - auc: 0.9511 - val_loss: 0.3161 - val_accuracy: 0.8900 - val_auc: 0.9411\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 71ms/step - loss: 0.1849 - accuracy: 0.9390 - auc: 0.9747 - val_loss: 0.3159 - val_accuracy: 0.8760 - val_auc: 0.9366\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.1207 - accuracy: 0.9625 - auc: 0.9863 - val_loss: 0.4101 - val_accuracy: 0.8260 - val_auc: 0.9306\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0947 - accuracy: 0.9712 - auc: 0.9914 - val_loss: 0.3960 - val_accuracy: 0.8720 - val_auc: 0.9299\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0838 - accuracy: 0.9747 - auc: 0.9926 - val_loss: 0.5096 - val_accuracy: 0.8080 - val_auc: 0.9137\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0869 - accuracy: 0.9745 - auc: 0.9923 - val_loss: 0.4164 - val_accuracy: 0.8640 - val_auc: 0.9224\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 84ms/step - loss: 0.6591 - accuracy: 0.6620 - auc: 0.4841 - val_loss: 0.6304 - val_accuracy: 0.6680 - val_auc: 0.7321\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 0.5563 - accuracy: 0.7207 - auc: 0.8314 - val_loss: 0.4230 - val_accuracy: 0.8320 - val_auc: 0.9102\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 0.3083 - accuracy: 0.8840 - auc: 0.9372 - val_loss: 0.2845 - val_accuracy: 0.9020 - val_auc: 0.9400\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.2049 - accuracy: 0.9265 - auc: 0.9690 - val_loss: 0.3640 - val_accuracy: 0.8440 - val_auc: 0.9336\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.1548 - accuracy: 0.9463 - auc: 0.9825 - val_loss: 0.3103 - val_accuracy: 0.8840 - val_auc: 0.9413\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0967 - accuracy: 0.9715 - auc: 0.9913 - val_loss: 0.3788 - val_accuracy: 0.8720 - val_auc: 0.9338\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0609 - accuracy: 0.9852 - auc: 0.9949 - val_loss: 0.4239 - val_accuracy: 0.8760 - val_auc: 0.9263\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0432 - accuracy: 0.9905 - auc: 0.9970 - val_loss: 0.4715 - val_accuracy: 0.8660 - val_auc: 0.9272\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 95ms/step - loss: 0.6081 - accuracy: 0.6727 - auc: 0.6425 - val_loss: 0.4841 - val_accuracy: 0.7980 - val_auc: 0.8755\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.3340 - accuracy: 0.8630 - auc: 0.9258 - val_loss: 0.2965 - val_accuracy: 0.8740 - val_auc: 0.9402\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.1662 - accuracy: 0.9398 - auc: 0.9806 - val_loss: 0.2843 - val_accuracy: 0.8880 - val_auc: 0.9457\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.1025 - accuracy: 0.9670 - auc: 0.9912 - val_loss: 0.3673 - val_accuracy: 0.8580 - val_auc: 0.9298\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0712 - accuracy: 0.9787 - auc: 0.9948 - val_loss: 0.4180 - val_accuracy: 0.8500 - val_auc: 0.9300\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.0713 - accuracy: 0.9775 - auc: 0.9950 - val_loss: 0.4458 - val_accuracy: 0.8480 - val_auc: 0.9240\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.0415 - accuracy: 0.9895 - auc: 0.9976 - val_loss: 0.5299 - val_accuracy: 0.8440 - val_auc: 0.9162\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.0277 - accuracy: 0.9937 - auc: 0.9982 - val_loss: 0.5923 - val_accuracy: 0.8500 - val_auc: 0.9001\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 97ms/step - loss: 0.6319 - accuracy: 0.6650 - auc: 0.5756 - val_loss: 0.5279 - val_accuracy: 0.6680 - val_auc: 0.8655\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 83ms/step - loss: 0.4228 - accuracy: 0.7540 - auc: 0.9034 - val_loss: 0.4417 - val_accuracy: 0.8180 - val_auc: 0.9143\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.3423 - accuracy: 0.8982 - auc: 0.9463 - val_loss: 0.4010 - val_accuracy: 0.8600 - val_auc: 0.9150\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.2812 - accuracy: 0.9345 - auc: 0.9638 - val_loss: 0.4074 - val_accuracy: 0.8520 - val_auc: 0.8959\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.2522 - accuracy: 0.9490 - auc: 0.9690 - val_loss: 0.4551 - val_accuracy: 0.8500 - val_auc: 0.8950\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 82ms/step - loss: 0.2404 - accuracy: 0.9540 - auc: 0.9699 - val_loss: 0.5203 - val_accuracy: 0.8540 - val_auc: 0.8960\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 80ms/step - loss: 0.2309 - accuracy: 0.9535 - auc: 0.9684 - val_loss: 0.4538 - val_accuracy: 0.8480 - val_auc: 0.8852\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 5s 81ms/step - loss: 0.2230 - accuracy: 0.9585 - auc: 0.9717 - val_loss: 0.4866 - val_accuracy: 0.8420 - val_auc: 0.8867\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 86ms/step - loss: 0.6541 - accuracy: 0.6595 - auc: 0.5127 - val_loss: 0.6053 - val_accuracy: 0.6680 - val_auc: 0.8542\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 74ms/step - loss: 0.4826 - accuracy: 0.7625 - auc: 0.8602 - val_loss: 0.3578 - val_accuracy: 0.8620 - val_auc: 0.9196\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.2628 - accuracy: 0.9013 - auc: 0.9568 - val_loss: 0.2746 - val_accuracy: 0.8880 - val_auc: 0.9439\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.1567 - accuracy: 0.9465 - auc: 0.9822 - val_loss: 0.3315 - val_accuracy: 0.8780 - val_auc: 0.9445\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 4s 70ms/step - loss: 0.1177 - accuracy: 0.9630 - auc: 0.9871 - val_loss: 0.3536 - val_accuracy: 0.8720 - val_auc: 0.9325\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.0823 - accuracy: 0.9765 - auc: 0.9921 - val_loss: 0.5078 - val_accuracy: 0.8260 - val_auc: 0.9214\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0731 - accuracy: 0.9803 - auc: 0.9923 - val_loss: 0.4479 - val_accuracy: 0.8560 - val_auc: 0.9123\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 4s 71ms/step - loss: 0.0617 - accuracy: 0.9830 - auc: 0.9935 - val_loss: 0.6076 - val_accuracy: 0.8580 - val_auc: 0.9057\n",
      "Epoch 1/50\n",
      "63/63 [==============================] - 10s 91ms/step - loss: 0.6772 - accuracy: 0.6678 - auc: 0.4874 - val_loss: 0.6419 - val_accuracy: 0.6680 - val_auc: 0.7495\n",
      "Epoch 2/50\n",
      "63/63 [==============================] - 5s 71ms/step - loss: 0.6006 - accuracy: 0.6883 - auc: 0.7817 - val_loss: 0.4882 - val_accuracy: 0.8360 - val_auc: 0.9151\n",
      "Epoch 3/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.3858 - accuracy: 0.8758 - auc: 0.9230 - val_loss: 0.3723 - val_accuracy: 0.8500 - val_auc: 0.9215\n",
      "Epoch 4/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.2471 - accuracy: 0.9208 - auc: 0.9630 - val_loss: 0.3212 - val_accuracy: 0.8780 - val_auc: 0.9316\n",
      "Epoch 5/50\n",
      "63/63 [==============================] - 5s 73ms/step - loss: 0.1708 - accuracy: 0.9492 - auc: 0.9780 - val_loss: 0.3196 - val_accuracy: 0.8800 - val_auc: 0.9326\n",
      "Epoch 6/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.1240 - accuracy: 0.9670 - auc: 0.9851 - val_loss: 0.3709 - val_accuracy: 0.8560 - val_auc: 0.9333\n",
      "Epoch 7/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.1179 - accuracy: 0.9657 - auc: 0.9875 - val_loss: 0.4148 - val_accuracy: 0.8620 - val_auc: 0.9204\n",
      "Epoch 8/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.0883 - accuracy: 0.9745 - auc: 0.9915 - val_loss: 0.3777 - val_accuracy: 0.8840 - val_auc: 0.9230\n",
      "Epoch 9/50\n",
      "63/63 [==============================] - 5s 72ms/step - loss: 0.0646 - accuracy: 0.9858 - auc: 0.9936 - val_loss: 0.4303 - val_accuracy: 0.8780 - val_auc: 0.9154\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2723</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.9422</td>\n",
       "      <td>22</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2600</td>\n",
       "      <td>0.2764</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>21</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2240</td>\n",
       "      <td>0.2945</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.9416</td>\n",
       "      <td>24</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2893</td>\n",
       "      <td>0.2992</td>\n",
       "      <td>0.892</td>\n",
       "      <td>0.9431</td>\n",
       "      <td>21</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3344</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.9449</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.3121</td>\n",
       "      <td>0.3003</td>\n",
       "      <td>0.896</td>\n",
       "      <td>0.9406</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2542</td>\n",
       "      <td>0.3426</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.9303</td>\n",
       "      <td>46</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2549</td>\n",
       "      <td>0.2979</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>44</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2723    0.2860         0.885   0.9422        22            gru   \n",
       "1  0.2600    0.2764         0.890   0.9498        21            gru   \n",
       "2  0.2240    0.2945         0.880   0.9416        24            gru   \n",
       "3  0.2893    0.2992         0.892   0.9431        21            gru   \n",
       "4  0.3344    0.2877         0.884   0.9449        41            gru   \n",
       "5  0.3121    0.3003         0.896   0.9406        41            gru   \n",
       "6  0.2542    0.3426         0.874   0.9303        46            gru   \n",
       "7  0.2549    0.2979         0.883   0.9378        44            gru   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     32             0            True  \n",
       "1           1             1     16             0            True  \n",
       "2           1             2     32             0            True  \n",
       "3           1             2     16             0            True  \n",
       "4           2             1     32             0            True  \n",
       "5           2             1     16             0            True  \n",
       "6           2             2     32             0            True  \n",
       "7           2             2     16             0            True  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru'],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2],\n",
    "    'units': [32,16],\n",
    "    'dropout_rate': [0],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=10000,\n",
    "        percentile_len=0.8,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f52f6ad-e8df-49f2-b28d-1ccc0c356c79",
   "metadata": {},
   "source": [
    "**changing min_delta to 0.001**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "175cf75f-cd04-438d-91b2-0d898735f1e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad7d6f735c44194bccf665161f51999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.3251</td>\n",
       "      <td>0.3021</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.9426</td>\n",
       "      <td>21</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2024</td>\n",
       "      <td>0.2961</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.9437</td>\n",
       "      <td>24</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1790</td>\n",
       "      <td>0.3119</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>25</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2970</td>\n",
       "      <td>0.3694</td>\n",
       "      <td>0.867</td>\n",
       "      <td>0.9229</td>\n",
       "      <td>24</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.3498</td>\n",
       "      <td>0.3210</td>\n",
       "      <td>0.864</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2298</td>\n",
       "      <td>0.2992</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.9440</td>\n",
       "      <td>46</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.3185</td>\n",
       "      <td>0.872</td>\n",
       "      <td>0.9356</td>\n",
       "      <td>49</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.4393</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.772</td>\n",
       "      <td>0.7193</td>\n",
       "      <td>76</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.3251    0.3021         0.879   0.9426        21            gru   \n",
       "1  0.2024    0.2961         0.884   0.9437        24            gru   \n",
       "2  0.1790    0.3119         0.873   0.9428        25            gru   \n",
       "3  0.2970    0.3694         0.867   0.9229        24            gru   \n",
       "4  0.3498    0.3210         0.864   0.9288        41            gru   \n",
       "5  0.2298    0.2992         0.886   0.9440        46            gru   \n",
       "6  0.2364    0.3185         0.872   0.9356        49            gru   \n",
       "7  0.4393    0.4674         0.772   0.7193        76            gru   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     32             0            True  \n",
       "1           1             1     16             0            True  \n",
       "2           1             2     32             0            True  \n",
       "3           1             2     16             0            True  \n",
       "4           2             1     32             0            True  \n",
       "5           2             1     16             0            True  \n",
       "6           2             2     32             0            True  \n",
       "7           2             2     16             0            True  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru'],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2],\n",
    "    'units': [32,16],\n",
    "    'dropout_rate': [0],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=10000,\n",
    "        percentile_len=0.8,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 2,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c48f3675-549d-4ec6-9220-7ca85da64611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b634896735444f8420398ea0746dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.3010</td>\n",
       "      <td>0.8827</td>\n",
       "      <td>0.9445</td>\n",
       "      <td>22</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2623</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.8900</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>22</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3274</td>\n",
       "      <td>0.3231</td>\n",
       "      <td>0.8733</td>\n",
       "      <td>0.9433</td>\n",
       "      <td>22</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.3335</td>\n",
       "      <td>0.4162</td>\n",
       "      <td>0.8693</td>\n",
       "      <td>0.9035</td>\n",
       "      <td>29</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2288</td>\n",
       "      <td>0.3046</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>45</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.3245</td>\n",
       "      <td>0.8813</td>\n",
       "      <td>0.9452</td>\n",
       "      <td>46</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.3175</td>\n",
       "      <td>0.3234</td>\n",
       "      <td>0.8787</td>\n",
       "      <td>0.9409</td>\n",
       "      <td>44</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.5602</td>\n",
       "      <td>0.7273</td>\n",
       "      <td>0.6393</td>\n",
       "      <td>75</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0  0.2892    0.3010        0.8827   0.9445        22            gru   \n",
       "1  0.2623    0.2875        0.8900   0.9511        22            gru   \n",
       "2  0.3274    0.3231        0.8733   0.9433        22            gru   \n",
       "3  0.3335    0.4162        0.8693   0.9035        29            gru   \n",
       "4  0.2288    0.3046        0.8813   0.9466        45            gru   \n",
       "5  0.2145    0.3245        0.8813   0.9452        46            gru   \n",
       "6  0.3175    0.3234        0.8787   0.9409        44            gru   \n",
       "7  0.5455    0.5602        0.7273   0.6393        75            gru   \n",
       "\n",
       "   rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0           1             1     32             0            True  \n",
       "1           1             1     16             0            True  \n",
       "2           1             2     32             0            True  \n",
       "3           1             2     16             0            True  \n",
       "4           2             1     32             0            True  \n",
       "5           2             1     16             0            True  \n",
       "6           2             2     32             0            True  \n",
       "7           2             2     16             0            True  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru'],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2],\n",
    "    'units': [32,16],\n",
    "    'dropout_rate': [0],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=5000,\n",
    "        max_tokens=20000,\n",
    "        percentile_len=0.8,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 3,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7dc73d08-e7c4-4426-ab87-e20ab2daf5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "256600e850b94ea683d11888bfb0a7a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2063</td>\n",
       "      <td>0.2494</td>\n",
       "      <td>0.8997</td>\n",
       "      <td>0.9576</td>\n",
       "      <td>43</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2688</td>\n",
       "      <td>0.2457</td>\n",
       "      <td>0.8977</td>\n",
       "      <td>0.9578</td>\n",
       "      <td>36</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2136</td>\n",
       "      <td>0.2561</td>\n",
       "      <td>0.8957</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>36</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2409</td>\n",
       "      <td>0.2595</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9568</td>\n",
       "      <td>42</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2604</td>\n",
       "      <td>0.2927</td>\n",
       "      <td>0.8917</td>\n",
       "      <td>0.9537</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.1696</td>\n",
       "      <td>0.2975</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.9425</td>\n",
       "      <td>50</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2029</td>\n",
       "      <td>0.2492</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.9594</td>\n",
       "      <td>83</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2914</td>\n",
       "      <td>0.2580</td>\n",
       "      <td>0.8963</td>\n",
       "      <td>0.9534</td>\n",
       "      <td>69</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2938</td>\n",
       "      <td>0.4316</td>\n",
       "      <td>0.8113</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>119</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.2497</td>\n",
       "      <td>0.2733</td>\n",
       "      <td>0.8980</td>\n",
       "      <td>0.9573</td>\n",
       "      <td>84</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4317</td>\n",
       "      <td>0.4503</td>\n",
       "      <td>0.8097</td>\n",
       "      <td>0.7941</td>\n",
       "      <td>95</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.2794</td>\n",
       "      <td>0.3343</td>\n",
       "      <td>0.8920</td>\n",
       "      <td>0.9342</td>\n",
       "      <td>87</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0   0.2063    0.2494        0.8997   0.9576        43            gru   \n",
       "1   0.2688    0.2457        0.8977   0.9578        36            gru   \n",
       "2   0.2136    0.2561        0.8957   0.9532        36            gru   \n",
       "3   0.2409    0.2595        0.8980   0.9568        42            gru   \n",
       "4   0.2604    0.2927        0.8917   0.9537        41            gru   \n",
       "5   0.1696    0.2975        0.8893   0.9425        50            gru   \n",
       "6   0.2029    0.2492        0.9040   0.9594        83            gru   \n",
       "7   0.2914    0.2580        0.8963   0.9534        69            gru   \n",
       "8   0.2938    0.4316        0.8113   0.7892       119            gru   \n",
       "9   0.2497    0.2733        0.8980   0.9573        84            gru   \n",
       "10  0.4317    0.4503        0.8097   0.7941        95            gru   \n",
       "11  0.2794    0.3343        0.8920   0.9342        87            gru   \n",
       "\n",
       "    rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0            1             1     32             0            True  \n",
       "1            1             1     16             0            True  \n",
       "2            1             1      8             0            True  \n",
       "3            1             2     32             0            True  \n",
       "4            1             2     16             0            True  \n",
       "5            1             2      8             0            True  \n",
       "6            2             1     32             0            True  \n",
       "7            2             1     16             0            True  \n",
       "8            2             1      8             0            True  \n",
       "9            2             2     32             0            True  \n",
       "10           2             2     16             0            True  \n",
       "11           2             2      8             0            True  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru'],\n",
    "    'rnn_layers': [1,2],\n",
    "    'dense_layers': [1,2],\n",
    "    'units': [32,16,8],\n",
    "    'dropout_rate': [0],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=10000,\n",
    "        max_tokens=20000,\n",
    "        percentile_len=0.8,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 3,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "83539054-a05c-42d4-9eb6-8c3d70b59b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04aa6f8a09a9403a83520bb0f9f92184",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running Configurations:   0%|          | 0/18 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "      <th>val_auc</th>\n",
       "      <th>duration</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>rnn_layers</th>\n",
       "      <th>dense_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>bi_directional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2056</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.8797</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2353</td>\n",
       "      <td>0.2692</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9535</td>\n",
       "      <td>40</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3410</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.8803</td>\n",
       "      <td>0.9492</td>\n",
       "      <td>38</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2525</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.8880</td>\n",
       "      <td>0.9538</td>\n",
       "      <td>40</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2657</td>\n",
       "      <td>0.2897</td>\n",
       "      <td>0.8887</td>\n",
       "      <td>0.9511</td>\n",
       "      <td>40</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2636</td>\n",
       "      <td>0.2839</td>\n",
       "      <td>0.8883</td>\n",
       "      <td>0.9526</td>\n",
       "      <td>41</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2342</td>\n",
       "      <td>0.2724</td>\n",
       "      <td>0.8853</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>37</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2703</td>\n",
       "      <td>0.2835</td>\n",
       "      <td>0.8777</td>\n",
       "      <td>0.9494</td>\n",
       "      <td>37</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2427</td>\n",
       "      <td>0.2769</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.9530</td>\n",
       "      <td>40</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.3146</td>\n",
       "      <td>0.2738</td>\n",
       "      <td>0.8843</td>\n",
       "      <td>0.9527</td>\n",
       "      <td>37</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.2718</td>\n",
       "      <td>0.2830</td>\n",
       "      <td>0.8817</td>\n",
       "      <td>0.9499</td>\n",
       "      <td>42</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.3098</td>\n",
       "      <td>0.2690</td>\n",
       "      <td>0.8873</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>42</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.2138</td>\n",
       "      <td>0.2968</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9478</td>\n",
       "      <td>38</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.3308</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.9366</td>\n",
       "      <td>42</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.2752</td>\n",
       "      <td>0.3288</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.9266</td>\n",
       "      <td>47</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.2862</td>\n",
       "      <td>0.3134</td>\n",
       "      <td>0.8863</td>\n",
       "      <td>0.9456</td>\n",
       "      <td>257</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.2836</td>\n",
       "      <td>0.2795</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9513</td>\n",
       "      <td>272</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.3392</td>\n",
       "      <td>0.3415</td>\n",
       "      <td>0.8820</td>\n",
       "      <td>0.9383</td>\n",
       "      <td>150</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      loss  val_loss  val_accuracy  val_auc  duration recurrent_type  \\\n",
       "0   0.2056    0.2875        0.8797   0.9513        41            gru   \n",
       "1   0.2353    0.2692        0.8870   0.9535        40            gru   \n",
       "2   0.3410    0.2889        0.8803   0.9492        38            gru   \n",
       "3   0.2525    0.2727        0.8880   0.9538        40            gru   \n",
       "4   0.2657    0.2897        0.8887   0.9511        40            gru   \n",
       "5   0.2636    0.2839        0.8883   0.9526        41            gru   \n",
       "6   0.2342    0.2724        0.8853   0.9530        37            gru   \n",
       "7   0.2703    0.2835        0.8777   0.9494        37            gru   \n",
       "8   0.2427    0.2769        0.8870   0.9530        40            gru   \n",
       "9   0.3146    0.2738        0.8843   0.9527        37            gru   \n",
       "10  0.2718    0.2830        0.8817   0.9499        42            gru   \n",
       "11  0.3098    0.2690        0.8873   0.9518        42            gru   \n",
       "12  0.2138    0.2968        0.8867   0.9478        38            gru   \n",
       "13  0.2652    0.3308        0.8877   0.9366        42            gru   \n",
       "14  0.2752    0.3288        0.8833   0.9266        47            gru   \n",
       "15  0.2862    0.3134        0.8863   0.9456       257            gru   \n",
       "16  0.2836    0.2795        0.8867   0.9513       272            gru   \n",
       "17  0.3392    0.3415        0.8820   0.9383       150            gru   \n",
       "\n",
       "    rnn_layers  dense_layers  units  dropout_rate  bi_directional  \n",
       "0            1             1     32           0.0            True  \n",
       "1            1             1     32           0.1            True  \n",
       "2            1             1     32           0.2            True  \n",
       "3            1             1     32           0.3            True  \n",
       "4            1             1     32           0.4            True  \n",
       "5            1             1     32           0.5            True  \n",
       "6            1             1     16           0.0            True  \n",
       "7            1             1     16           0.1            True  \n",
       "8            1             1     16           0.2            True  \n",
       "9            1             1     16           0.3            True  \n",
       "10           1             1     16           0.4            True  \n",
       "11           1             1     16           0.5            True  \n",
       "12           1             1      8           0.0            True  \n",
       "13           1             1      8           0.1            True  \n",
       "14           1             1      8           0.2            True  \n",
       "15           1             1      8           0.3            True  \n",
       "16           1             1      8           0.4            True  \n",
       "17           1             1      8           0.5            True  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'recurrent_type': ['gru'],\n",
    "    'rnn_layers': [1],\n",
    "    'dense_layers': [1],\n",
    "    'units': [32,16,8],\n",
    "    'dropout_rate': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'bi_directional':[True]}\n",
    "\n",
    "iterate(sample_size=10000,\n",
    "        max_tokens=20000,\n",
    "        percentile_len=0.8,\n",
    "        batch_size=64,\n",
    "        param_dict= params,\n",
    "        runs = 3,\n",
    "        epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393bd4c-5f20-47ec-ad59-b40ebeb7e186",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
