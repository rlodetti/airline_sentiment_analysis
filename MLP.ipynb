{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "58cbf541-7bf1-4394-a11f-ff6d2b5fd36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nltk  # Added this import\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "# Ensure stopwords are downloaded only once (not a coding error, but a good practice)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "df = pd.read_csv('../data/Airline_review.csv')[['Review_Title','Review','Recommended']]\n",
    "X = df['Review_Title'] + ' ' + df['Review']\n",
    "y = df['Recommended'].map({'yes':1,'no':0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, test_size=(len(X_train)-5000)/len(X_train), stratify=y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e79af750-1f4c-437a-99cc-d62ef6f647fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stop_words=None, lemmatize=True):\n",
    "        self.stop_words = set(stop_words) if stop_words else None\n",
    "        self.lemmatize = lemmatize\n",
    "        self.lemmatizer = WordNetLemmatizer() if lemmatize else None\n",
    "        self.tokenizer = RegexpTokenizer(r\"([a-zA-Z]+(?:â€™[a-z]+)?)\")\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # No fitting necessary for this transformer\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return [self.clean_text(review) for review in X]\n",
    "    \n",
    "    def clean_text(self, review):\n",
    "        tokens = self.tokenizer.tokenize(review.lower())  # Tokenize and lowercase\n",
    "        if self.lemmatize:\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            tokens = [self.lemmatizer.lemmatize(word, self.get_wordnet_pos(tag))\n",
    "                      for word, tag in pos_tags]\n",
    "        if self.stop_words:\n",
    "            tokens = [word for word in tokens if word not in self.stop_words]\n",
    "        \n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def get_wordnet_pos(self, treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "def summarize_mlp_grid_search_results(grid_search):\n",
    "    columns_to_extract = [\n",
    "        ('mean_fit_time', 'fit_time'),\n",
    "        ('mean_score_time', 'score_time'),\n",
    "        ('param_mlp__model__num_layers', 'num_layers'),\n",
    "        ('param_mlp__model__units', 'units'),\n",
    "        ('mean_test_score', 'balanced_accuracy'),\n",
    "        ('param_mlp__model__initializer','initializer'),\n",
    "        ('param_mlp__model__dropout_rate', 'dropout_rate')\n",
    "        \n",
    "    ]\n",
    "    summary_df = pd.DataFrame(grid_search.cv_results_)[[original for original, renamed in columns_to_extract]]\n",
    "\n",
    "    summary_df.columns = [renamed for original, renamed in columns_to_extract]\n",
    "    \n",
    "    # Calculate total time and convert to int\n",
    "    summary_df['time'] = (summary_df['fit_time'] + summary_df['score_time']).astype(int)\n",
    "    \n",
    "    # Reorder and select final columns for the output\n",
    "    final_columns = ['balanced_accuracy', 'time', 'num_layers', 'units', 'dropout_rate', 'initializer']\n",
    "    final_df = summary_df[final_columns]\n",
    "    sorted_df = final_df.sort_values(by=['balanced_accuracy', 'time'], ascending=[False, True])\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "def summarize_rnn_grid_search_results(grid_search):\n",
    "    columns_to_extract = [\n",
    "        ('mean_fit_time', 'fit_time'),\n",
    "        ('mean_score_time', 'score_time'),\n",
    "        ('param_rnn__model__bi_directional', 'bi_directional'),\n",
    "        ('param_rnn__model__dense_layers', 'num_dense_layers'),\n",
    "        ('param_rnn__model__recurrent_type', 'recurrent_type'),\n",
    "        ('param_rnn__model__rnn_layers', 'num_rnn_layers'),\n",
    "        ('param_rnn__model__units', 'units'),\n",
    "        ('param_rnn__model__dropout_rate', 'dropout_rate'),\n",
    "        ('mean_train_score', 'train_score'),\n",
    "        ('mean_test_score', 'test_score')\n",
    "    ]\n",
    "    summary_df = pd.DataFrame(grid_search.cv_results_)[[original for original, renamed in columns_to_extract]]\n",
    "\n",
    "    summary_df.columns = [renamed for original, renamed in columns_to_extract]\n",
    "    \n",
    "    # Calculate total time and convert to int\n",
    "    summary_df['time'] = (summary_df['fit_time'] + summary_df['score_time']).astype(int)\n",
    "    \n",
    "    # Reorder and select final columns for the output\n",
    "    final_columns = ['train_score', 'test_score', 'time', 'units', 'bi_directional', 'recurrent_type', 'num_rnn_layers', 'num_dense_layers', 'dropout_rate']\n",
    "    final_df = summary_df[final_columns]\n",
    "    sorted_df = final_df.sort_values(by=['test_score', 'time'], ascending=[False, True])\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_train)\n",
    "X_train_clean_sampled = text_cleaner.transform(X_train_sampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24885d1-ec69-418f-bba3-cf67e12387f8",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1306d842-66c7-487b-ae0d-906526eed281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 32 candidates, totalling 96 fits\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\scikeras\\wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\ronlo\\anaconda3\\envs\\capstone2-env\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.5532 - accuracy: 0.8126\n",
      "Epoch 2/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.3777 - accuracy: 0.8794\n",
      "Epoch 3/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.3145 - accuracy: 0.9041\n",
      "Epoch 4/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.2756 - accuracy: 0.9197\n",
      "Epoch 5/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.2442 - accuracy: 0.9282\n",
      "Epoch 6/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.9322\n",
      "Epoch 7/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1956 - accuracy: 0.9426\n",
      "Epoch 8/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1820 - accuracy: 0.9464\n",
      "Epoch 9/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1665 - accuracy: 0.9519\n",
      "Epoch 10/20\n",
      "290/290 [==============================] - 1s 3ms/step - loss: 0.1538 - accuracy: 0.9564\n",
      "Epoch 11/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1417 - accuracy: 0.9596\n",
      "Epoch 12/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1299 - accuracy: 0.9637\n",
      "Epoch 13/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1205 - accuracy: 0.9677\n",
      "Epoch 14/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1111 - accuracy: 0.9702\n",
      "Epoch 15/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.1018 - accuracy: 0.9739\n",
      "Epoch 16/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.0955 - accuracy: 0.9761\n",
      "Epoch 17/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.0903 - accuracy: 0.9760\n",
      "Epoch 18/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.0856 - accuracy: 0.9789\n",
      "Epoch 19/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.0803 - accuracy: 0.9802\n",
      "Epoch 20/20\n",
      "290/290 [==============================] - 1s 2ms/step - loss: 0.0763 - accuracy: 0.9806\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>balanced_accuracy</th>\n",
       "      <th>time</th>\n",
       "      <th>num_layers</th>\n",
       "      <th>units</th>\n",
       "      <th>dropout_rate</th>\n",
       "      <th>initializer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.903777</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.903689</td>\n",
       "      <td>242</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.901034</td>\n",
       "      <td>238</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.899201</td>\n",
       "      <td>244</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.898304</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.897982</td>\n",
       "      <td>238</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.896635</td>\n",
       "      <td>161</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.895369</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.893785</td>\n",
       "      <td>244</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.893504</td>\n",
       "      <td>202</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.888659</td>\n",
       "      <td>243</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.887637</td>\n",
       "      <td>246</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.887352</td>\n",
       "      <td>263</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.887088</td>\n",
       "      <td>161</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.886887</td>\n",
       "      <td>243</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.886331</td>\n",
       "      <td>222</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.885199</td>\n",
       "      <td>236</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.885178</td>\n",
       "      <td>209</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.883949</td>\n",
       "      <td>264</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.883882</td>\n",
       "      <td>258</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.883151</td>\n",
       "      <td>175</td>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.882448</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.882001</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.881991</td>\n",
       "      <td>206</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.881821</td>\n",
       "      <td>256</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.881760</td>\n",
       "      <td>228</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.881641</td>\n",
       "      <td>199</td>\n",
       "      <td>1</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.880786</td>\n",
       "      <td>254</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.877917</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.877560</td>\n",
       "      <td>273</td>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.877305</td>\n",
       "      <td>232</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.876957</td>\n",
       "      <td>215</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>0.25</td>\n",
       "      <td>he_normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    balanced_accuracy  time num_layers units dropout_rate initializer\n",
       "16           0.903777   200          1     8          0.5        None\n",
       "24           0.903689   242          1     8          0.5   he_normal\n",
       "20           0.901034   238          2     8          0.5        None\n",
       "28           0.899201   244          2     8          0.5   he_normal\n",
       "8            0.898304   160          1     8         0.25   he_normal\n",
       "0            0.897982   238          1     8         0.25        None\n",
       "4            0.896635   161          2     8         0.25        None\n",
       "12           0.895369   221          2     8         0.25   he_normal\n",
       "25           0.893785   244          1    16          0.5   he_normal\n",
       "17           0.893504   202          1    16          0.5        None\n",
       "29           0.888659   243          2    16          0.5   he_normal\n",
       "18           0.887637   246          1    32          0.5        None\n",
       "26           0.887352   263          1    32          0.5   he_normal\n",
       "9            0.887088   161          1    16         0.25   he_normal\n",
       "1            0.886887   243          1    16         0.25        None\n",
       "30           0.886331   222          2    32          0.5   he_normal\n",
       "21           0.885199   236          2    16          0.5        None\n",
       "13           0.885178   209          2    16         0.25   he_normal\n",
       "22           0.883949   264          2    32          0.5        None\n",
       "23           0.883882   258          2    64          0.5        None\n",
       "5            0.883151   175          2    16         0.25        None\n",
       "6            0.882448   206          2    32         0.25        None\n",
       "2            0.882001   258          1    32         0.25        None\n",
       "31           0.881991   206          2    64          0.5   he_normal\n",
       "27           0.881821   256          1    64          0.5   he_normal\n",
       "14           0.881760   228          2    32         0.25   he_normal\n",
       "10           0.881641   199          1    32         0.25   he_normal\n",
       "19           0.880786   254          1    64          0.5        None\n",
       "3            0.877917   261          1    64         0.25        None\n",
       "11           0.877560   273          1    64         0.25   he_normal\n",
       "7            0.877305   232          2    64         0.25        None\n",
       "15           0.876957   215          2    64         0.25   he_normal"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model\n",
    "def build_mlp_model(num_layers=1, units=64, initializer=None, dropout_rate=0.2):\n",
    "    model = Sequential()\n",
    "    model.add(layers.InputLayer(input_shape=(20000,)))\n",
    "    for _ in range(num_layers):\n",
    "        model.add(layers.Dense(units, activation=\"relu\", kernel_initializer=initializer))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(8, units // 2)\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "    \n",
    "# Setting parameters\n",
    "k_best = SelectKBest(k=20000)\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              min_delta=0.001,\n",
    "                                              patience=5, \n",
    "                                              restore_best_weights=True,\n",
    "                                              verbose=1)]\n",
    "\n",
    "# Instantiate transformers\n",
    "vectorizer = CountVectorizer(decode_error='replace', strip_accents='unicode', stop_words=None, ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "tf_idf = TfidfTransformer()\n",
    "nlp_model_wrapper = KerasClassifier(build_fn=build_mlp_model,\n",
    "                                random_state=42,\n",
    "                                optimizer='adam',\n",
    "                                loss='binary_crossentropy',\n",
    "                                metrics=['accuracy'],\n",
    "                                batch_size=64,\n",
    "                                verbose=1,\n",
    "                                callbacks=CALLBACKS,\n",
    "                                shuffle=True,\n",
    "                                epochs=20)\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf', tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    ('mlp', nlp_model_wrapper)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'mlp__model__num_layers': [1,2],  \n",
    "    'mlp__model__units': [8, 16, 32, 64],\n",
    "    'mlp__model__initializer': [None,'he_normal'],\n",
    "    'mlp__model__dropout_rate': [0.25, 0.5]}\n",
    "\n",
    "gs_1 = GridSearchCV(estimator=pipe, \n",
    "                  param_grid=params,\n",
    "                  scoring='balanced_accuracy',\n",
    "                  cv=skf,\n",
    "                  verbose=3,\n",
    "                  error_score=0,\n",
    "                  n_jobs= -1)\n",
    "\n",
    "mlp_grid_search = gs_1.fit(X_train_clean, y_train)\n",
    "summarize_mlp_grid_search_results(mlp_grid_search)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
