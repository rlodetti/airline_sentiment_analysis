{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f7cc28-6628-4dc2-bab5-e5118e1effe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from nltk.corpus import stopwords\n",
    "STOPWORDS = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684f04ed-8be3-42cc-a340-db1431a6eb56",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595f539b-6351-4514-84f1-51c51c478ea9",
   "metadata": {},
   "source": [
    "- Combine title & review into one column\n",
    "- Binary Encode target labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9be554d-7eef-48ea-bda5-889a023b8988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Airline_review.csv')[['Review_Title','Review','Recommended']]\n",
    "reviews = df['Review_Title'] + ' ' + df['Review']\n",
    "labels = df['Recommended'].map({'yes':1,'no':0})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af7c6b1-9d5e-4f27-942a-e09b2cf59e07",
   "metadata": {},
   "source": [
    "## Data Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a307c6a-4be1-4d07-95ff-7809517f3bf6",
   "metadata": {},
   "source": [
    "- Standard cleaning and tokenization for understanding\n",
    "- Number of Reviews\n",
    "- Number and distribution of target\n",
    "- Number of words per review\n",
    "- Frequency distribution of words\n",
    "- Distribution of review length\n",
    "\n",
    "**Next Steps**: \n",
    "- Maybe show difference between yes and no reviews\n",
    "- also show after stopwords have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06d87b22-4ff5-4758-b4af-3f9495fe19a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard cleaning and tokenization for understanding\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    \"\"\"Convert treebank POS tags to wordnet POS tags.\"\"\"\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(document, stop_words = None):\n",
    "    \"\"\"\n",
    "    Clean and preprocess the text document.\n",
    "    \n",
    "    Parameters:\n",
    "        document (str): The text document to clean.\n",
    "        stop_words (list): A list of stop words to exclude.\n",
    "        \n",
    "    Returns:\n",
    "        str: The cleaned and lemmatized text.\n",
    "    \"\"\"\n",
    "    # Initialize a tokenizer with a regex for words and contractions\n",
    "    tokenizer = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "    \n",
    "    # Tokenize the document\n",
    "    tokens = tokenizer.tokenize(document)\n",
    "    \n",
    "    # Convert tokens to lowercase if not a stop word\n",
    "    if stop_words == None:\n",
    "        tokens = [word.lower() for word in tokens]\n",
    "    else:\n",
    "        tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "    \n",
    "    # Tag tokens with part-of-speech tags\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    \n",
    "    # Convert treebank POS tags to wordnet POS tags\n",
    "    wordnet_tags = [(word, get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "    \n",
    "    # Initialize the lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    \n",
    "    # Lemmatize words based on their POS tags\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word, tag) for word, tag in wordnet_tags]\n",
    "    \n",
    "    return lemmatized_tokens\n",
    "reviews_tokened = [clean_text(review) for review in reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61071a92-d43b-4769-80d0-742dbbce91be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23171"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Reviews\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369a145f-8f62-4aed-b5b4-1cc7ec726441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number and distribution of target\n",
    "display(df['Recommended'].value_counts())\n",
    "print('')\n",
    "display(df['Recommended'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5e30f627-a5f6-49f9-8d3b-f13bfb3eabec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "105.0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of words per review\n",
    "review_lengths = [len(review) for review in reviews_tokened]\n",
    "np.median(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fb5223-7369-49f9-9ffe-b3dc35f437fb",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Frequency distribution of words\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "import seaborn as sns\n",
    "\n",
    "fdist = FreqDist(word for review in reviews_tokened for word in review)\n",
    "top_words = fdist.most_common(25)\n",
    "words = []\n",
    "counts = []\n",
    "for word, count in top_words:\n",
    "    words.append(word)\n",
    "    counts.append(count)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "sns.barplot(x=words, y=counts, ax= ax)\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7280bfed-44c4-4d15-aad9-0d6dea8c81d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review length\n",
    "sns.histplot(review_lengths)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd71af02-9e66-44f7-8512-cb86e894334d",
   "metadata": {},
   "source": [
    "## Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c246439-ca3c-4821-980b-d4443a011148",
   "metadata": {},
   "source": [
    "- Split raw data into train-val-test sets\n",
    "- Manually Normalize\n",
    "  - Remove punctuation\n",
    "  - remove stop words\n",
    "  - lowercase\n",
    "  - part of speech tags\n",
    "  - lemmanize\n",
    "- Normalize by creating tensorflow datasets\n",
    "  - CountVectorization\n",
    "  - TfidfVecorization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e8c60f7-7a59-4d10-9977-55dfea3ffd3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Labels\n",
      "  Yes Reviews:\n",
      "     Count: 6245\n",
      "     Percent: 33.69%\n",
      "  No Reviews:\n",
      "     Count: 12291\n",
      "     Percent: 66.31%\n",
      "\n",
      "Validation Labels\n",
      "  Yes Reviews:\n",
      "     Count: 781\n",
      "     Percent: 33.71%\n",
      "  No Reviews:\n",
      "     Count: 1536\n",
      "     Percent: 66.29%\n",
      "\n",
      "Testing Labels\n",
      "  Yes Reviews:\n",
      "     Count: 781\n",
      "     Percent: 33.69%\n",
      "  No Reviews:\n",
      "     Count: 1537\n",
      "     Percent: 66.31%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Make 80-10-10 train-validation-test split\n",
    "\n",
    "# First split with stratification\n",
    "train_reviews, temp_reviews, train_labels, temp_labels = train_test_split(reviews, labels, test_size=0.2, stratify=labels, random_state=42)\n",
    "\n",
    "# Second split for val and test sets with stratification\n",
    "val_reviews, test_reviews, val_labels, test_labels = train_test_split(temp_reviews, temp_labels, test_size=0.5, stratify=temp_labels, random_state=42)\n",
    "\n",
    "def label_distribution(name,labels):\n",
    "    total = len(labels)\n",
    "    yes_counts = (labels==1).sum()\n",
    "    yes_rate = yes_counts/total\n",
    "    no_counts = (labels==0).sum()\n",
    "    no_rate = no_counts/total\n",
    "    print(f'{name} Labels')\n",
    "    print('  Yes Reviews:')\n",
    "    print(f'     Count: {yes_counts}')\n",
    "    print(f'     Percent: {round(100*yes_rate,2)}%')\n",
    "    print('  No Reviews:')\n",
    "    print(f'     Count: {no_counts}')\n",
    "    print(f'     Percent: {round(100*no_rate,2)}%')\n",
    "    print('')\n",
    "\n",
    "label_distribution('Training',train_labels)\n",
    "label_distribution('Validation',val_labels)\n",
    "label_distribution('Testing',test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7044ae49-c886-41aa-8e9b-226892ea9fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I don't need to do this as I will include it in my pipeline\n",
    "# Manual Normalization including stopword removal\n",
    "# STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# X_train = [clean_text(review, stop_words = STOPWORDS) for review in train_reviews]\n",
    "# X_val = [clean_text(review, stop_words = STOPWORDS) for review in val_reviews]\n",
    "# X_test = [clean_text(review, stop_words = STOPWORDS) for review in test_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a2792b1e-df90-4873-9622-3390a054abc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating tensorflow datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "import tensorflow as tf\n",
    "\n",
    "def vectorize_text(train_reviews, val_reviews, test_reviews, stop_words, use_tf_idf=False):\n",
    "    \"\"\"\n",
    "    Vectorizes text data. Optionally applies TF-IDF transformation.\n",
    "    \"\"\"\n",
    "    vectorizer = CountVectorizer(decode_error='replace', strip_accents='unicode', stop_words=stop_words,\n",
    "                                 ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "    if use_tf_idf:\n",
    "        pipeline = make_pipeline(vectorizer, TfidfTransformer())\n",
    "        X_train = pipeline.fit_transform(train_reviews)\n",
    "        X_val = pipeline.transform(val_reviews)\n",
    "        X_test = pipeline.transform(test_reviews)\n",
    "    else:\n",
    "        X_train = vectorizer.fit_transform(train_reviews)\n",
    "        X_val = vectorizer.transform(val_reviews)\n",
    "        X_test = vectorizer.transform(test_reviews)\n",
    "    return X_train, X_val, X_test\n",
    "\n",
    "def select_features(X_train, train_labels, X_val, X_test, k_best=20000):\n",
    "    \"\"\"\n",
    "    Selects the k best features from the vectorized text data.\n",
    "    \"\"\"\n",
    "    selector = SelectKBest(k=min(k_best, X_train.shape[1]))\n",
    "    selector.fit(X_train, train_labels)\n",
    "    X_train_selected = selector.transform(X_train)\n",
    "    X_val_selected = selector.transform(X_val)\n",
    "    X_test_selected = selector.transform(X_test)\n",
    "    return X_train_selected, X_val_selected, X_test_selected\n",
    "\n",
    "def create_tf_datasets(X_train_selected, train_labels, X_val_selected, val_labels, X_test_selected, test_labels):\n",
    "    \"\"\"\n",
    "    Converts selected features and labels into TensorFlow datasets.\n",
    "    \"\"\"\n",
    "    train_ds = tf.data.Dataset.from_tensor_slices((X_train_selected.toarray(), train_labels.astype('float32')))\n",
    "    val_ds = tf.data.Dataset.from_tensor_slices((X_val_selected.toarray(), val_labels.astype('float32')))\n",
    "    test_ds = tf.data.Dataset.from_tensor_slices((X_test_selected.toarray(), test_labels.astype('float32')))\n",
    "    \n",
    "    train_ds = train_ds.shuffle(1000, reshuffle_each_iteration=True).batch(64).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    val_ds = val_ds.batch(64).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    test_ds = test_ds.batch(64).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "def prepare_datasets(train_reviews, train_labels, val_reviews, val_labels, test_reviews, test_labels, stop_words, use_tf_idf=False, k_best=20000):\n",
    "    \"\"\"\n",
    "    Prepares training and validation datasets by vectorizing text data, selecting features,\n",
    "    and converting to TensorFlow datasets.\n",
    "    \"\"\"\n",
    "    X_train, X_val, X_test = vectorize_text(train_reviews, val_reviews, test_reviews, stop_words, use_tf_idf)\n",
    "    X_train_selected, X_val_selected, X_test_selected = select_features(X_train, train_labels, X_val, X_test, k_best)\n",
    "    train_ds, val_ds, test_ds = create_tf_datasets(X_train_selected, train_labels, X_val_selected, val_labels, X_test_selected, test_labels)\n",
    "    return train_ds, val_ds, test_ds\n",
    "\n",
    "# Counts\n",
    "# train_ds_counts, val_ds_counts, test_ds_counts = prepare_datasets(train_reviews, train_labels, val_reviews, val_labels, test_reviews, test_labels, STOPWORDS)\n",
    "\n",
    "# Tf-idf\n",
    "# train_ds_tfidf, val_ds_tfidf, test_ds_tfidf = prepare_datasets(train_reviews, train_labels, val_reviews, val_labels, test_reviews, test_labels, STOPWORDS, use_tf_idf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfa53d6-426f-4328-9389-b3db511d723f",
   "metadata": {},
   "source": [
    "## Data Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1618b676-1d95-4eed-a8f1-c1d2b438d62e",
   "metadata": {},
   "source": [
    "- CountVectorizer vs TfidfVectorizer\n",
    "- Basic\n",
    "  - Dummy\n",
    "  - Baseline: LogisticRegression\n",
    "  - MultinomialNB\n",
    "  - SVC\n",
    "- Ensemble\n",
    "  - GradientBoostingClassifier\n",
    "  - RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8c445d9-0bd1-4963-a3d3-eb0d76c004e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "\n",
    "class TextCleanerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stop_words=None):\n",
    "        self.stop_words = stop_words\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self  # Nothing to do here\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        cleaned_reviews = []\n",
    "        for review in X:\n",
    "            cleaned_reviews.append(self.clean_text(review, self.stop_words))\n",
    "        return cleaned_reviews\n",
    "    \n",
    "    def clean_text(self, review, stop_words):\n",
    "        tokenizer = RegexpTokenizer(r\"([a-zA-Z]+(?:’[a-z]+)?)\")\n",
    "        tokens = tokenizer.tokenize(review)\n",
    "        if stop_words is None:\n",
    "            tokens = [word.lower() for word in tokens]\n",
    "        else:\n",
    "            tokens = [word.lower() for word in tokens if word.lower() not in stop_words]\n",
    "        \n",
    "        pos_tags = pos_tag(tokens)\n",
    "        wordnet_tags = [(word, self.get_wordnet_pos(tag)) for word, tag in pos_tags]\n",
    "        lemmatizer = WordNetLemmatizer()\n",
    "        lemmatized_tokens = [lemmatizer.lemmatize(word, tag) for word, tag in wordnet_tags]\n",
    "        return ' '.join(lemmatized_tokens)\n",
    "    \n",
    "    def get_wordnet_pos(self, treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "def model_cv_scores(pipeline, model_name, X= None, y= None, scoring=None, cv=None):\n",
    "    \"\"\"\n",
    "    Performs cross-validation on the given pipeline and data, displaying the results.\n",
    "    \n",
    "    Parameters:\n",
    "    - pipeline: The scikit-learn pipeline to evaluate.\n",
    "    - model_name: A name for the model, used in the output DataFrame.\n",
    "    - X: The feature matrix. Default is None. Should be provided explicitly.\n",
    "    - y: The target vector. Default is None. Should be provided explicitly.\n",
    "    - scoring: Scoring parameter for cross-validation. Default is None. Should be provided explicitly.\n",
    "    - cv: Cross-validation splitting strategy. Default is None. Should be provided explicitly.\n",
    "    \n",
    "    Returns:\n",
    "    - A dictionary containing the cross-validation scores.\n",
    "    \"\"\"\n",
    "    scores = cross_validate(pipeline, X, y, scoring=scoring, cv=cv, n_jobs=-1, return_train_score=False)\n",
    "    \n",
    "    # Calculating mean values and rounding them for readability\n",
    "    time = round((scores['fit_time'] + scores['score_time']).mean())\n",
    "    accuracy = round(scores['test_accuracy'].mean(), 4)\n",
    "    roc_auc = round(scores['test_roc_auc'].mean(), 4)\n",
    "    \n",
    "    # Creating and displaying a DataFrame with the results\n",
    "    results_df = pd.DataFrame([[accuracy, roc_auc, time]], \n",
    "                              index=[model_name], \n",
    "                              columns=['Accuracy', 'ROC AUC', 'Time (s)'])\n",
    "    display(results_df)\n",
    "\n",
    "def RandCV_scores(model_name,random_search):\n",
    "    index = random_search.best_index_\n",
    "    results = random_search.cv_results_\n",
    "\n",
    "    # Calculating mean values and rounding them for readability\n",
    "    time = round(results['mean_fit_time'][index] + results['mean_score_time'][index])\n",
    "    accuracy = round(results['mean_test_accuracy'][index], 4)\n",
    "    roc_auc = round(results['mean_test_roc_auc'][index], 4)\n",
    "    \n",
    "    # Creating and displaying a DataFrame with the results\n",
    "    results_df = pd.DataFrame([[accuracy, roc_auc, time]], \n",
    "                              index=[model_name+'_RandCV'], \n",
    "                              columns=['Accuracy', 'ROC AUC', 'Time (s)'])\n",
    "    display(results_df)\n",
    "    return random_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55d92c06-ed2d-49b3-9cc7-bc4dd95b744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate, StratifiedKFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Instantiating processing transformers\n",
    "text_cleaner = TextCleanerTransformer(stop_words=STOPWORDS)\n",
    "vectorizer = CountVectorizer(decode_error='replace', strip_accents='unicode', stop_words=None, ngram_range=(1, 2), max_df=0.95, min_df=2)\n",
    "tf_idf = TfidfTransformer()\n",
    "k_best = SelectKBest(k=10000)\n",
    "\n",
    "# Setting CV parameters\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "SCORING = {'accuracy':'accuracy',\n",
    "           'roc_auc':'roc_auc'}\n",
    "\n",
    "# Concatenating the valildation set as I don't need it here. 90-10 split\n",
    "X_train = pd.concat([train_reviews, val_reviews])\n",
    "y_train = pd.concat([train_labels, val_labels])\n",
    "\n",
    "# Clean data before entering the pipeline for efficiency\n",
    "X_train_clean = text_cleaner.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bac2eab-439f-451e-bbaf-9f4614339d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dummy Model\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "clf = DummyClassifier(strategy='uniform', random_state=42)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"dummy\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'Dummy', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22dc7ff-d934-4cb9-b4e3-e245cadac751",
   "metadata": {},
   "source": [
    "### Bag of Words Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821affd0-113b-4f8b-a176-ff7cc4e29d77",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6fe813-7c36-4842-b676-684a2d785d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"log_reg\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'log_reg', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e0d7d98-39f2-48ee-827a-280b69a076f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression RandCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import loguniform\n",
    "\n",
    "clf = LogisticRegression()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"log_reg\", clf)])\n",
    "\n",
    "params = {\n",
    "    'log_reg__C': loguniform(0.001, 100),\n",
    "    'log_reg__solver': ['liblinear', 'lbfgs', 'sag', 'newton-cg'],\n",
    "    'log_reg__max_iter': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator= pipe, \n",
    "                        param_distributions= params,\n",
    "                        n_iter=100, \n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        scoring=SCORING,\n",
    "                        refit= 'roc_auc',\n",
    "                        random_state=42)\n",
    "rand_search = rs.fit(X_train_clean, y_train)\n",
    "RandCV_scores('log_reg',rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db6c42e-b603-4d16-aa36-3783d8fdad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"mnb\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'mnb', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee05392-607f-40aa-afed-912ba97936eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB RandCV\n",
    "clf = MultinomialNB()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"mnb\", clf)])\n",
    "\n",
    "params = {\n",
    "    'mnb__alpha': [0.01, 0.1, 0.5, 1.0, 2.0, 5.0],\n",
    "    'mnb__fit_prior': [True, False],\n",
    "    'mnb__class_prior': [None,[0.66,0.34]]\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator= pipe, \n",
    "                        param_distributions= params,\n",
    "                        n_iter=100, \n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        scoring=SCORING,\n",
    "                        refit= 'roc_auc',\n",
    "                        random_state=42)\n",
    "rand_search = rs.fit(X_train_clean, y_train)\n",
    "RandCV_scores('mnb',rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd7efc7-1c7b-49f3-9fb9-e4e5e80ae696",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"svc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'svc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)\n",
    "# Too Slow even for one round, not doing RandomizedCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef7958-3dc0-4ac5-97a0-b9dfa37f391a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                    max_depth=3, min_samples_split=2,\n",
    "                                    max_features=None)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"gbc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'gbc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2033f9-f9be-4bf2-894b-ae325a2df3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier RandCV\n",
    "clf = GradientBoostingClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"gbc\", clf)])\n",
    "\n",
    "params = {\n",
    "    'gbc__n_estimators': [100, 200, 300],  # Number of boosting stages\n",
    "    'gbc__learning_rate': [0.01, 0.05, 0.1, 0.2],  # Learning rate\n",
    "    'gbc__max_depth': [3, 4, 5, 6],  # Maximum depth of the individual estimators\n",
    "    'gbc__min_samples_split': [2, 4, 6],  # Minimum number of samples required to split an internal node\n",
    "    'gbc__max_features': [None, 'sqrt', 'log2'],  # Number of features to consider when looking for the best split\n",
    "    'gbc__subsample': [0.8, 0.9, 1.0],  # The fraction of samples to be used for fitting the individual base learners\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator= pipe, \n",
    "                        param_distributions= params,\n",
    "                        n_iter=100, \n",
    "                        cv=3,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        scoring=SCORING,\n",
    "                        refit= 'roc_auc',\n",
    "                        random_state=42)\n",
    "rand_search = rs.fit(X_train_clean, y_train)\n",
    "RandCV_scores('gbc',rand_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2707c356-6d93-4eb2-9e4f-0c0edbd25ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None,\n",
    "                                min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='sqrt')\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"rfc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'rfc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed9ddd4-1675-4f77-aa50-f8bc3b60c262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier RandCV\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"rfc\", clf)])\n",
    "\n",
    "params = {\n",
    "    'rfc__n_estimators': [100, 200, 300, 400, 500],  # Number of trees\n",
    "    'rfc__max_depth': [None, 10, 20, 30, 40, 50],  # Maximum depth of the trees\n",
    "    'rfc__min_samples_split': [2, 5, 10],  # Minimum number of samples required to split an internal node\n",
    "    'rfc__min_samples_leaf': [1, 2, 4],  # Minimum number of samples required to be at a leaf node\n",
    "    'rfc__max_features': ['auto', 'sqrt', 'log2'],  # Number of features to consider for the best split\n",
    "    'rfc__bootstrap': [True, False],  # Method of selecting samples for training each tree\n",
    "}\n",
    "\n",
    "rs = RandomizedSearchCV(estimator= pipe, \n",
    "                        param_distributions= params,\n",
    "                        n_iter=100, \n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        scoring=SCORING,\n",
    "                        refit= 'roc_auc',\n",
    "                        random_state=42)\n",
    "rand_search = rs.fit(X_train_clean, y_train)\n",
    "RandCV_scores('rfc',rand_search)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aaf641b-7044-4f7d-8b50-2441b87995a0",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9679d5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "clf = LogisticRegression(max_iter=1000)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"log_reg\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'log_reg', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af60724d-95e3-4146-abd6-a5808a977d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MultinomialNB\n",
    "clf = MultinomialNB(alpha=1.0, fit_prior=True)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"mnb\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'mnb', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72d71f-2c07-4ffd-8a10-b7e0d603f4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC\n",
    "clf = SVC(C=1.0, kernel='rbf', gamma='scale')\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"svc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'svc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c392f3-c9ef-4a91-b973-30a89451aed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, learning_rate=0.1,\n",
    "                                    max_depth=3, min_samples_split=2,\n",
    "                                    max_features=None)\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"gbc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'gbc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9f0b21-73b4-42d0-b2e2-6c7d562ebb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestClassifier\n",
    "clf = RandomForestClassifier(n_estimators=100, max_depth=None,\n",
    "                                min_samples_split=2, min_samples_leaf=1,\n",
    "                                max_features='sqrt')\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    (\"rfc\", clf)])\n",
    "\n",
    "model_cv_scores(pipe, 'rfc', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94764d9-ab51-440e-b630-ac5e93415f61",
   "metadata": {},
   "source": [
    "### Multi-layer perceptrons (MLPs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "848a5266-18bd-451a-a233-f66688ee3989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='loss', \n",
    "                                              patience=5, \n",
    "                                              restore_best_weights=True,\n",
    "                                              verbose=1,\n",
    "                                              start_from_epoch=5)]\n",
    "# Concatenating the valildation set as I don't need it here. 90-10 split\n",
    "X_train = pd.concat([train_reviews, val_reviews])\n",
    "y_train = pd.concat([train_labels, val_labels])\n",
    "\n",
    "# Clean data before entering the pipeline for efficiency\n",
    "X_train_clean = text_cleaner.transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2ed51f6-ad8b-4b63-bebe-80ab3cc5fe15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7d86dc5-6e83-41a0-90fc-0e9dd17c24ab",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-27 21:44:01.020589: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 21:44:01.021428: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 21:44:01.021805: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 21:44:01.026908: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-27 21:44:01.029234: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "/Users/ronlodetti/anaconda3/envs/capstone2-env/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/ronlodetti/anaconda3/envs/capstone2-env/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/ronlodetti/anaconda3/envs/capstone2-env/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/ronlodetti/anaconda3/envs/capstone2-env/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n",
      "/Users/ronlodetti/anaconda3/envs/capstone2-env/lib/python3.11/site-packages/scikeras/wrappers.py:915: UserWarning: ``build_fn`` will be renamed to ``model`` in a future release, at which point use of ``build_fn`` will raise an Error instead.\n",
      "  X, y = self._initialize(X, y)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "Epoch 1/100\n",
      "522/522 [==============================] - 3s 4ms/step - loss: 0.4176 - accuracy: 0.8530 - auc: 0.9253\n",
      "506/522 [============================>.] - ETA: 0s - loss: 0.4311 - accuracy: 0.8342 - auc: 0.9186Epoch 2/100\n",
      "522/522 [==============================] - 3s 4ms/step - loss: 0.4266 - accuracy: 0.8364 - auc: 0.9198\n",
      "522/522 [==============================] - 3s 4ms/step - loss: 0.4485 - accuracy: 0.8709 - auc: 0.9256\n",
      "Epoch 2/100\n",
      "Epoch 2/100\n",
      "522/522 [==============================] - 3s 4ms/step - loss: 0.4378 - accuracy: 0.8563 - auc: 0.9257\n",
      " 33/522 [>.............................] - ETA: 1s - loss: 0.2472 - accuracy: 0.9223 - auc: 0.9680Epoch 2/100\n",
      "522/522 [==============================] - 3s 4ms/step - loss: 0.4283 - accuracy: 0.8250 - auc: 0.9171\n",
      " 29/522 [>.............................] - ETA: 1s - loss: 0.2552 - accuracy: 0.9084 - auc: 0.9697Epoch 2/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.2246 - accuracy: 0.9193 - auc: 0.9704\n",
      "Epoch 3/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.2284 - accuracy: 0.9178 - auc: 0.9686\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.2295 - accuracy: 0.9186 - auc: 0.9696\n",
      "Epoch 3/100\n",
      "Epoch 3/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.2296 - accuracy: 0.9196 - auc: 0.9696\n",
      "Epoch 3/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.2307 - accuracy: 0.9158 - auc: 0.9681\n",
      "  1/522 [..............................] - ETA: 34s - loss: 0.1324 - accuracy: 0.9688 - auc: 1.0000Epoch 3/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1752 - accuracy: 0.9374 - auc: 0.9808\n",
      "450/522 [========================>.....] - ETA: 0s - loss: 0.1841 - accuracy: 0.9326 - auc: 0.9784Epoch 4/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1790 - accuracy: 0.9336 - auc: 0.9798\n",
      "Epoch 4/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1788 - accuracy: 0.9359 - auc: 0.9799\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1792 - accuracy: 0.9350 - auc: 0.9796\n",
      " 16/522 [..............................] - ETA: 1s - loss: 0.1601 - accuracy: 0.9492 - auc: 0.9826 Epoch 4/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1819 - accuracy: 0.9332 - auc: 0.9790\n",
      "Epoch 4/100\n",
      " 79/522 [===>..........................] - ETA: 1s - loss: 0.1562 - accuracy: 0.9403 - auc: 0.9852Epoch 4/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1455 - accuracy: 0.9489 - auc: 0.9867\n",
      "Epoch 5/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1489 - accuracy: 0.9479 - auc: 0.9861\n",
      "387/522 [=====================>........] - ETA: 0s - loss: 0.1505 - accuracy: 0.9480 - auc: 0.9854Epoch 5/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1493 - accuracy: 0.9463 - auc: 0.9858\n",
      " 16/522 [..............................] - ETA: 3s - loss: 0.1078 - accuracy: 0.9688 - auc: 0.9938Epoch 5/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1528 - accuracy: 0.9447 - auc: 0.9852\n",
      " 70/522 [===>..........................] - ETA: 2s - loss: 0.1313 - accuracy: 0.9549 - auc: 0.9891Epoch 5/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1499 - accuracy: 0.9462 - auc: 0.9856\n",
      " 78/522 [===>..........................] - ETA: 2s - loss: 0.1385 - accuracy: 0.9499 - auc: 0.9880Epoch 5/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1237 - accuracy: 0.9567 - auc: 0.9905\n",
      "494/522 [===========================>..] - ETA: 0s - loss: 0.1266 - accuracy: 0.9558 - auc: 0.9899Epoch 6/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1268 - accuracy: 0.9559 - auc: 0.9899\n",
      "448/522 [========================>.....] - ETA: 0s - loss: 0.1303 - accuracy: 0.9535 - auc: 0.9893Epoch 6/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1273 - accuracy: 0.9549 - auc: 0.9897\n",
      "484/522 [==========================>...] - ETA: 0s - loss: 0.1302 - accuracy: 0.9533 - auc: 0.9893Epoch 6/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1311 - accuracy: 0.9531 - auc: 0.9891\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1285 - accuracy: 0.9559 - auc: 0.9894\n",
      "Epoch 6/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1057 - accuracy: 0.9654 - auc: 0.9931\n",
      "486/522 [==========================>...] - ETA: 0s - loss: 0.1096 - accuracy: 0.9636 - auc: 0.9926Epoch 7/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1087 - accuracy: 0.9640 - auc: 0.9927\n",
      "Epoch 7/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 0.1092 - accuracy: 0.9627 - auc: 0.9925\n",
      "Epoch 7/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 0.1108 - accuracy: 0.9627 - auc: 0.9921\n",
      "Epoch 7/100\n",
      "122/522 [======>.......................] - ETA: 1s - loss: 0.0881 - accuracy: 0.9754 - auc: 0.9958Epoch 6/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0908 - accuracy: 0.9709 - auc: 0.9951\n",
      "Epoch 8/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0936 - accuracy: 0.9700 - auc: 0.9948\n",
      "388/522 [=====================>........] - ETA: 0s - loss: 0.0951 - accuracy: 0.9701 - auc: 0.9945Epoch 8/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0939 - accuracy: 0.9705 - auc: 0.9946\n",
      "Epoch 8/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0961 - accuracy: 0.9691 - auc: 0.9941\n",
      "Epoch 8/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.1134 - accuracy: 0.9603 - auc: 0.9920\n",
      "300/522 [================>.............] - ETA: 0s - loss: 0.0761 - accuracy: 0.9769 - auc: 0.9971Epoch 7/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0777 - accuracy: 0.9764 - auc: 0.9967\n",
      "470/522 [==========================>...] - ETA: 0s - loss: 0.0795 - accuracy: 0.9756 - auc: 0.9966Epoch 9/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0807 - accuracy: 0.9750 - auc: 0.9963\n",
      "502/522 [===========================>..] - ETA: 0s - loss: 0.0810 - accuracy: 0.9762 - auc: 0.9961Epoch 9/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0811 - accuracy: 0.9760 - auc: 0.9961\n",
      "406/522 [======================>.......] - ETA: 0s - loss: 0.0840 - accuracy: 0.9743 - auc: 0.9954Epoch 9/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0833 - accuracy: 0.9746 - auc: 0.9957\n",
      "104/522 [====>.........................] - ETA: 1s - loss: 0.0726 - accuracy: 0.9802 - auc: 0.9972Epoch 9/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0986 - accuracy: 0.9666 - auc: 0.9941\n",
      "Epoch 8/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0668 - accuracy: 0.9804 - auc: 0.9976\n",
      "207/522 [==========>...................] - ETA: 1s - loss: 0.0860 - accuracy: 0.9722 - auc: 0.9957Epoch 10/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0695 - accuracy: 0.9802 - auc: 0.9973\n",
      " 45/522 [=>............................] - ETA: 1s - loss: 0.0480 - accuracy: 0.9889 - auc: 0.9992Epoch 10/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0699 - accuracy: 0.9796 - auc: 0.9971\n",
      "Epoch 10/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0720 - accuracy: 0.9793 - auc: 0.9967\n",
      "Epoch 10/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0856 - accuracy: 0.9714 - auc: 0.9956\n",
      "255/522 [=============>................] - ETA: 1s - loss: 0.0572 - accuracy: 0.9864 - auc: 0.9983Epoch 9/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0572 - accuracy: 0.9851 - auc: 0.9984\n",
      "203/522 [==========>...................] - ETA: 1s - loss: 0.0696 - accuracy: 0.9786 - auc: 0.9975Epoch 11/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0598 - accuracy: 0.9844 - auc: 0.9982\n",
      "503/522 [===========================>..] - ETA: 0s - loss: 0.0602 - accuracy: 0.9844 - auc: 0.9980Epoch 11/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0602 - accuracy: 0.9842 - auc: 0.9980\n",
      " 74/522 [===>..........................] - ETA: 1s - loss: 0.0474 - accuracy: 0.9890 - auc: 0.9992Epoch 11/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0622 - accuracy: 0.9830 - auc: 0.9975\n",
      "Epoch 11/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0741 - accuracy: 0.9769 - auc: 0.9968\n",
      "Epoch 10/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0487 - accuracy: 0.9887 - auc: 0.9989\n",
      "Epoch 12/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0513 - accuracy: 0.9880 - auc: 0.9987\n",
      "Epoch 12/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0517 - accuracy: 0.9875 - auc: 0.9985\n",
      "Epoch 12/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0538 - accuracy: 0.9874 - auc: 0.9982\n",
      "Epoch 12/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0642 - accuracy: 0.9813 - auc: 0.9978\n",
      "Epoch 11/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0414 - accuracy: 0.9920 - auc: 0.9992\n",
      "Epoch 13/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0440 - accuracy: 0.9907 - auc: 0.9992\n",
      "506/522 [============================>.] - ETA: 0s - loss: 0.0447 - accuracy: 0.9897 - auc: 0.9989Epoch 13/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0444 - accuracy: 0.9897 - auc: 0.9989\n",
      "Epoch 13/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0463 - accuracy: 0.9896 - auc: 0.9986\n",
      "Epoch 13/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0556 - accuracy: 0.9849 - auc: 0.9985\n",
      "Epoch 12/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0350 - accuracy: 0.9938 - auc: 0.9995\n",
      "301/522 [================>.............] - ETA: 0s - loss: 0.0364 - accuracy: 0.9938 - auc: 0.9994Epoch 14/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0375 - accuracy: 0.9929 - auc: 0.9994\n",
      "Epoch 14/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0380 - accuracy: 0.9926 - auc: 0.9992\n",
      "  1/522 [..............................] - ETA: 31s - loss: 0.0265 - accuracy: 1.0000 - auc: 1.0000Epoch 14/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0398 - accuracy: 0.9920 - auc: 0.9989\n",
      "Epoch 14/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0478 - accuracy: 0.9881 - auc: 0.9989\n",
      "Epoch 13/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0294 - accuracy: 0.9953 - auc: 0.9997\n",
      "Epoch 15/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0318 - accuracy: 0.9944 - auc: 0.9997\n",
      "277/522 [==============>...............] - ETA: 0s - loss: 0.0409 - accuracy: 0.9909 - auc: 0.9993Epoch 15/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0325 - accuracy: 0.9940 - auc: 0.9994\n",
      "Epoch 15/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0340 - accuracy: 0.9938 - auc: 0.9992\n",
      "432/522 [=======================>......] - ETA: 0s - loss: 0.0411 - accuracy: 0.9908 - auc: 0.9993Epoch 15/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0411 - accuracy: 0.9906 - auc: 0.9993\n",
      "Epoch 14/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0246 - accuracy: 0.9968 - auc: 0.9998\n",
      "Epoch 16/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0268 - accuracy: 0.9954 - auc: 0.9998\n",
      "Epoch 16/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0275 - accuracy: 0.9958 - auc: 0.9995\n",
      "Epoch 16/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0290 - accuracy: 0.9953 - auc: 0.9994\n",
      "Epoch 16/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0351 - accuracy: 0.9934 - auc: 0.9996\n",
      "Epoch 15/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0204 - accuracy: 0.9974 - auc: 0.9999\n",
      "Epoch 17/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0225 - accuracy: 0.9966 - auc: 0.9999\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0234 - accuracy: 0.9965 - auc: 0.9997\n",
      "Epoch 17/100\n",
      "406/522 [======================>.......] - ETA: 0s - loss: 0.0286 - accuracy: 0.9955 - auc: 0.9998Epoch 17/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0246 - accuracy: 0.9965 - auc: 0.9996\n",
      "233/522 [============>.................] - ETA: 1s - loss: 0.0155 - accuracy: 0.9987 - auc: 0.9999Epoch 17/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0298 - accuracy: 0.9949 - auc: 0.9997\n",
      "Epoch 16/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0168 - accuracy: 0.9983 - auc: 0.9999\n",
      "199/522 [==========>...................] - ETA: 1s - loss: 0.0243 - accuracy: 0.9973 - auc: 0.9999Epoch 18/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0197 - accuracy: 0.9973 - auc: 0.9998\n",
      "Epoch 18/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0187 - accuracy: 0.9973 - auc: 0.9999\n",
      "396/522 [=====================>........] - ETA: 0s - loss: 0.0252 - accuracy: 0.9965 - auc: 0.9999Epoch 18/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0209 - accuracy: 0.9974 - auc: 0.9996\n",
      "Epoch 18/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0253 - accuracy: 0.9963 - auc: 0.9998\n",
      "184/522 [=========>....................] - ETA: 1s - loss: 0.0150 - accuracy: 0.9988 - auc: 0.9996Epoch 17/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0138 - accuracy: 0.9989 - auc: 1.0000\n",
      "Epoch 19/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0165 - accuracy: 0.9981 - auc: 0.9999\n",
      "Epoch 19/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0154 - accuracy: 0.9984 - auc: 1.0000\n",
      "Epoch 19/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0175 - accuracy: 0.9978 - auc: 0.9997\n",
      "Epoch 19/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0212 - accuracy: 0.9972 - auc: 0.9999\n",
      "180/522 [=========>....................] - ETA: 1s - loss: 0.0130 - accuracy: 0.9990 - auc: 0.9999Epoch 18/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0112 - accuracy: 0.9992 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0139 - accuracy: 0.9987 - auc: 0.9999\n",
      "Epoch 20/100\n",
      "434/522 [=======================>......] - ETA: 0s - loss: 0.0122 - accuracy: 0.9988 - auc: 1.0000Epoch 20/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0128 - accuracy: 0.9987 - auc: 1.0000\n",
      " 89/522 [====>.........................] - ETA: 1s - loss: 0.0107 - accuracy: 0.9996 - auc: 0.9999Epoch 20/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0148 - accuracy: 0.9983 - auc: 0.9998\n",
      "Epoch 20/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0177 - accuracy: 0.9980 - auc: 1.0000\n",
      "Epoch 19/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0090 - accuracy: 0.9993 - auc: 1.0000\n",
      "Epoch 21/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0116 - accuracy: 0.9991 - auc: 0.9999\n",
      "Epoch 21/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0105 - accuracy: 0.9991 - auc: 1.0000\n",
      " 98/522 [====>.........................] - ETA: 1s - loss: 0.0066 - accuracy: 0.9997 - auc: 1.0000Epoch 21/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9989 - auc: 0.9998\n",
      "Epoch 21/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0147 - accuracy: 0.9987 - auc: 1.0000\n",
      "Epoch 20/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0074 - accuracy: 0.9994 - auc: 1.0000\n",
      "Epoch 22/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0096 - accuracy: 0.9993 - auc: 1.0000\n",
      "380/522 [====================>.........] - ETA: 0s - loss: 0.0104 - accuracy: 0.9989 - auc: 0.9999Epoch 22/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0087 - accuracy: 0.9993 - auc: 1.0000.........] - ETA: 2s - loss: 0.0056 - accuracy: 1.0000 - auc: 1.00\n",
      "Epoch 22/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0103 - accuracy: 0.9990 - auc: 0.9999\n",
      "Epoch 22/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0121 - accuracy: 0.9990 - auc: 1.0000\n",
      "214/522 [===========>..................] - ETA: 1s - loss: 0.0068 - accuracy: 0.9996 - auc: 1.0000Epoch 21/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0059 - accuracy: 0.9994 - auc: 1.0000\n",
      "184/522 [=========>....................] - ETA: 1s - loss: 0.0087 - accuracy: 0.9992 - auc: 1.0000Epoch 23/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0079 - accuracy: 0.9992 - auc: 1.0000\n",
      "  1/522 [..............................] - ETA: 33s - loss: 0.0026 - accuracy: 1.0000 - auc: 1.0000Epoch 23/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0071 - accuracy: 0.9993 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0085 - accuracy: 0.9992 - auc: 0.9999\n",
      "Epoch 23/100\n",
      "202/522 [==========>...................] - ETA: 1s - loss: 0.0062 - accuracy: 0.9995 - auc: 1.0000Epoch 23/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0101 - accuracy: 0.9991 - auc: 1.0000\n",
      "164/522 [========>.....................] - ETA: 1s - loss: 0.0058 - accuracy: 0.9996 - auc: 1.0000Epoch 22/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - auc: 1.0000\n",
      "505/522 [============================>.] - ETA: 0s - loss: 0.0064 - accuracy: 0.9994 - auc: 1.0000Epoch 24/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0065 - accuracy: 0.9994 - auc: 1.0000\n",
      "503/522 [===========================>..] - ETA: 0s - loss: 0.0069 - accuracy: 0.9994 - auc: 1.0000Epoch 24/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0071 - accuracy: 0.9993 - auc: 1.0000\n",
      "Epoch 24/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.9993 - auc: 1.0000\n",
      " 77/522 [===>..........................] - ETA: 1s - loss: 0.0066 - accuracy: 0.9992 - auc: 1.0000Epoch 24/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0082 - accuracy: 0.9994 - auc: 1.0000\n",
      "211/522 [===========>..................] - ETA: 1s - loss: 0.0057 - accuracy: 0.9994 - auc: 1.0000Epoch 23/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0039 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 25/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0053 - accuracy: 0.9995 - auc: 1.0000===>........] - ETA: 0s - loss: 0.0060 - accuracy: 0.9993 - auc: 1.003 - auc: 1.00\n",
      "Epoch 25/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0058 - accuracy: 0.9993 - auc: 1.0000\n",
      "Epoch 25/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - auc: 1.0000\n",
      "404/522 [======================>.......] - ETA: 0s - loss: 0.0067 - accuracy: 0.9995 - auc: 1.0000Epoch 25/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0068 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 24/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 26/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0044 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 26/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0048 - accuracy: 0.9995 - auc: 1.0000 0.0028 - accuracy: 1.0000 - auc: 1.000\n",
      "484/522 [==========================>...] - ETA: 0s - loss: 0.0039 - accuracy: 0.9995 - auc: 1.0000Epoch 26/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0040 - accuracy: 0.9995 - auc: 1.0000\n",
      "213/522 [===========>..................] - ETA: 1s - loss: 0.0024 - accuracy: 0.9997 - auc: 1.0000Epoch 26/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.0056 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 25/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.0026 - accuracy: 0.9995 - auc: 1.0000\n",
      "174/522 [=========>....................] - ETA: 2s - loss: 0.0044 - accuracy: 0.9996 - auc: 1.0000Epoch 27/100\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.0036 - accuracy: 0.9995 - auc: 1.0000================>.........] - ETA: 0s - loss: 0.0031 - accuracy: 0.9996 - auc: 1.00ccuracy: 0.9996 - auc: 1.00\n",
      "Epoch 27/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.0033 - accuracy: 0.9995 - auc: 1.0000\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.0039 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 27/100\n",
      "Epoch 27/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.0045 - accuracy: 0.9996 - auc: 1.0000==>....................] - ETA: 1s - loss: 0.0027 - accuracy: 0.9995 - auc: 1.00\n",
      "Epoch 26/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0022 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 28/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0030 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 28/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0032 - accuracy: 0.9995 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0027 - accuracy: 0.9994 - auc: 1.0000\n",
      "Epoch 28/100\n",
      "185/522 [=========>....................] - ETA: 1s - loss: 0.0017 - accuracy: 0.9995 - auc: 1.0000Epoch 28/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0038 - accuracy: 0.9996 - auc: 1.0000\n",
      "154/522 [=======>......................] - ETA: 1s - loss: 0.0033 - accuracy: 0.9992 - auc: 1.0000Epoch 27/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - auc: 1.0000\n",
      "168/522 [========>.....................] - ETA: 1s - loss: 0.0033 - accuracy: 0.9996 - auc: 1.0000Epoch 29/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0024 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 29/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0023 - accuracy: 0.9995 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 29/100\n",
      "Epoch 29/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0031 - accuracy: 0.9996 - auc: 1.0000\n",
      "154/522 [=======>......................] - ETA: 1s - loss: 0.0017 - accuracy: 1.0000 - auc: 1.0000Epoch 28/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 30/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 30/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0020 - accuracy: 0.9998 - auc: 1.0000\n",
      "360/522 [===================>..........] - ETA: 0s - loss: 0.0024 - accuracy: 0.9998 - auc: 1.0000Epoch 30/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0021 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 30/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0026 - accuracy: 0.9997 - auc: 1.0000\n",
      "152/522 [=======>......................] - ETA: 1s - loss: 0.0012 - accuracy: 1.0000 - auc: 1.0000Epoch 29/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9997 - auc: 1.0000\n",
      "Epoch 31/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0017 - accuracy: 0.9995 - auc: 1.0000\n",
      "474/522 [==========================>...] - ETA: 0s - loss: 0.0016 - accuracy: 0.9997 - auc: 1.0000Epoch 31/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9997 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9995 - auc: 1.0000\n",
      " 42/522 [=>............................] - ETA: 1s - loss: 0.0021 - accuracy: 0.9985 - auc: 1.0000Epoch 31/100\n",
      "440/522 [========================>.....] - ETA: 0s - loss: 0.0022 - accuracy: 0.9996 - auc: 1.000000Epoch 31/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0022 - accuracy: 0.9996 - auc: 1.0000\n",
      "307/522 [================>.............] - ETA: 0s - loss: 0.0013 - accuracy: 0.9996 - auc: 1.0000Epoch 30/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 32/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 32/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0015 - accuracy: 0.9995 - auc: 1.0000\n",
      " 49/522 [=>............................] - ETA: 2s - loss: 0.0011 - accuracy: 0.9994 - auc: 1.0000Epoch 32/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0014 - accuracy: 0.9999 - auc: 1.0000\n",
      "353/522 [===================>..........] - ETA: 0s - loss: 0.0017 - accuracy: 0.9998 - auc: 1.0000Epoch 32/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0018 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 31/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 8.9773e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 33/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0012 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 33/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0012 - accuracy: 0.9995 - auc: 1.0000\n",
      "275/522 [==============>...............] - ETA: 1s - loss: 0.0014 - accuracy: 0.9998 - auc: 1.0000Epoch 33/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0013 - accuracy: 0.9998 - auc: 1.0000\n",
      " 79/522 [===>..........................] - ETA: 1s - loss: 8.5649e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 33/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0016 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 32/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 7.8073e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 0.0011 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9995 - auc: 1.0000\n",
      " 64/522 [==>...........................] - ETA: 1s - loss: 4.5678e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 34/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0011 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0013 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 33/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 6.8072e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "314/522 [=================>............] - ETA: 0s - loss: 9.8843e-04 - accuracy: 0.9993 - auc: 1.0000Epoch 35/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9995 - auc: 1.0000\n",
      "362/522 [===================>..........] - ETA: 0s - loss: 0.0011 - accuracy: 0.9997 - auc: 1.0000Epoch 35/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 8.7241e-04 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 35/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 9.8693e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "363/522 [===================>..........] - ETA: 0s - loss: 0.0012 - accuracy: 0.9997 - auc: 1.0000Epoch 35/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.0011 - accuracy: 0.9997 - auc: 1.0000\n",
      "Epoch 34/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 5.9901e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 36/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 8.5960e-04 - accuracy: 0.9996 - auc: 1.0000\n",
      "118/522 [=====>........................] - ETA: 1s - loss: 5.0908e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 36/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 7.5523e-04 - accuracy: 0.9995 - auc: 1.0000\n",
      "Epoch 36/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 8.7424e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "376/522 [====================>.........] - ETA: 0s - loss: 8.8934e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 36/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 0.0010 - accuracy: 0.9999 - auc: 1.0000\n",
      "307/522 [================>.............] - ETA: 0s - loss: 6.8112e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 35/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 5.3403e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "320/522 [=================>............] - ETA: 0s - loss: 6.1471e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 37/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 7.7878e-04 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 37/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 6.5726e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "459/522 [=========================>....] - ETA: 0s - loss: 8.9278e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 37/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 8.4412e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 37/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 8.9294e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 36/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.8062e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "397/522 [=====================>........] - ETA: 0s - loss: 7.8307e-04 - accuracy: 0.9995 - auc: 1.0000Epoch 38/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 7.1883e-04 - accuracy: 0.9996 - auc: 1.0000\n",
      "Epoch 38/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.8259e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "297/522 [================>.............] - ETA: 0s - loss: 5.4692e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 38/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 7.4351e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "165/522 [========>.....................] - ETA: 1s - loss: 6.7426e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 38/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 8.5092e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "213/522 [===========>..................] - ETA: 1s - loss: 4.5826e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 37/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.3984e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 71/522 [===>..........................] - ETA: 1s - loss: 3.4313e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 39/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.6299e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 39/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.2036e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 39/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.7625e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 66/522 [==>...........................] - ETA: 1s - loss: 7.1136e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 39/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 7.2719e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "206/522 [==========>...................] - ETA: 1s - loss: 5.1641e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 38/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0573e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 40/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.9741e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "419/522 [=======================>......] - ETA: 0s - loss: 5.4837e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 40/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.6843e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "451/522 [========================>.....] - ETA: 0s - loss: 6.6705e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 40/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.4256e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "178/522 [=========>....................] - ETA: 1s - loss: 4.4513e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 40/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.5713e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 39/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.7585e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 67/522 [==>...........................] - ETA: 1s - loss: 2.5869e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 41/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.8323e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.2509e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.9845e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.6253e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 40/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5751e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "273/522 [==============>...............] - ETA: 1s - loss: 4.7039e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 42/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.3704e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.8577e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.7538e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.3512e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 41/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.3466e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "263/522 [==============>...............] - ETA: 1s - loss: 5.7340e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 43/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.7484e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 43/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5382e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "466/522 [=========================>....] - ETA: 0s - loss: 5.4543e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 43/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.0264e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "380/522 [====================>.........] - ETA: 0s - loss: 5.0659e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 43/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.4281e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 42/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.1979e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "381/522 [====================>.........] - ETA: 0s - loss: 4.8077e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 44/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.7299e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "390/522 [=====================>........] - ETA: 0s - loss: 2.9709e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 44/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2513e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 44/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.3788e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 44/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.0811e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "332/522 [==================>...........] - ETA: 0s - loss: 2.1034e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 43/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.0447e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "383/522 [=====================>........] - ETA: 0s - loss: 2.4412e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 45/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.5633e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "397/522 [=====================>........] - ETA: 0s - loss: 3.0710e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 45/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.0096e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "310/522 [================>.............] - ETA: 0s - loss: 6.4584e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 45/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.6695e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 38/522 [=>............................] - ETA: 2s - loss: 3.2812e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 45/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 5.5911e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "483/522 [==========================>...] - ETA: 0s - loss: 3.1322e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 44/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 2.9219e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "380/522 [====================>.........] - ETA: 0s - loss: 4.8829e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 46/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.5981e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 46/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.8116e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "111/522 [=====>........................] - ETA: 1s - loss: 9.3520e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 46/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.9327e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 43/522 [=>............................] - ETA: 1s - loss: 2.1826e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 46/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 5.2774e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "224/522 [===========>..................] - ETA: 1s - loss: 8.7251e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 45/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.8386e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 47/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.7395e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "405/522 [======================>.......] - ETA: 0s - loss: 2.6114e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 47/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.6032e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "124/522 [======>.......................] - ETA: 1s - loss: 1.9946e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 47/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.6389e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 47/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 4.5038e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "496/522 [===========================>..] - ETA: 0s - loss: 2.1775e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 46/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.7616e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 48/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.6581e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 48/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.4604e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.5713e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 48/100\n",
      " 13/522 [..............................] - ETA: 2s - loss: 4.1142e-05 - accuracy: 1.0000 - auc: 1.0000 Epoch 48/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5067e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 47/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.6810e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 49/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0327e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 49/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5807e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 49/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.2803e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 49/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.1533e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "500/522 [===========================>..] - ETA: 0s - loss: 2.4701e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 48/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.5949e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 50/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5112e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 50/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.1471e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 50/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.1397e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "  1/522 [..............................] - ETA: 36s - loss: 5.9900e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 50/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.7005e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "508/522 [============================>.] - ETA: 0s - loss: 2.6109e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 49/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.5457e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 51/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.9538e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "330/522 [=================>............] - ETA: 0s - loss: 2.2505e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 51/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.2104e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 51/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0131e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 51/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5982e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.5262e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "171/522 [========>.....................] - ETA: 1s - loss: 5.2540e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 52/100\n",
      "447/522 [========================>.....] - ETA: 0s - loss: 1.9736e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 50/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.7949e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 79/522 [===>..........................] - ETA: 1s - loss: 8.2363e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 52/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.7562e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 52/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9010e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 52/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.5283e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "170/522 [========>.....................] - ETA: 1s - loss: 4.9581e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 53/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.7581e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 51/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.8456e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 53/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1545e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 53/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.7874e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 53/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.4190e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 54/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1818e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "231/522 [============>.................] - ETA: 1s - loss: 3.2401e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 52/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6856e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 54/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1793e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "349/522 [===================>..........] - ETA: 0s - loss: 3.2269e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 54/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.6880e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 54/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.3655e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "360/522 [===================>..........] - ETA: 0s - loss: 2.0665e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 55/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.8403e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 53/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6631e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "332/522 [==================>...........] - ETA: 0s - loss: 4.9021e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 55/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.9917e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 55/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.5905e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 55/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.3427e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "346/522 [==================>...........] - ETA: 0s - loss: 4.4945e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 56/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.7652e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 54/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6162e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 56/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1985e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "283/522 [===============>..............] - ETA: 0s - loss: 4.6684e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 56/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.4994e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 56/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.3047e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "155/522 [=======>......................] - ETA: 1s - loss: 1.0245e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 57/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.6053e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "203/522 [==========>...................] - ETA: 1s - loss: 1.2388e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 55/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1978e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 96/522 [====>.........................] - ETA: 1s - loss: 4.2616e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 57/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.9158e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.4239e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 57/100\n",
      "446/522 [========================>.....] - ETA: 0s - loss: 2.6567e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 57/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.2761e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 58/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6971e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 56/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0884e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 58/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.3390e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "213/522 [===========>..................] - ETA: 1s - loss: 4.5600e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 58/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0163e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 58/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.2503e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "344/522 [==================>...........] - ETA: 0s - loss: 3.2758e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 59/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6458e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "156/522 [=======>......................] - ETA: 1s - loss: 8.9647e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 57/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1721e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 59/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.2638e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 59/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.7046e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "362/522 [===================>..........] - ETA: 0s - loss: 5.8480e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 59/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.2322e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 60/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.4582e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 58/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.8932e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 60/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.1944e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "310/522 [================>.............] - ETA: 0s - loss: 2.3392e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 60/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.8023e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 60/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.2210e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "437/522 [========================>.....] - ETA: 0s - loss: 4.2104e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 61/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5729e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "160/522 [========>.....................] - ETA: 1s - loss: 3.3724e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 59/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2281e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 61/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.1293e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "394/522 [=====================>........] - ETA: 0s - loss: 2.2387e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 61/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.9408e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 61/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.1858e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 62/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6049e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 60/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.9541e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 62/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.0724e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.6864e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 62/100\n",
      "278/522 [==============>...............] - ETA: 1s - loss: 3.9249e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 62/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.1762e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 63/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.3442e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 61/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.0472e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 63/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.5630e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "446/522 [========================>.....] - ETA: 0s - loss: 2.5155e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 63/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 1.0101e-04 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 63/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.1531e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 64/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.4955e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "434/522 [=======================>......] - ETA: 0s - loss: 3.3996e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 62/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.0808e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 64/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.7948e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 64/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 9.5504e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "283/522 [===============>..............] - ETA: 1s - loss: 1.3033e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 64/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.1323e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 65/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.4020e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 63/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 4.0713e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "260/522 [=============>................] - ETA: 1s - loss: 2.0306e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 65/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.7228e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "345/522 [==================>...........] - ETA: 0s - loss: 1.5920e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 65/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 9.0241e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "281/522 [===============>..............] - ETA: 0s - loss: 4.9305e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 65/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.1178e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "423/522 [=======================>......] - ETA: 0s - loss: 2.3997e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 66/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.4904e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "172/522 [========>.....................] - ETA: 1s - loss: 5.1272e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 64/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.9870e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 66/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 4.6000e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "499/522 [===========================>..] - ETA: 0s - loss: 7.9560e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 66/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 8.5367e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 66/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 2.1019e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "416/522 [======================>.......] - ETA: 0s - loss: 3.2110e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 67/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.9696e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "179/522 [=========>....................] - ETA: 1s - loss: 2.8224e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 65/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.7059e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 67/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.0180e-04 - accuracy: 0.9998 - auc: 1.0000 2.0471e-04 - accuracy: 0.9999 - auc: 1.\n",
      "449/522 [========================>.....] - ETA: 0s - loss: 2.2584e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 67/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 8.1534e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "  1/522 [..............................] - ETA: 36s - loss: 4.0611e-06 - accuracy: 1.0000 - auc: 1.0000Epoch 67/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 2.0894e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 39/522 [=>............................] - ETA: 1s - loss: 3.7421e-07 - accuracy: 1.0000 - auc: 1.0000Epoch 68/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.4872e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "446/522 [========================>.....] - ETA: 0s - loss: 2.2337e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 66/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.5754e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "238/522 [============>.................] - ETA: 1s - loss: 7.5553e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 68/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.3820e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "453/522 [=========================>....] - ETA: 0s - loss: 2.2290e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 68/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 7.6379e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "479/522 [==========================>...] - ETA: 0s - loss: 2.2614e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 68/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0781e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "410/522 [======================>.......] - ETA: 0s - loss: 3.6422e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 69/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.4350e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "107/522 [=====>........................] - ETA: 1s - loss: 1.3658e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 67/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8868e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 69/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5598e-04 - accuracy: 0.9999 - auc: 1.0000 1.0699e-04 - accuracy: 1.0000 - auc: 1.\n",
      "Epoch 69/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 7.2452e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 69/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0652e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 70/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.4460e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "154/522 [=======>......................] - ETA: 1s - loss: 7.8533e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 68/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8176e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 68/522 [==>...........................] - ETA: 2s - loss: 4.7491e-04 - accuracy: 0.9995 - auc: 1.0000Epoch 70/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6193e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 70/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.8367e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "365/522 [===================>..........] - ETA: 0s - loss: 5.2995e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 70/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0544e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 71/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0070e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 69/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5756e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 71/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6182e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 71/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.4532e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "276/522 [==============>...............] - ETA: 1s - loss: 7.4805e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 71/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0430e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 72/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.3146e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 70/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8447e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "202/522 [==========>...................] - ETA: 1s - loss: 3.5393e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 72/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5127e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 72/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 6.0871e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 72/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0376e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 73/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.0927e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "168/522 [========>.....................] - ETA: 1s - loss: 4.0862e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 71/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8063e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "235/522 [============>.................] - ETA: 1s - loss: 7.1743e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 73/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5780e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "350/522 [===================>..........] - ETA: 0s - loss: 3.7671e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 73/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.7522e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0261e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 74/100\n",
      "393/522 [=====================>........] - ETA: 0s - loss: 3.5147e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 73/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.3383e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 72/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8370e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 74/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.2592e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "406/522 [======================>.......] - ETA: 0s - loss: 3.9309e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 74/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0261e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 75/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.4697e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 74/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.2755e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 73/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.6094e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "126/522 [======>.......................] - ETA: 1s - loss: 4.8161e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 75/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.6238e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "273/522 [==============>...............] - ETA: 0s - loss: 4.2043e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 75/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0085e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "404/522 [======================>.......] - ETA: 0s - loss: 4.5668e-04 - accuracy: 0.9998 - auc: 1.0000Epoch 76/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 5.1251e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 75/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5547e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "154/522 [=======>......................] - ETA: 1s - loss: 8.0083e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 74/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.7155e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 80/522 [===>..........................] - ETA: 1s - loss: 9.3829e-04 - accuracy: 0.9996 - auc: 1.0000Epoch 76/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.3759e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 76/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.0048e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 77/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.8384e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      " 96/522 [====>.........................] - ETA: 1s - loss: 8.1606e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 76/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5035e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 75/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.5948e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 77/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.3394e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 77/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9941e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "300/522 [================>.............] - ETA: 0s - loss: 1.3720e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 78/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.5654e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 77/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.3057e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 76/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 2.5919e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 78/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.2810e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "496/522 [===========================>..] - ETA: 0s - loss: 1.9651e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 78/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 1.9889e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 79/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.3107e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      " 77/522 [===>..........................] - ETA: 2s - loss: 9.2346e-08 - accuracy: 1.0000 - auc: 1.0000Epoch 78/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 2.8869e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 77/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.7053e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 79/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.5541e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 79/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 1.9821e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "431/522 [=======================>......] - ETA: 0s - loss: 4.3940e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 80/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.0735e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 79/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.2739e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 78/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.1788e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "219/522 [===========>..................] - ETA: 1s - loss: 8.3232e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 80/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 4.3416e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "499/522 [===========================>..] - ETA: 0s - loss: 1.9456e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 80/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 1.9780e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "293/522 [===============>..............] - ETA: 1s - loss: 1.0689e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 81/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.8370e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 80/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.3847e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 79/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.1276e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 81/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.5715e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "271/522 [==============>...............] - ETA: 1s - loss: 3.2042e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 81/100\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 1.9710e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 82/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.6185e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      " 96/522 [====>.........................] - ETA: 1s - loss: 6.9726e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 81/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.3658e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 80/100\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 3.0364e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "221/522 [===========>..................] - ETA: 1s - loss: 3.5688e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 82/100\n",
      "386/522 [=====================>........] - ETA: 0s - loss: 4.1191e-05 - accuracy: 1.0000 - auc: 1.0000Restoring model weights from the end of the best epoch: 71.\n",
      "522/522 [==============================] - 2s 5ms/step - loss: 3.5267e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 81: early stopping\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9661e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 83/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.4209e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 82/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.1740e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "150/522 [=======>......................] - ETA: 1s - loss: 7.7900e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 81/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.4697e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      " 57/522 [==>...........................] - ETA: 1s - loss: 3.7882e-06 - accuracy: 1.0000 - auc: 1.0000Epoch 83/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9608e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 84/100\n",
      "131/131 [==============================] - 1s 3ms/steposs: 2.4248e-04 - accuracy: 1.0000 - auc: 1.00\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2367e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 83/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2643e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 82/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.4803e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "105/522 [=====>........................] - ETA: 1s - loss: 1.7297e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 84/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9581e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 85/100\n",
      "131/131 [==============================] - 0s 3ms/steposs: 2.0216e-04 - accuracy: 1.0000 - auc: 1.00\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.0511e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "479/522 [==========================>...] - ETA: 0s - loss: 3.5561e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 84/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2715e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 83/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 3.2548e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 85/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9523e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 86/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.8778e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 85/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 4.2610e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "449/522 [========================>.....] - ETA: 0s - loss: 2.8552e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 84/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.4640e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "245/522 [=============>................] - ETA: 0s - loss: 4.7212e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 86/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9483e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "102/522 [====>.........................] - ETA: 1s - loss: 6.9060e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 87/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.7202e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "228/522 [============>.................] - ETA: 0s - loss: 6.2096e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 86/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.8385e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      " 33/522 [>.............................] - ETA: 1s - loss: 4.6166e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 85/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.2739e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 87/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9439e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 88/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.5673e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.8186e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 86/100\n",
      "182/522 [=========>....................] - ETA: 0s - loss: 6.2315e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 87/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.0608e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "412/522 [======================>.......] - ETA: 0s - loss: 2.1917e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 88/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9476e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 89/100\n",
      "350/522 [===================>..........] - ETA: 0s - loss: 2.0332e-05 - accuracy: 1.0000 - auc: 1.0000Restoring model weights from the end of the best epoch: 76.\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.8001e-04 - accuracy: 0.9998 - auc: 1.0000\n",
      "Epoch 86: early stopping\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.4240e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 88/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.2798e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 89/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9399e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "159/522 [========>.....................] - ETA: 1s - loss: 8.5757e-06 - accuracy: 1.0000 - auc: 1.0000Epoch 90/100\n",
      "131/131 [==============================] - 0s 2ms/steposs: 4.5800e-04 - accuracy: 0.9998 - auc: 1.00\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.2824e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 89/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.1149e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 90/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9353e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "104/522 [====>.........................] - ETA: 1s - loss: 1.8397e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 91/100\n",
      "131/131 [==============================] - 0s 2ms/steposs: 7.8114e-06 - accuracy: 1.0000 - auc: 1.00\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.1464e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "349/522 [===================>..........] - ETA: 0s - loss: 1.0549e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 90/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.3699e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 91/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9342e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "110/522 [=====>........................] - ETA: 1s - loss: 5.9505e-04 - accuracy: 0.9997 - auc: 1.0000Epoch 92/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.0235e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 91/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.1749e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 92/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9307e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 93/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9113e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 92/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.3956e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "395/522 [=====================>........] - ETA: 0s - loss: 7.8387e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 93/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9292e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 94/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.8042e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.2915e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "395/522 [=====================>........] - ETA: 0s - loss: 2.2804e-04 - accuracy: 0.9999 - auc: 1.0000Epoch 94/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9246e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 95/100\n",
      "187/522 [=========>....................] - ETA: 0s - loss: 1.0861e-04 - accuracy: 1.0000 - auc: 1.0000Epoch 93/100\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 2.8890e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 95/100\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 1.9245e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "112/522 [=====>........................] - ETA: 1s - loss: 5.2709e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 96/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.7004e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 94/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.2920e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 96/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9197e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "310/522 [================>.............] - ETA: 0s - loss: 2.1062e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 97/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.6009e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 95/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 2.3270e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 97/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.9201e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 98/100\n",
      "522/522 [==============================] - 2s 4ms/step - loss: 1.5174e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "200/522 [==========>...................] - ETA: 1s - loss: 9.8803e-05 - accuracy: 1.0000 - auc: 1.0000Epoch 96/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 2.3457e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 98/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9168e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 99/100\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.4253e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 97/100\n",
      "193/522 [==========>...................] - ETA: 0s - loss: 8.2569e-06 - accuracy: 1.0000 - auc: 1.0000Restoring model weights from the end of the best epoch: 88.\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 3.1303e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 98: early stopping\n",
      "522/522 [==============================] - 2s 3ms/step - loss: 1.9153e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "Epoch 100/100\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 1.3414e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 98/100\n",
      "131/131 [==============================] - 0s 2ms/steposs: 2.2155e-04 - accuracy: 0.9999 - auc: 1.00\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 1.9120e-04 - accuracy: 0.9999 - auc: 1.0000\n",
      "522/522 [==============================] - 1s 2ms/step - loss: 1.2639e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 99/100\n",
      "131/131 [==============================] - 0s 1ms/steposs: 1.5050e-05 - accuracy: 1.0000 - auc: 1.000\n",
      "131/131 [==============================] - 0s 2ms/steposs: 1.9947e-05 - accuracy: 1.0000 - auc: 1.00\n",
      "522/522 [==============================] - 1s 3ms/step - loss: 1.1942e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "Epoch 100/100\n",
      "131/131 [==============================] - 0s 1ms/steposs: 3.2742e-08 - accuracy: 1.0000 - auc: 1.00\n",
      "522/522 [==============================] - 1s 2ms/step - loss: 1.1252e-05 - accuracy: 1.0000 - auc: 1.0000\n",
      "131/131 [==============================] - 0s 1ms/step\n",
      "131/131 [==============================] - 0s 1ms/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>ROC AUC</th>\n",
       "      <th>Time (s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple_mlp</th>\n",
       "      <td>0.87</td>\n",
       "      <td>0.9288</td>\n",
       "      <td>216</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Accuracy  ROC AUC  Time (s)\n",
       "simple_mlp      0.87   0.9288       216"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def create_model(input_shape=10000):\n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.InputLayer(input_shape=(input_shape,)),\n",
    "        tf.keras.layers.Dense(10, activation='relu'),\n",
    "        tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=create_model, epochs=100, verbose=1, \n",
    "                        callbacks=CALLBACKS,\n",
    "                        input_shape=10000)\n",
    "\n",
    "pipe = Pipeline([\n",
    "    (\"count\", vectorizer),\n",
    "    ('tf_idf',tf_idf),\n",
    "    ('feature_selection', k_best),\n",
    "    ('simple_mlp', model)\n",
    "])\n",
    "\n",
    "model_cv_scores(pipe, 'simple_mlp', X= X_train_clean, y= y_train, scoring=SCORING, cv=skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb6e85d-a063-481a-a337-6b628c9383ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2692a4ed-ff4e-434e-81af-ab69a2bc715b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(20000,)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=1000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6845a22-d78a-4f54-b78d-dc360ac278c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(20000,)),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=1000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7f1d94-7ab1-4c48-be22-58c6c7a35e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(20000,)),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.4),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy', tf.keras.metrics.AUC()])\n",
    "\n",
    "history = model.fit(train_ds,\n",
    "                    epochs=1000,\n",
    "                    callbacks=callbacks,\n",
    "                    validation_data=val_ds,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6704eb-7350-4fe6-a21e-60469de3d254",
   "metadata": {},
   "source": [
    "### Sequence Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1ed3dd-f25c-4b17-a8f0-b50cc4773101",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32354cc3-46a4-4092-bcd6-1ae693e7733a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f517055-ff28-43ad-a75e-da245ecb8365",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04cda2ba-b9d1-466b-9a5a-133e8a51661a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
