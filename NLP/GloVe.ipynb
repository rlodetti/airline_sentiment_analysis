{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fc2952b9-7354-4b87-8436-59fbada9325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk  # Added this import\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords, wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from gensim.models import word2vec\n",
    "\n",
    "# Ensure stopwords are downloaded only once (not a coding error, but a good practice)\n",
    "nltk.download('stopwords', quiet=True)\n",
    "nltk.download('averaged_perceptron_tagger', quiet=True)\n",
    "nltk.download('wordnet', quiet=True)\n",
    "nltk.download('omw-1.4', quiet=True)\n",
    "\n",
    "STOPWORDS = stopwords.words('english')\n",
    "\n",
    "# Third-party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, cross_validate, train_test_split\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from tensorflow.keras import Sequential, layers\n",
    "\n",
    "\n",
    "sample_size = 5000\n",
    "df = pd.read_csv('../data/Airline_review.csv')[['Review_Title','Review','Recommended']]\n",
    "X = df['Review_Title'] + ' ' + df['Review']\n",
    "y = df['Recommended'].map({'yes':1,'no':0})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "X_train_sampled, _, y_train_sampled, _ = train_test_split(X_train, y_train, test_size=(len(X_train)-sample_size)/len(X_train), stratify=y_train, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4a7d564b-1c80-4cc7-a153-a5565e1e93cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCleanerTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, stop_words=None, lemmatize=True):\n",
    "        self.stop_words = set(stop_words) if stop_words else None\n",
    "        self.lemmatize = lemmatize\n",
    "        self.lemmatizer = WordNetLemmatizer() if lemmatize else None\n",
    "        self.tokenizer = RegexpTokenizer(r\"([a-zA-Z]+(?:â€™[a-z]+)?)\")\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self \n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return [self.clean_text(review) for review in X]\n",
    "    \n",
    "    def clean_text(self, review):\n",
    "        tokens = self.tokenizer.tokenize(review.lower())  # Tokenize and lowercase\n",
    "        if self.lemmatize:\n",
    "            pos_tags = pos_tag(tokens)\n",
    "            tokens = [self.lemmatizer.lemmatize(word, self.get_wordnet_pos(tag))\n",
    "                      for word, tag in pos_tags]\n",
    "        if self.stop_words:\n",
    "            tokens = [word for word in tokens if word not in self.stop_words]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def get_wordnet_pos(self, treebank_tag):\n",
    "        if treebank_tag.startswith('J'):\n",
    "            return wordnet.ADJ\n",
    "        elif treebank_tag.startswith('V'):\n",
    "            return wordnet.VERB\n",
    "        elif treebank_tag.startswith('N'):\n",
    "            return wordnet.NOUN\n",
    "        elif treebank_tag.startswith('R'):\n",
    "            return wordnet.ADV\n",
    "        else:\n",
    "            return wordnet.NOUN\n",
    "\n",
    "def summarize_glv_grid_search_results(grid_search):\n",
    "    columns_to_extract = [\n",
    "        ('mean_fit_time', 'fit_time'),\n",
    "        ('mean_score_time', 'score_time'),\n",
    "        ('param_glv__model__bi_directional', 'bi_directional'),\n",
    "        ('param_glv__model__dense_layers', 'num_dense_layers'),\n",
    "        ('param_glv__model__recurrent_type', 'recurrent_type'),\n",
    "        ('param_glv__model__rnn_layers', 'num_rnn_layers'),\n",
    "        ('param_glv__model__units', 'units'),\n",
    "        ('param_glv__model__dropout_rate', 'dropout_rate'),\n",
    "        ('mean_train_score', 'train_score'),\n",
    "        ('mean_test_score', 'test_score')\n",
    "    ]\n",
    "    summary_df = pd.DataFrame(grid_search.cv_results_)[[original for original, renamed in columns_to_extract]]\n",
    "\n",
    "    summary_df.columns = [renamed for original, renamed in columns_to_extract]\n",
    "    \n",
    "    # Calculate total time and convert to int\n",
    "    summary_df['time'] = (summary_df['fit_time'] + summary_df['score_time']).astype(int)\n",
    "    \n",
    "    # Reorder and select final columns for the output\n",
    "    final_columns = ['train_score', 'test_score', 'time', 'units', 'bi_directional', 'recurrent_type', 'num_rnn_layers', 'num_dense_layers', 'dropout_rate']\n",
    "    final_df = summary_df[final_columns]\n",
    "    sorted_df = final_df.sort_values(by=['test_score', 'time'], ascending=[False, True])\n",
    "    \n",
    "    return sorted_df\n",
    "\n",
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_train)\n",
    "X_train_clean_sampled = text_cleaner.transform(X_train_sampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8ae13b1-1874-4f4e-9570-884addcca520",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6abfba95-6dee-473a-9035-e701cdd44252",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15257"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_train_sampled)\n",
    "X_train_tokenized = [review.split() for review in X_train_clean]\n",
    "train_vocabulary = set(word for review in X_train_tokenized for word in review)\n",
    "len(train_vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb6d4ce0-4d28-44c0-b425-ebe38aff897e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "glove_embeddings = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "vocab = min(15000, len(train_vocabulary) + 1)\n",
    "length = 500\n",
    "embedding_dim = 300\n",
    "\n",
    "# Initialize the embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab, embedding_dim))\n",
    "\n",
    "# Fill in the matrix with GloVe embeddings\n",
    "for i, word in enumerate(train_vocabulary):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Ensure the index i does not exceed the vocab size limitation\n",
    "        if i < vocab:\n",
    "            embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1bcdb5bd-688c-453a-bf35-823c5d34830e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sampled or not?\n",
    "X_input = X_train_clean_sampled\n",
    "y_input = y_train_sampled\n",
    "\n",
    "# finding vocab size\n",
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_input)\n",
    "X_train_tokenized = [review.split() for review in X_train_clean]\n",
    "train_vocabulary = set(word for review in X_train_tokenized for word in review)\n",
    "vocab_size = len(train_vocabulary) + 1\n",
    "\n",
    "#setting important dimensions\n",
    "vocab=min(15000,len(train_vocabulary) + 1)\n",
    "length=500\n",
    "embedding_dim = 300\n",
    "\n",
    "#making embedding matrix\n",
    "glove_embeddings = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "# Initialize the embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab, embedding_dim))\n",
    "\n",
    "# Fill in the matrix with GloVe embeddings\n",
    "for i, word in enumerate(train_vocabulary):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Ensure the index i does not exceed the vocab size limitation\n",
    "        if i < vocab:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4035eaac-c950-457e-8f0a-5ccc17268057",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.503, test=0.503) total time=  36.3s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.610, test=0.616) total time=  35.7s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.715, test=0.671) total time=  40.6s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.730, test=0.685) total time=  52.9s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.606, test=0.588) total time=  58.6s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.627, test=0.608) total time=  55.8s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.716, test=0.660) total time= 1.2min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.748, test=0.692) total time= 1.2min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.511, test=0.506) total time=  35.4s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.501, test=0.501) total time=  35.1s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.587, test=0.572) total time=  41.0s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.523, test=0.523) total time=  40.6s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.501, test=0.505) total time=  56.7s\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.509, test=0.509) total time=  55.4s\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.673, test=0.654) total time= 1.1min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.717, test=0.686) total time= 1.2min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time</th>\n",
       "      <th>units</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>num_rnn_layers</th>\n",
       "      <th>num_dense_layers</th>\n",
       "      <th>dropout_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.722576</td>\n",
       "      <td>0.677848</td>\n",
       "      <td>46</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.731950</td>\n",
       "      <td>0.675982</td>\n",
       "      <td>70</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.694882</td>\n",
       "      <td>0.670068</td>\n",
       "      <td>69</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.616576</td>\n",
       "      <td>0.597944</td>\n",
       "      <td>57</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.556593</td>\n",
       "      <td>0.559410</td>\n",
       "      <td>36</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.555165</td>\n",
       "      <td>0.547657</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.505188</td>\n",
       "      <td>0.506662</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.505625</td>\n",
       "      <td>0.503388</td>\n",
       "      <td>35</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  test_score  time units bi_directional recurrent_type  \\\n",
       "1     0.722576    0.677848    46    64           True            gru   \n",
       "3     0.731950    0.675982    70    64           True            gru   \n",
       "7     0.694882    0.670068    69    64           True            gru   \n",
       "2     0.616576    0.597944    57    32           True            gru   \n",
       "0     0.556593    0.559410    36    32           True            gru   \n",
       "5     0.555165    0.547657    40    64           True            gru   \n",
       "6     0.505188    0.506662    56    32           True            gru   \n",
       "4     0.505625    0.503388    35    32           True            gru   \n",
       "\n",
       "  num_rnn_layers num_dense_layers dropout_rate  \n",
       "1              1                1         0.25  \n",
       "3              2                1         0.25  \n",
       "7              2                2         0.25  \n",
       "2              2                1         0.25  \n",
       "0              1                1         0.25  \n",
       "5              1                2         0.25  \n",
       "6              2                2         0.25  \n",
       "4              1                2         0.25  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled or not?\n",
    "X_input = X_train_clean_sampled\n",
    "y_input = y_train_sampled\n",
    "\n",
    "# finding vocab size\n",
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_input)\n",
    "X_train_tokenized = [review.split() for review in X_train_clean]\n",
    "train_vocabulary = set(word for review in X_train_tokenized for word in review)\n",
    "vocab_size = len(train_vocabulary) + 1\n",
    "\n",
    "#setting important dimensions\n",
    "vocab=min(15000,len(train_vocabulary) + 1)\n",
    "length=500\n",
    "embedding_dim = 300\n",
    "\n",
    "#making embedding matrix\n",
    "glove_embeddings = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "# Initialize the embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab, embedding_dim))\n",
    "\n",
    "# Fill in the matrix with GloVe embeddings\n",
    "for i, word in enumerate(train_vocabulary):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Ensure the index i does not exceed the vocab size limitation\n",
    "        if i < vocab:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "class KerasTextVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_tokens=vocab, output_sequence_length=length):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.output_sequence_length = output_sequence_length\n",
    "        self.text_vectorization = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=self.max_tokens,\n",
    "            output_sequence_length=self.output_sequence_length)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.text_vectorization.adapt(X)\n",
    "        return self  # Return self to allow chaining\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.text_vectorization(X).numpy()  \n",
    "\n",
    "def add_rnn_layer(model, units, rnn_type='gru', bidirectional=False, return_sequences=False):\n",
    "    LayerClass = layers.GRU if rnn_type == 'gru' else layers.LSTM\n",
    "    layer = LayerClass(units, return_sequences=return_sequences)\n",
    "    if bidirectional:\n",
    "        layer = layers.Bidirectional(layer)\n",
    "    model.add(layer)\n",
    "\n",
    "def build_glove_model(rnn_layers=1, dense_layers=1, recurrent_type='gru', bi_directional=False, dropout_rate=0.2, units=64, sequence_length=length, vocab_size=vocab, embedding_dim=embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length,\n",
    "                     weights=[embedding_matrix], trainable=False))\n",
    "    for i in range(rnn_layers):\n",
    "        add_rnn_layer(model, units, rnn_type=recurrent_type, bidirectional=bi_directional, \n",
    "                      return_sequences=(i < rnn_layers - 1))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(8, units // 2)\n",
    "\n",
    "    for _ in range(dense_layers):\n",
    "        model.add(layers.Dense(units, activation=\"relu\"))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(8, units // 2)\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              min_delta=0.01,\n",
    "                                              patience=2, \n",
    "                                              restore_best_weights=True,\n",
    "                                              verbose=0)]\n",
    "\n",
    "# Instantiate transformers\n",
    "text_vectorizer = KerasTextVectorizer(max_tokens=vocab, output_sequence_length=length)\n",
    "glv_model_wrapper = KerasClassifier(model=build_glove_model,\n",
    "                                    random_state=42,\n",
    "                                    optimizer='adam',\n",
    "                                    loss='binary_crossentropy',\n",
    "                                    metrics=['accuracy'],\n",
    "                                    batch_size=64,\n",
    "                                    verbose=0,\n",
    "                                    callbacks=CALLBACKS,\n",
    "                                    shuffle=True,\n",
    "                                    epochs=2)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('text_vect', text_vectorizer),\n",
    "    ('glv', glv_model_wrapper)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'glv__model__recurrent_type': ['gru'],  \n",
    "    'glv__model__units': [32,64],\n",
    "    'glv__model__bi_directional': [True],\n",
    "    'glv__model__rnn_layers': [1,2],\n",
    "    'glv__model__dense_layers': [1,2],\n",
    "    'glv__model__dropout_rate': [0.25]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                    param_grid=params,\n",
    "                    scoring='balanced_accuracy',\n",
    "                    cv=skf,\n",
    "                    verbose=4,\n",
    "                    n_jobs= 1,\n",
    "                    return_train_score=True)\n",
    "\n",
    "glv_grid_search = gs.fit(X_input, y_input)\n",
    "summarize_glv_grid_search_results(glv_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c35a2dd-7b17-4a7e-a3b5-ecfa818e3d96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 8 candidates, totalling 16 fits\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.842, test=0.817) total time= 2.0min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.831, test=0.836) total time= 2.1min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.865, test=0.847) total time= 2.7min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.853, test=0.849) total time= 2.7min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.673, test=0.657) total time= 3.4min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.806, test=0.807) total time= 3.0min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.844, test=0.819) total time= 4.7min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=1, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.859, test=0.847) total time= 3.9min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.827, test=0.807) total time= 2.0min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=32;, score=(train=0.796, test=0.805) total time= 2.0min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.800, test=0.783) total time= 2.3min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=1, glv__model__units=64;, score=(train=0.828, test=0.825) total time= 2.3min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.853, test=0.828) total time= 3.1min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=32;, score=(train=0.803, test=0.799) total time= 3.1min\n",
      "[CV 1/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.860, test=0.844) total time= 3.8min\n",
      "[CV 2/2] END glv__model__bi_directional=True, glv__model__dense_layers=2, glv__model__dropout_rate=0.25, glv__model__recurrent_type=gru, glv__model__rnn_layers=2, glv__model__units=64;, score=(train=0.861, test=0.850) total time= 3.8min\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>time</th>\n",
       "      <th>units</th>\n",
       "      <th>bi_directional</th>\n",
       "      <th>recurrent_type</th>\n",
       "      <th>num_rnn_layers</th>\n",
       "      <th>num_dense_layers</th>\n",
       "      <th>dropout_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.859047</td>\n",
       "      <td>0.848073</td>\n",
       "      <td>161</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.860750</td>\n",
       "      <td>0.847363</td>\n",
       "      <td>228</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.851308</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>258</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.836592</td>\n",
       "      <td>0.826778</td>\n",
       "      <td>124</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.828239</td>\n",
       "      <td>0.813345</td>\n",
       "      <td>186</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.811458</td>\n",
       "      <td>0.805816</td>\n",
       "      <td>118</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.814215</td>\n",
       "      <td>0.803960</td>\n",
       "      <td>135</td>\n",
       "      <td>64</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.739192</td>\n",
       "      <td>0.731675</td>\n",
       "      <td>192</td>\n",
       "      <td>32</td>\n",
       "      <td>True</td>\n",
       "      <td>gru</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_score  test_score  time units bi_directional recurrent_type  \\\n",
       "1     0.859047    0.848073   161    64           True            gru   \n",
       "7     0.860750    0.847363   228    64           True            gru   \n",
       "3     0.851308    0.832618   258    64           True            gru   \n",
       "0     0.836592    0.826778   124    32           True            gru   \n",
       "6     0.828239    0.813345   186    32           True            gru   \n",
       "4     0.811458    0.805816   118    32           True            gru   \n",
       "5     0.814215    0.803960   135    64           True            gru   \n",
       "2     0.739192    0.731675   192    32           True            gru   \n",
       "\n",
       "  num_rnn_layers num_dense_layers dropout_rate  \n",
       "1              1                1         0.25  \n",
       "7              2                2         0.25  \n",
       "3              2                1         0.25  \n",
       "0              1                1         0.25  \n",
       "6              2                2         0.25  \n",
       "4              1                2         0.25  \n",
       "5              1                2         0.25  \n",
       "2              2                1         0.25  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sampled or not?\n",
    "X_input = X_train\n",
    "y_input = y_train\n",
    "\n",
    "# finding vocab size\n",
    "text_cleaner = TextCleanerTransformer(stop_words=None, lemmatize=False)\n",
    "X_train_clean = text_cleaner.transform(X_input)\n",
    "X_train_tokenized = [review.split() for review in X_train_clean]\n",
    "train_vocabulary = set(word for review in X_train_tokenized for word in review)\n",
    "vocab_size = len(train_vocabulary) + 1\n",
    "\n",
    "#setting important dimensions\n",
    "vocab=min(20000,len(train_vocabulary) + 1)\n",
    "length=500\n",
    "embedding_dim = 300\n",
    "\n",
    "#making embedding matrix\n",
    "glove_embeddings = {}\n",
    "with open('../data/glove.6B.300d.txt', 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype='float32')\n",
    "        glove_embeddings[word] = vector\n",
    "\n",
    "# Initialize the embedding matrix with zeros\n",
    "embedding_matrix = np.zeros((vocab, embedding_dim))\n",
    "\n",
    "# Fill in the matrix with GloVe embeddings\n",
    "for i, word in enumerate(train_vocabulary):\n",
    "    embedding_vector = glove_embeddings.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Ensure the index i does not exceed the vocab size limitation\n",
    "        if i < vocab:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "class KerasTextVectorizer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, max_tokens=vocab, output_sequence_length=length):\n",
    "        self.max_tokens = max_tokens\n",
    "        self.output_sequence_length = output_sequence_length\n",
    "        self.text_vectorization = tf.keras.layers.TextVectorization(\n",
    "            max_tokens=self.max_tokens,\n",
    "            output_sequence_length=self.output_sequence_length)\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.text_vectorization.adapt(X)\n",
    "        return self  # Return self to allow chaining\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return self.text_vectorization(X).numpy()  \n",
    "\n",
    "def add_rnn_layer(model, units, rnn_type='gru', bidirectional=False, return_sequences=False):\n",
    "    LayerClass = layers.GRU if rnn_type == 'gru' else layers.LSTM\n",
    "    layer = LayerClass(units, return_sequences=return_sequences)\n",
    "    if bidirectional:\n",
    "        layer = layers.Bidirectional(layer)\n",
    "    model.add(layer)\n",
    "\n",
    "def build_glove_model(rnn_layers=1, dense_layers=1, recurrent_type='gru', bi_directional=False, dropout_rate=0.2, units=64, sequence_length=length, vocab_size=vocab, embedding_dim=embedding_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length,\n",
    "                     weights=[embedding_matrix], trainable=False))\n",
    "    for i in range(rnn_layers):\n",
    "        add_rnn_layer(model, units, rnn_type=recurrent_type, bidirectional=bi_directional, \n",
    "                      return_sequences=(i < rnn_layers - 1))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(8, units // 2)\n",
    "\n",
    "    for _ in range(dense_layers):\n",
    "        model.add(layers.Dense(units, activation=\"relu\"))\n",
    "        model.add(layers.Dropout(dropout_rate))\n",
    "        units = max(8, units // 2)\n",
    "\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
    "CALLBACKS = [tf.keras.callbacks.EarlyStopping(monitor='loss',\n",
    "                                              min_delta=0.01,\n",
    "                                              patience=2, \n",
    "                                              restore_best_weights=True,\n",
    "                                              verbose=0)]\n",
    "\n",
    "# Instantiate transformers\n",
    "text_vectorizer = KerasTextVectorizer(max_tokens=vocab, output_sequence_length=length)\n",
    "glv_model_wrapper = KerasClassifier(model=build_glove_model,\n",
    "                                    random_state=42,\n",
    "                                    optimizer='adam',\n",
    "                                    loss='binary_crossentropy',\n",
    "                                    metrics=['accuracy'],\n",
    "                                    batch_size=64,\n",
    "                                    verbose=0,\n",
    "                                    callbacks=CALLBACKS,\n",
    "                                    shuffle=True,\n",
    "                                    epochs=2)\n",
    "\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('text_vect', text_vectorizer),\n",
    "    ('glv', glv_model_wrapper)\n",
    "])\n",
    "\n",
    "params = {\n",
    "    'glv__model__recurrent_type': ['gru'],  \n",
    "    'glv__model__units': [32,64],\n",
    "    'glv__model__bi_directional': [True],\n",
    "    'glv__model__rnn_layers': [1,2],\n",
    "    'glv__model__dense_layers': [1,2],\n",
    "    'glv__model__dropout_rate': [0.25]\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(estimator=pipe,\n",
    "                    param_grid=params,\n",
    "                    scoring='balanced_accuracy',\n",
    "                    cv=skf,\n",
    "                    verbose=4,\n",
    "                    n_jobs= 1,\n",
    "                    return_train_score=True)\n",
    "\n",
    "glv_grid_search = gs.fit(X_input, y_input)\n",
    "summarize_glv_grid_search_results(glv_grid_search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f3938e-d170-484b-a63b-931cf37d65db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
